{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "855f9f50-ef38-4069-932a-fb49af02d28e",
      "metadata": {
        "id": "855f9f50-ef38-4069-932a-fb49af02d28e"
      },
      "source": [
        "# Query Pipeline for Advanced Text-to-SQL\n",
        "\n",
        "In this guide we show you how to setup a text-to-SQL pipeline over your data with our [query pipeline](https://docs.llamaindex.ai/en/stable/module_guides/querying/pipeline/root.html) syntax.\n",
        "\n",
        "This gives you flexibility to enhance text-to-SQL with additional techniques. We show these in the below sections:\n",
        "1. **Query-Time Table Retrieval**: Dynamically retrieve relevant tables in the text-to-SQL prompt.\n",
        "2. **Query-Time Sample Row retrieval**: Embed/Index each row, and dynamically retrieve example rows for each table in the text-to-SQL prompt.\n",
        "\n",
        "Our out-of-the box pipelines include our `NLSQLTableQueryEngine` and `SQLTableRetrieverQueryEngine`. (if you want to check out our text-to-SQL guide using these modules, take a look [here](https://docs.llamaindex.ai/en/stable/examples/index_structs/struct_indices/SQLIndexDemo.html)). This guide implements an advanced version of those modules, giving you the utmost flexibility to apply this to your own setting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e39cc96c-9fbc-44c3-b57f-017a9aa75473",
      "metadata": {
        "id": "e39cc96c-9fbc-44c3-b57f-017a9aa75473"
      },
      "source": [
        "## Load and Ingest Data\n",
        "\n",
        "\n",
        "### Load Data\n",
        "We use the [WikiTableQuestions dataset](https://ppasupat.github.io/WikiTableQuestions/) (Pasupat and Liang 2015) as our test dataset.\n",
        "\n",
        "We go through all the csv's in one folder, store each in a sqlite database (we will then build an object index over each table schema)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6bc8cd21",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "import zipfile\n",
        "import json\n",
        "import json as pyjson\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "# put data into sqlite db\n",
        "from sqlalchemy import (\n",
        "    create_engine,\n",
        "    MetaData,\n",
        "    Table,\n",
        "    Column,\n",
        "    String,\n",
        "    Integer,\n",
        ")\n",
        "\n",
        "# setup Arize Phoenix for logging/observability\n",
        "import phoenix as px\n",
        "from llama_index.core import set_global_handler\n",
        "\n",
        "from llama_index.core.objects import (\n",
        "    SQLTableNodeMapping,\n",
        "    ObjectIndex,\n",
        "    SQLTableSchema,\n",
        ")\n",
        "from llama_index.core import SQLDatabase, VectorStoreIndex\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "from llama_index.core.retrievers import SQLRetriever\n",
        "\n",
        "from llama_index.core.prompts.default_prompts import DEFAULT_TEXT_TO_SQL_PROMPT\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.llms import ChatResponse\n",
        "\n",
        "from llama_index.core.workflow import Workflow, step, StartEvent, StopEvent\n",
        "from llama_index.core.workflow.events import Event\n",
        "\n",
        "# import networkx as nx\n",
        "# from pyvis.network import Network\n",
        "\n",
        "from llama_index.utils.workflow import (\n",
        "    draw_all_possible_flows,\n",
        "    draw_most_recent_execution,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cadfb28c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "Extracting...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "URL = \"https://github.com/ppasupat/WikiTableQuestions/releases/download/v1.0.2/WikiTableQuestions-1.0.2-compact.zip\"\n",
        "\n",
        "OUTPUT_DIR = \"../data\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Downloading...\")\n",
        "response = requests.get(URL)\n",
        "response.raise_for_status()\n",
        "\n",
        "print(\"Extracting...\")\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "    z.extractall(OUTPUT_DIR)\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "5a710f7a-74b4-48c3-98d1-a6d409a7af1a",
      "metadata": {
        "id": "5a710f7a-74b4-48c3-98d1-a6d409a7af1a",
        "outputId": "fb840754-8360-459d-fe4b-bbe92b24475e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\0.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\1.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\10.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\11.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\12.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\14.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\15.csv\n",
            "Error parsing ..\\data\\WikiTableQuestions\\csv\\200-csv\\15.csv: Error tokenizing data. C error: Expected 4 fields in line 16, saw 5\n",
            "\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\17.csv\n",
            "Error parsing ..\\data\\WikiTableQuestions\\csv\\200-csv\\17.csv: Error tokenizing data. C error: Expected 6 fields in line 5, saw 7\n",
            "\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\18.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\20.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\22.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\24.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\25.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\26.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\28.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\29.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\3.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\30.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\31.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\32.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\33.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\34.csv\n",
            "Error parsing ..\\data\\WikiTableQuestions\\csv\\200-csv\\34.csv: Error tokenizing data. C error: Expected 4 fields in line 6, saw 13\n",
            "\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\35.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\36.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\37.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\38.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\4.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\41.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\42.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\44.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\45.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\46.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\47.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\48.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\7.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\8.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\9.csv\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = Path(\"../data/WikiTableQuestions/csv/200-csv\")\n",
        "CSV_FILES = sorted([f for f in DATA_DIR.glob(\"*.csv\")])\n",
        "dfs = []\n",
        "\n",
        "for csv_file in CSV_FILES:\n",
        "    print(f\"processing file: {csv_file}\")\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        dfs.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {csv_file}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c271b986-9ed6-4a8a-a7c2-1dad7a642c06",
      "metadata": {
        "id": "c271b986-9ed6-4a8a-a7c2-1dad7a642c06"
      },
      "source": [
        "### Extract Table Name and Summary from each Table\n",
        "\n",
        "Here we use gpt-3.5 to extract a table name (with underscores) and summary from each table with our Pydantic program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "4cef9585-87f8-4427-aaca-c0038c289e00",
      "metadata": {
        "id": "4cef9585-87f8-4427-aaca-c0038c289e00",
        "outputId": "03b3f4e4-93cf-4125-b745-a5f190208bbf"
      },
      "outputs": [],
      "source": [
        "TABLEINFO_DIR = \"../data/WikiTableQuestions_TableInfo\"\n",
        "os.makedirs(TABLEINFO_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "9a81afbf-0870-41b1-baea-017026a1b7d6",
      "metadata": {
        "id": "9a81afbf-0870-41b1-baea-017026a1b7d6"
      },
      "outputs": [],
      "source": [
        "class TableInfo(BaseModel):\n",
        "    \"\"\"Information regarding a structured table.\"\"\"\n",
        "\n",
        "    table_name: str = Field(\n",
        "        ..., description=\"table name (must be underscores and NO spaces)\"\n",
        "    )\n",
        "    table_summary: str = Field(\n",
        "        ..., description=\"short, concise summary/caption of the table\"\n",
        "    )\n",
        "\n",
        "PROMPT_STR = \"\"\"\\\n",
        "    Return only a JSON object, with no explanation, no prose, no markdown, and no trailing text.\n",
        "    You are to produce **only** a JSON object matching the following exact schema:\n",
        "\n",
        "    {\n",
        "        \"table_name\": \"<short_name_in_snake_case_without_spaces>\",\n",
        "        \"table_summary\": \"<short concise caption of the table>\"\n",
        "    }\n",
        "\n",
        "    Example:\n",
        "    {\"table_name\": \"movie_info\", \"table_summary\": \"Summary of movie data\"}\n",
        "\n",
        "    Rules:\n",
        "    - The table_name must be unique to the table, describe it clearly, and be in snake_case.\n",
        "    - Do NOT output a generic table name (e.g., \"table\", \"my_table\").\n",
        "    - Do NOT make the table name one of the following: {exclude_table_name_list}.\n",
        "    - Do NOT include any keys other than \"table_name\" and \"table_summary\".\n",
        "    - Do NOT include extra text before/after the JSON.\n",
        "    - Do NOT include any other keys or text before/after the JSON.\n",
        "    - Do NOT wrap in ```json.\n",
        "\n",
        "    Table:\n",
        "    {table_str}\n",
        "\"\"\"\n",
        "\n",
        "Settings.llm = Ollama(\n",
        "    model=\"qwen3:0.6b\", \n",
        "    request_timeout=240,\n",
        "    format=\"json\",\n",
        "    # context_window=1000\n",
        ")\n",
        "\n",
        "program = LLMTextCompletionProgram.from_defaults(\n",
        "    output_cls=TableInfo,\n",
        "    prompt_template_str=PROMPT_STR,\n",
        "    llm=Settings.llm,\n",
        "    # verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "db30f75b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_first_json_block(text: str):\n",
        "    match = re.search(r\"\\{.*\\}\", text, re.S)  # grab first {...} block\n",
        "    if not match:\n",
        "        raise ValueError(\"No JSON object found in output\")\n",
        "    return pyjson.loads(match.group())\n",
        "\n",
        "\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "\n",
        "def _get_tableinfo_with_index(idx: int) -> str:\n",
        "    results_gen = Path(TABLEINFO_DIR).glob(f\"{idx}_*\")\n",
        "    results_list = list(results_gen)\n",
        "    \n",
        "    if len(results_list) == 0:\n",
        "        return None\n",
        "    elif len(results_list) == 1:\n",
        "        path = results_list[0]\n",
        "        json_str = path.read_text(encoding=\"utf-8\")\n",
        "        return TableInfo.model_validate_json(json_str)\n",
        "    else:\n",
        "        raise ValueError(f\"More than one file matching index: {list(results_gen)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "f50a3c04-d1fb-4964-8f37-741fb98a5249",
      "metadata": {
        "id": "f50a3c04-d1fb-4964-8f37-741fb98a5249"
      },
      "outputs": [],
      "source": [
        "table_names = set()\n",
        "table_infos = []\n",
        "\n",
        "for idx, df in enumerate(dfs):\n",
        "    table_info = _get_tableinfo_with_index(idx)\n",
        "    if table_info:\n",
        "        table_infos.append(table_info)\n",
        "        continue\n",
        "\n",
        "    df_str = df.head(10).to_csv()\n",
        "\n",
        "    for attempt in range(MAX_RETRIES):\n",
        "        try:\n",
        "            raw_output = program(\n",
        "                table_str=df_str,\n",
        "                exclude_table_name_list=str(list(table_names)),\n",
        "            )\n",
        "\n",
        "            if isinstance(raw_output, TableInfo):\n",
        "                table_info = raw_output\n",
        "            elif isinstance(raw_output, dict):\n",
        "                table_info = TableInfo(**raw_output)\n",
        "            elif isinstance(raw_output, str):\n",
        "                parsed_dict = extract_first_json_block(raw_output)\n",
        "                table_info = TableInfo(**parsed_dict)\n",
        "            else:\n",
        "                raise TypeError(f\"Unexpected return type from program(): {type(raw_output)}\")\n",
        "\n",
        "            table_name = table_info.table_name\n",
        "            print(f\"Processed table: {table_name}\")\n",
        "\n",
        "            if table_name in table_names:\n",
        "                print(f\"Table name '{table_name}' already exists, skipping this table.\")\n",
        "                table_info = None  # donâ€™t append duplicate\n",
        "                break  # skip\n",
        "\n",
        "            # save table info\n",
        "            table_names.add(table_name)\n",
        "            out_file = f\"{TABLEINFO_DIR}/{idx}_{table_name}.json\"\n",
        "            json.dump(table_info.model_dump(), open(out_file, \"w\"))\n",
        "            break  # move to next table\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with attempt {attempt+1}: {e}\")\n",
        "            time.sleep(2)\n",
        "\n",
        "    if table_info:\n",
        "        table_infos.append(table_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e667fde",
      "metadata": {},
      "source": [
        "To retry for a single index (in needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8dd7ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error with attempt 1: 1 validation error for TableInfo\n",
            "  Invalid JSON: trailing characters at line 1 column 97 [type=json_invalid, input_value='{\"table_name\": \"award_in...n the specified table\"}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n",
            "Processed table: award_nominations\n"
          ]
        }
      ],
      "source": [
        "# idx = 20\n",
        "# df = dfs[idx]\n",
        "\n",
        "# table_info = _get_tableinfo_with_index(idx)\n",
        "# if table_info:\n",
        "#     table_infos.append(table_info)\n",
        "# else:\n",
        "#     df_str = df.head(20).to_csv()\n",
        "\n",
        "#     for attempt in range(MAX_RETRIES):\n",
        "#         try:\n",
        "#             raw_output = program(\n",
        "#                 table_str=df_str,\n",
        "#                 exclude_table_name_list=str(list(table_names)),\n",
        "#             )\n",
        "\n",
        "#             if isinstance(raw_output, TableInfo):\n",
        "#                 table_info = raw_output\n",
        "#             elif isinstance(raw_output, dict):\n",
        "#                 table_info = TableInfo(**raw_output)\n",
        "#             elif isinstance(raw_output, str):\n",
        "#                 parsed_dict = extract_first_json_block(raw_output)\n",
        "#                 table_info = TableInfo(**parsed_dict)\n",
        "#             else:\n",
        "#                 raise TypeError(f\"Unexpected return type from program(): {type(raw_output)}\")\n",
        "\n",
        "#             table_name = table_info.table_name\n",
        "#             print(f\"Processed table: {table_name}\")\n",
        "\n",
        "#             if table_name in table_names:\n",
        "#                 print(f\"Table name '{table_name}' already exists, skipping this table.\")\n",
        "#                 table_info = None\n",
        "#                 break\n",
        "\n",
        "#             table_names.add(table_name)\n",
        "#             out_file = f\"{TABLEINFO_DIR}/{idx}_{table_name}.json\"\n",
        "#             json.dump(table_info.model_dump(), open(out_file, \"w\"))\n",
        "#             break\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error with attempt {attempt+1}: {e}\")\n",
        "#             time.sleep(2)\n",
        "\n",
        "#     if table_info:\n",
        "#         table_infos.append(table_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1cc3230-d14c-4491-b79f-45159708badb",
      "metadata": {
        "id": "a1cc3230-d14c-4491-b79f-45159708badb"
      },
      "source": [
        "### Put Data in SQL Database\n",
        "\n",
        "We use `sqlalchemy`, a popular SQL database toolkit, to load all the tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "53544059-de7d-48dd-8e00-89517964852b",
      "metadata": {
        "id": "53544059-de7d-48dd-8e00-89517964852b",
        "outputId": "df224651-1765-4aa7-e841-d58546c20e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating table: movie_chart_positions\n",
            "Creating table: movie_data\n",
            "Creating table: death_accident_statistics\n",
            "Creating table: award_data_1972\n",
            "Creating table: award_data\n",
            "Creating table: people_info\n",
            "Creating table: broadcasting_info\n",
            "Creating table: person_info\n",
            "Creating table: chart_positions\n",
            "Creating table: kodachrome_film_info\n",
            "Creating table: bbc_radio_costs\n",
            "Creating table: airport_locations\n",
            "Creating table: party_voters\n",
            "Creating table: club_performance\n",
            "Creating table: horse_race_data\n",
            "Creating table: grammy_awards\n",
            "Creating table: boxing_matches\n",
            "Creating table: sports_performance_data\n",
            "Creating table: district_info\n",
            "Creating table: party_data\n",
            "Creating table: award_nominations\n",
            "Creating table: government_ministers\n",
            "Creating table: new_municipality_old_municipality_seat\n",
            "Creating table: team_performance\n",
            "Creating table: encoding_info\n",
            "Creating table: temperature_data\n",
            "Creating table: people_terms\n",
            "Creating table: new_mexico_governorships\n",
            "Creating table: weather_statistics\n",
            "Creating table: drop_event_data\n",
            "Creating table: precipitation_data\n",
            "Creating table: afrikaans_language_usage\n",
            "Creating table:  ohio_districts\n",
            "Creating table: gene_functions\n"
          ]
        }
      ],
      "source": [
        "# Function to create a sanitized column name\n",
        "def sanitize_column_name(col_name):\n",
        "    # Remove special characters and replace spaces with underscores\n",
        "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
        "\n",
        "\n",
        "# Function to create a table from a DataFrame using SQLAlchemy\n",
        "def create_table_from_dataframe(\n",
        "    df: pd.DataFrame, table_name: str, engine, metadata_obj\n",
        "):\n",
        "    # Sanitize column names\n",
        "    sanitized_columns = {col: sanitize_column_name(col) for col in df.columns}\n",
        "    df = df.rename(columns=sanitized_columns)\n",
        "\n",
        "    # Dynamically create columns based on DataFrame columns and data types\n",
        "    columns = [\n",
        "        Column(col, String if dtype == \"object\" else Integer)\n",
        "        for col, dtype in zip(df.columns, df.dtypes)\n",
        "    ]\n",
        "\n",
        "    # Create a table with the defined columns\n",
        "    table = Table(table_name, metadata_obj, *columns)\n",
        "\n",
        "    # Create the table in the database\n",
        "    metadata_obj.create_all(engine)\n",
        "\n",
        "    # Insert data from DataFrame into the table\n",
        "    with engine.connect() as conn:\n",
        "        for _, row in df.iterrows():\n",
        "            insert_stmt = table.insert().values(**row.to_dict())\n",
        "            conn.execute(insert_stmt)\n",
        "        conn.commit()\n",
        "\n",
        "\n",
        "engine = create_engine(\"sqlite:///:memory:\")\n",
        "metadata_obj = MetaData()\n",
        "for idx, df in enumerate(dfs):\n",
        "    tableinfo = _get_tableinfo_with_index(idx)\n",
        "    if tableinfo is None:\n",
        "        print(f\"[ERROR] No TableInfo for index {idx}\")\n",
        "        continue  # skip this one or handle it differently\n",
        "    print(f\"Creating table: {tableinfo.table_name}\")\n",
        "    create_table_from_dataframe(df, tableinfo.table_name, engine, metadata_obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "f12a34b5-1d91-4e85-a6ce-97adb5ddfa06",
      "metadata": {
        "id": "f12a34b5-1d91-4e85-a6ce-97adb5ddfa06",
        "outputId": "4527a7d1-6b5f-4f89-9a63-e5263f4e4441"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n",
            "Attempting to instrument while already instrumented\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŒ To view the Phoenix app in your browser, visit http://localhost:6006/\n",
            "ðŸ“– For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n"
          ]
        }
      ],
      "source": [
        "px.launch_app()\n",
        "set_global_handler(\"arize_phoenix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5906e7-4e20-4b0a-bc42-615f6b86beb7",
      "metadata": {
        "id": "1b5906e7-4e20-4b0a-bc42-615f6b86beb7"
      },
      "source": [
        "## Advanced Capability 1: Text-to-SQL with Query-Time Table Retrieval.\n",
        "\n",
        "We now show you how to setup an e2e text-to-SQL with table retrieval.\n",
        "\n",
        "### Define Modules\n",
        "\n",
        "Here we define the core modules.\n",
        "1. Object index + retriever to store table schemas\n",
        "2. SQLDatabase object to connect to the above tables + SQLRetriever.\n",
        "3. Text-to-SQL Prompt\n",
        "4. Response synthesis Prompt\n",
        "5. LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0830ecca-9688-45b7-b011-d6d44d6fc551",
      "metadata": {
        "id": "0830ecca-9688-45b7-b011-d6d44d6fc551"
      },
      "source": [
        "Object index, retriever, SQLDatabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "8a89bc36-a5ac-46bf-b9ae-801f34992019",
      "metadata": {
        "id": "8a89bc36-a5ac-46bf-b9ae-801f34992019"
      },
      "outputs": [],
      "source": [
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "sql_database = SQLDatabase(engine)\n",
        "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
        "\n",
        "table_schema_objs = [\n",
        "    SQLTableSchema(table_name=t.table_name, context_str=t.table_summary)\n",
        "    for t in table_infos\n",
        "]  # add a SQLTableSchema for each table\n",
        "\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    table_schema_objs,\n",
        "    table_node_mapping,\n",
        "    VectorStoreIndex,\n",
        "    embed_model=embed_model,\n",
        ")\n",
        "obj_retriever = obj_index.as_retriever(similarity_top_k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4620fbe4-eac6-4476-b373-0e48dfbd81e0",
      "metadata": {
        "id": "4620fbe4-eac6-4476-b373-0e48dfbd81e0"
      },
      "source": [
        "SQLRetriever + Table Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "3e9d68bb-16a5-409c-a406-1432565dde99",
      "metadata": {
        "id": "3e9d68bb-16a5-409c-a406-1432565dde99"
      },
      "outputs": [],
      "source": [
        "sql_retriever = SQLRetriever(sql_database)\n",
        "\n",
        "\n",
        "def get_table_context_str(table_schema_objs: List[SQLTableSchema]):\n",
        "    \"\"\"Get table context string.\"\"\"\n",
        "    context_strs = []\n",
        "    for table_schema_obj in table_schema_objs:\n",
        "        table_info = sql_database.get_single_table_info(\n",
        "            table_schema_obj.table_name\n",
        "        )\n",
        "        if table_schema_obj.context_str:\n",
        "            table_opt_context = \" The table description is: \"\n",
        "            table_opt_context += table_schema_obj.context_str\n",
        "            table_info += table_opt_context\n",
        "\n",
        "        context_strs.append(table_info)\n",
        "    return \"\\n\\n\".join(context_strs)\n",
        "\n",
        "\n",
        "table_parser_component = get_table_context_str(table_schema_objs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830ff35b-72ba-42bc-ab49-14b2efc93d17",
      "metadata": {
        "id": "830ff35b-72ba-42bc-ab49-14b2efc93d17"
      },
      "source": [
        "Text-to-SQL Prompt + Output Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "246b8a28-a5b8-4103-b731-a6c09f8694ed",
      "metadata": {
        "id": "246b8a28-a5b8-4103-b731-a6c09f8694ed",
        "outputId": "479f47f2-f530-4984-d0fe-ded7a02a306e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.\n",
            "\n",
            "Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
            "\n",
            "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
            "\n",
            "Question: Question here\n",
            "SQLQuery: SQL Query to run\n",
            "SQLResult: Result of the SQLQuery\n",
            "Answer: Final answer here\n",
            "\n",
            "Only use tables listed below.\n",
            "{schema}\n",
            "\n",
            "Question: {query_str}\n",
            "SQLQuery: \n"
          ]
        }
      ],
      "source": [
        "def parse_response_to_sql(response: ChatResponse) -> str:\n",
        "    \"\"\"Parse response to SQL.\"\"\"\n",
        "    response = response.message.content\n",
        "    sql_query_start = response.find(\"SQLQuery:\")\n",
        "    if sql_query_start != -1:\n",
        "        response = response[sql_query_start:]\n",
        "        \n",
        "        if response.startswith(\"SQLQuery:\"):\n",
        "            response = response[len(\"SQLQuery:\") :]\n",
        "    sql_result_start = response.find(\"SQLResult:\")\n",
        "    if sql_result_start != -1:\n",
        "        response = response[:sql_result_start]\n",
        "    return response.strip().strip(\"```\").strip()\n",
        "\n",
        "\n",
        "sql_parser_component = FunctionTool.from_defaults(fn=parse_response_to_sql)\n",
        "\n",
        "text2sql_prompt = DEFAULT_TEXT_TO_SQL_PROMPT.partial_format(\n",
        "    dialect=engine.dialect.name\n",
        ")\n",
        "print(text2sql_prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cf6a211-dd6b-4ffc-b781-0b0c38896e25",
      "metadata": {
        "id": "0cf6a211-dd6b-4ffc-b781-0b0c38896e25"
      },
      "source": [
        "Response Synthesis Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "a2fe48e8-ffdd-48f8-b59a-d13d973e8a19",
      "metadata": {
        "id": "a2fe48e8-ffdd-48f8-b59a-d13d973e8a19"
      },
      "outputs": [],
      "source": [
        "response_synthesis_prompt_str = (\n",
        "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
        "    \"Query: {query_str}\\n\"\n",
        "    \"SQL: {sql_query}\\n\"\n",
        "    \"SQL Response: {context_str}\\n\"\n",
        "    \"Response: \"\n",
        ")\n",
        "response_synthesis_prompt = PromptTemplate(\n",
        "    response_synthesis_prompt_str,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ad7cc4-763b-4060-8cc3-ac198c6b956c",
      "metadata": {
        "id": "d4ad7cc4-763b-4060-8cc3-ac198c6b956c"
      },
      "source": [
        "### Define Workflow\n",
        "\n",
        "Now that the components are in place, let's define the query pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe05227",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # custom events\n",
        "# class TableRetrievedEvent(Event):\n",
        "#     tables: list\n",
        "#     query_str: str\n",
        "\n",
        "# class SchemaProcessedEvent(Event):\n",
        "#     table_schema: str\n",
        "#     query_str: str\n",
        "\n",
        "# class SQLPromptReadyEvent(Event):\n",
        "#     t2s_prompt: str\n",
        "#     query_str: str\n",
        "#     table_schema: str\n",
        "\n",
        "# class SQLGeneratedEvent(Event):\n",
        "#     sql_query: str\n",
        "#     query_str: str\n",
        "#     table_schema: str\n",
        "\n",
        "# class SQLParsedEvent(Event):\n",
        "#     sql_query: str\n",
        "#     query_str: str\n",
        "#     table_schema: str\n",
        "\n",
        "# class SQLResultsEvent(Event):\n",
        "#     context_str: str\n",
        "#     sql_query: str\n",
        "#     query_str: str\n",
        "\n",
        "# class ResponsePromptReadyEvent(Event):\n",
        "#     rs_prompt: str\n",
        "\n",
        "\n",
        "# def extract_sql_from_response(llm_response: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Extract SQL query from LLM response that might contain reasoning or formatting.\n",
        "#     \"\"\"\n",
        "#     response = llm_response.strip()\n",
        "    \n",
        "#     # First, remove <think> blocks entirely\n",
        "#     response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()\n",
        "    \n",
        "#     # Method 1: Look for SQLQuery: pattern\n",
        "#     sql_query_match = re.search(r'SQLQuery:\\s*([^;]+;?)', response, re.IGNORECASE | re.DOTALL)\n",
        "#     if sql_query_match:\n",
        "#         sql = sql_query_match.group(1).strip()\n",
        "#         return clean_sql_query(sql)\n",
        "    \n",
        "#     # Method 2: Look for SQL in code blocks\n",
        "#     code_block_match = re.search(r'```sql\\s*\\n(.*?)\\n```', response, re.IGNORECASE | re.DOTALL)\n",
        "#     if code_block_match:\n",
        "#         sql = code_block_match.group(1).strip()\n",
        "#         return clean_sql_query(sql)\n",
        "    \n",
        "#     # Method 3: Look for standalone SQL statements (most common case)\n",
        "#     sql_keywords = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'WITH']\n",
        "    \n",
        "#     # Split by lines and look for SQL statements\n",
        "#     lines = response.split('\\n')\n",
        "#     for line in lines:\n",
        "#         line = line.strip()\n",
        "#         if not line:\n",
        "#             continue\n",
        "            \n",
        "#         # Check if line starts with SQL keyword\n",
        "#         if any(line.upper().startswith(keyword.upper()) for keyword in sql_keywords):\n",
        "#             return clean_sql_query(line)\n",
        "    \n",
        "#     # Method 4: Look for multi-line SQL statements\n",
        "#     for keyword in sql_keywords:\n",
        "#         pattern = rf'\\b{keyword}\\b.*?(?=\\n\\s*\\n|\\nSQLResult|\\nAnswer|$)'\n",
        "#         sql_match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
        "#         if sql_match:\n",
        "#             sql = sql_match.group(0).strip()\n",
        "#             return clean_sql_query(sql)\n",
        "    \n",
        "#     # Fallback: if nothing found, return empty string to avoid errors\n",
        "#     print(f\"Warning: Could not extract SQL from response: {response[:100]}...\")\n",
        "#     return \"SELECT 1\"  # Safe fallback query\n",
        "\n",
        "\n",
        "# def clean_sql_query(sql: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Clean and standardize SQL query.\n",
        "#     \"\"\"\n",
        "#     if not sql:\n",
        "#         return \"SELECT 1\"\n",
        "    \n",
        "#     # Remove extra whitespace\n",
        "#     sql = ' '.join(sql.split())\n",
        "    \n",
        "#     # Fix quote issues - convert double quotes to single quotes for string literals\n",
        "#     # This is a simple approach - for more complex cases, you'd need a proper SQL parser\n",
        "#     sql = re.sub(r'\"([^\"]*)\"', r\"'\\1'\", sql)\n",
        "    \n",
        "#     # Remove multiple semicolons\n",
        "#     sql = re.sub(r';+', ';', sql)\n",
        "    \n",
        "#     # Remove trailing semicolon and add it back cleanly\n",
        "#     sql = sql.rstrip(';').strip()\n",
        "    \n",
        "#     # Don't add semicolon for now since it might be causing issues\n",
        "#     return sql\n",
        "\n",
        "\n",
        "# class Text2SQLWorkflow(Workflow):\n",
        "    \n",
        "#     @step\n",
        "#     async def input_step(self, ev: StartEvent) -> TableRetrievedEvent:\n",
        "#         \"\"\"Process the initial query and retrieve relevant tables\"\"\"\n",
        "#         query = ev.query\n",
        "        \n",
        "#         # Retrieve table schemas (you'll need to define obj_retriever)\n",
        "#         table_schema_objs = obj_retriever.retrieve(query)\n",
        "        \n",
        "#         return TableRetrievedEvent(\n",
        "#             tables=table_schema_objs,\n",
        "#             query_str=query\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def table_output_parser_step(self, ev: TableRetrievedEvent) -> SchemaProcessedEvent:\n",
        "#         \"\"\"Parse table schemas into string format\"\"\"\n",
        "#         # You'll need to define get_table_context_str function\n",
        "#         schema_str = get_table_context_str(ev.tables)\n",
        "        \n",
        "#         return SchemaProcessedEvent(\n",
        "#             table_schema=schema_str,\n",
        "#             query_str=ev.query_str\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def text2sql_prompt_step(self, ev: SchemaProcessedEvent) -> SQLPromptReadyEvent:\n",
        "#         \"\"\"Create the text-to-SQL prompt\"\"\"\n",
        "#         # Enhanced prompt to ensure clean SQL output\n",
        "#         ENHANCED_PROMPT = f\"\"\"\n",
        "#             Given the following table schema and user question, generate a SQL query.\n",
        "\n",
        "#             Table Schema:\n",
        "#             {ev.table_schema}\n",
        "\n",
        "#             User Question: {ev.query_str}\n",
        "\n",
        "#             Instructions:\n",
        "#             1. Generate ONLY a valid SQL query\n",
        "#             2. Do not include any explanations, reasoning, or additional text\n",
        "#             3. Do not include SQLQuery:, SQLResult:, or Answer: labels\n",
        "#             4. Do not wrap in code blocks or other formatting\n",
        "#             5. End the query with a semicolon\n",
        "\n",
        "#             SQL Query:\n",
        "#         \"\"\"\n",
        "        \n",
        "#         # If you have a custom text2sql_prompt, use it instead\n",
        "#         # prompt = text2sql_prompt.format(\n",
        "#         #     query_str=ev.query_str,\n",
        "#         #     table_schema=ev.table_schema\n",
        "#         # )\n",
        "        \n",
        "#         return SQLPromptReadyEvent(\n",
        "#             t2s_prompt=ENHANCED_PROMPT,\n",
        "#             query_str=ev.query_str,\n",
        "#             table_schema=ev.table_schema\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def text2sql_llm_step(self, ev: SQLPromptReadyEvent) -> SQLGeneratedEvent:\n",
        "#         \"\"\"Generate SQL query using LLM\"\"\"\n",
        "#         # You'll need to configure Settings.llm\n",
        "#         sql_response = await Settings.llm.acomplete(ev.t2s_prompt)\n",
        "        \n",
        "#         return SQLGeneratedEvent(\n",
        "#             sql_query=str(sql_response).strip(),\n",
        "#             query_str=ev.query_str,\n",
        "#             table_schema=ev.table_schema\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def sql_output_parser_step(self, ev: SQLGeneratedEvent) -> SQLParsedEvent:\n",
        "#         \"\"\"Parse and clean the generated SQL query\"\"\"\n",
        "#         # Extract clean SQL from the LLM response\n",
        "#         clean_sql = extract_sql_from_response(ev.sql_query)\n",
        "        \n",
        "#         print(f\"Original LLM Response: {ev.sql_query}\")\n",
        "#         print(f\"Cleaned SQL Query: {clean_sql}\")\n",
        "        \n",
        "#         # Validate that we have a reasonable SQL query\n",
        "#         if not clean_sql or clean_sql == \"SELECT 1\":\n",
        "#             print(\"Warning: Could not extract valid SQL, using fallback\")\n",
        "        \n",
        "#         return SQLParsedEvent(\n",
        "#             sql_query=clean_sql,\n",
        "#             query_str=ev.query_str,\n",
        "#             table_schema=ev.table_schema\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def sql_retriever_step(self, ev: SQLParsedEvent) -> SQLResultsEvent:\n",
        "#         \"\"\"Execute SQL query and get results\"\"\"\n",
        "#         try:\n",
        "#             # You'll need to define sql_retriever\n",
        "#             results = sql_retriever.retrieve(ev.sql_query)\n",
        "            \n",
        "#             return SQLResultsEvent(\n",
        "#                 context_str=str(results),\n",
        "#                 sql_query=ev.sql_query,\n",
        "#                 query_str=ev.query_str\n",
        "#             )\n",
        "#         except Exception as e:\n",
        "#             print(f\"SQL Execution Error: {e}\")\n",
        "#             print(f\"Failed SQL Query: {ev.sql_query}\")\n",
        "#             # Return error information for debugging\n",
        "#             return SQLResultsEvent(\n",
        "#                 context_str=f\"SQL execution failed: {str(e)}\",\n",
        "#                 sql_query=ev.sql_query,\n",
        "#                 query_str=ev.query_str\n",
        "#             )\n",
        "    \n",
        "#     @step\n",
        "#     async def response_synthesis_prompt_step(self, ev: SQLResultsEvent) -> ResponsePromptReadyEvent:\n",
        "#         \"\"\"Create the response synthesis prompt\"\"\"\n",
        "#         # You'll need to define response_synthesis_prompt template\n",
        "#         prompt = response_synthesis_prompt.format(\n",
        "#             query_str=ev.query_str,\n",
        "#             context_str=ev.context_str,\n",
        "#             sql_query=ev.sql_query\n",
        "#         )\n",
        "        \n",
        "#         return ResponsePromptReadyEvent(rs_prompt=prompt)\n",
        "    \n",
        "#     @step\n",
        "#     async def response_synthesis_llm_step(self, ev: ResponsePromptReadyEvent) -> StopEvent:\n",
        "#         \"\"\"Generate final answer using LLM\"\"\"\n",
        "#         answer = await Settings.llm.acomplete(ev.rs_prompt)\n",
        "        \n",
        "#         return StopEvent(result=str(answer))\n",
        "\n",
        "\n",
        "# async def run_text2sql_workflow(query: str):\n",
        "#     workflow = Text2SQLWorkflow(timeout=120)\n",
        "#     result = await workflow.run(query=query)\n",
        "#     return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "96cac786",
      "metadata": {},
      "outputs": [],
      "source": [
        "# custom events\n",
        "class TableRetrievedEvent(Event):\n",
        "    tables: list\n",
        "    query_str: str\n",
        "\n",
        "class SchemaProcessedEvent(Event):\n",
        "    table_schema: str\n",
        "    query_str: str\n",
        "\n",
        "class SQLPromptReadyEvent(Event):\n",
        "    t2s_prompt: str\n",
        "    query_str: str\n",
        "    table_schema: str\n",
        "    retry_count: int = 0\n",
        "    error_message: str = \"\"\n",
        "\n",
        "class SQLGeneratedEvent(Event):\n",
        "    sql_query: str\n",
        "    query_str: str\n",
        "    table_schema: str\n",
        "    retry_count: int = 0\n",
        "    error_message: str = \"\"\n",
        "\n",
        "class SQLParsedEvent(Event):\n",
        "    sql_query: str\n",
        "    query_str: str\n",
        "    table_schema: str\n",
        "    retry_count: int = 0\n",
        "    error_message: str = \"\"\n",
        "\n",
        "class SQLResultsEvent(Event):\n",
        "    context_str: str\n",
        "    sql_query: str\n",
        "    query_str: str\n",
        "    success: bool = True\n",
        "\n",
        "class ResponsePromptReadyEvent(Event):\n",
        "    rs_prompt: str\n",
        "\n",
        "\n",
        "def is_valid_sql_start(text: str) -> bool:\n",
        "    \"\"\"Check if text starts with valid SQL\"\"\"\n",
        "    if not text:\n",
        "        return False\n",
        "    \n",
        "    sql_keywords = ['SELECT', 'WITH', 'INSERT', 'UPDATE', 'DELETE']\n",
        "    text_upper = text.upper().strip()\n",
        "    return any(text_upper.startswith(keyword) for keyword in sql_keywords)\n",
        "\n",
        "def extract_sql_from_response(llm_response: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract SQL query from LLM response that might contain reasoning or formatting.\n",
        "    \"\"\"\n",
        "    response = llm_response.strip()\n",
        "    \n",
        "    # First, remove <think> blocks entirely\n",
        "    response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()\n",
        "    \n",
        "    # Remove any non-SQL content at the beginning\n",
        "    response = re.sub(r'^[^S]*(?=SELECT|WITH|INSERT|UPDATE|DELETE)', '', response, flags=re.IGNORECASE)\n",
        "    \n",
        "    # Method 1: Look for SQLQuery: pattern\n",
        "    sql_query_match = re.search(r'SQLQuery:\\s*([^;]+;?)', response, re.IGNORECASE | re.DOTALL)\n",
        "    if sql_query_match:\n",
        "        sql = sql_query_match.group(1).strip()\n",
        "        return clean_sql_query(sql)\n",
        "    \n",
        "    # Method 2: Look for SQL in code blocks\n",
        "    code_block_patterns = [\n",
        "        r'```sql\\s*\\n(.*?)\\n```',\n",
        "        r'```\\s*\\n(.*?)\\n```',\n",
        "        r'`([^`]+)`'\n",
        "    ]\n",
        "    \n",
        "    for pattern in code_block_patterns:\n",
        "        match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
        "        if match:\n",
        "            sql = match.group(1).strip()\n",
        "            if is_valid_sql_start(sql):\n",
        "                return clean_sql_query(sql)\n",
        "    \n",
        "    # Method 3: Look for standalone SQL statements\n",
        "    sql_keywords = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'WITH']\n",
        "    \n",
        "    # Split by lines and look for SQL statements\n",
        "    lines = response.split('\\n')\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "            \n",
        "        # Check if line starts with SQL keyword\n",
        "        if any(line.upper().startswith(keyword.upper()) for keyword in sql_keywords):\n",
        "            return clean_sql_query(line)\n",
        "    \n",
        "    # Method 4: Look for multi-line SQL statements\n",
        "    for keyword in sql_keywords:\n",
        "        pattern = rf'\\b{keyword}\\b.*?(?=\\n\\s*\\n|\\nSQLResult|\\nAnswer|$)'\n",
        "        sql_match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
        "        if sql_match:\n",
        "            sql = sql_match.group(0).strip()\n",
        "            return clean_sql_query(sql)\n",
        "    \n",
        "    # Fallback: if nothing found, return empty string to avoid errors\n",
        "    print(f\"Warning: Could not extract SQL from response: {response[:100]}...\")\n",
        "    return \"SELECT 1\"  # Safe fallback query\n",
        "\n",
        "\n",
        "def clean_sql_query(sql: str) -> str:\n",
        "    \"\"\"\n",
        "    Clean and standardize SQL query.\n",
        "    \"\"\"\n",
        "    if not sql:\n",
        "        return \"SELECT 1\"\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    sql = ' '.join(sql.split())\n",
        "    \n",
        "    # Fix quote issues - convert double quotes to single quotes for string literals\n",
        "    # This is a simple approach - for more complex cases, you'd need a proper SQL parser\n",
        "    sql = re.sub(r'\"([^\"]*)\"', r\"'\\1'\", sql)\n",
        "    \n",
        "    # Remove multiple semicolons\n",
        "    sql = re.sub(r';+', ';', sql)\n",
        "    \n",
        "    # Remove trailing semicolon and add it back cleanly\n",
        "    sql = sql.rstrip(';').strip()\n",
        "    \n",
        "    # Don't add semicolon for now since it might be causing issues\n",
        "    return sql\n",
        "\n",
        "\n",
        "def analyze_sql_error(error_message: str, sql_query: str, table_schema: str) -> str:\n",
        "    \"\"\"\n",
        "    Analyze SQL error and provide suggestions for fixing the query.\n",
        "    \"\"\"\n",
        "    error_lower = error_message.lower()\n",
        "    \n",
        "    if \"no such column\" in error_lower:\n",
        "        # Extract the problematic column name\n",
        "        column_match = re.search(r'no such column:\\s*(\\w+)', error_lower)\n",
        "        if column_match:\n",
        "            bad_column = column_match.group(1)\n",
        "            \n",
        "            # Try to suggest correct column names from schema\n",
        "            schema_lower = table_schema.lower()\n",
        "            possible_columns = re.findall(r'(\\w+):', schema_lower)\n",
        "            \n",
        "            suggestions = []\n",
        "            for col in possible_columns:\n",
        "                if bad_column.lower() in col.lower() or col.lower() in bad_column.lower():\n",
        "                    suggestions.append(col)\n",
        "            \n",
        "            error_msg = f\"Column '{bad_column}' does not exist.\"\n",
        "            if suggestions:\n",
        "                error_msg += f\" Did you mean: {', '.join(suggestions[:3])}?\"\n",
        "            error_msg += f\"\\n\\nAvailable columns from schema:\\n{table_schema}\"\n",
        "            return error_msg\n",
        "    \n",
        "    elif \"no such table\" in error_lower:\n",
        "        table_match = re.search(r'no such table:\\s*([\\w\\s\\[\\]]+)', error_lower)\n",
        "        if table_match:\n",
        "            bad_table = table_match.group(1).strip()\n",
        "            return f\"Table '{bad_table}' does not exist. Available tables from schema:\\n{table_schema}\"\n",
        "    \n",
        "    elif \"syntax error\" in error_lower:\n",
        "        return f\"SQL syntax error. Please check:\\n- Missing quotes around strings\\n- Proper parentheses\\n- Correct SQL keywords\\n\\nFailed query: {sql_query}\"\n",
        "    \n",
        "    return f\"SQL execution error: {error_message}\\n\\nFailed query: {sql_query}\\n\\nSchema: {table_schema}\"\n",
        "\n",
        "def create_enhanced_prompt(table_schema: str, query_str: str, retry_count: int = 0, error_message: str = \"\"):\n",
        "    if retry_count == 0:\n",
        "        # Initial attempt\n",
        "        ENHANCED_PROMPT = f\"\"\"Given the table schema and user question below, generate ONLY a valid SQL query.\n",
        "\n",
        "            Table Schema:\n",
        "            {table_schema}\n",
        "\n",
        "            User Question: {query_str}\n",
        "\n",
        "            IMPORTANT RULES:\n",
        "            1. Return ONLY the SQL query, nothing else\n",
        "            2. Use single quotes for string literals, not double quotes\n",
        "            3. Do not include any explanations, reasoning, or additional text\n",
        "            4. Do not include labels like \"SQLQuery:\", \"Answer:\", etc.\n",
        "            5. Do not wrap in code blocks or markdown formatting\n",
        "            6. Do not include semicolons at the end\n",
        "            7. Do not include any <think> tags or reasoning\n",
        "            8. Only use column names that exist in the provided schema\n",
        "\n",
        "            Example format:\n",
        "            SELECT column_name FROM table_name WHERE condition\n",
        "\n",
        "            Your SQL query:\n",
        "        \"\"\"\n",
        "    else:\n",
        "        # Retry attempt with error information\n",
        "        ENHANCED_PROMPT = f\"\"\"The previous SQL query failed with an error. Please generate a corrected SQL query.\n",
        "\n",
        "            Table Schema:\n",
        "            {table_schema}\n",
        "\n",
        "            User Question: {query_str}\n",
        "\n",
        "            Previous Error: {error_message}\n",
        "\n",
        "            IMPORTANT RULES:\n",
        "            1. Return ONLY the corrected SQL query, nothing else\n",
        "            2. Use single quotes for string literals, not double quotes\n",
        "            3. Carefully check that all column names exist in the provided schema\n",
        "            4. Do not include any explanations, reasoning, or additional text\n",
        "            5. Do not include labels like \"SQLQuery:\", \"Answer:\", etc.\n",
        "            6. Do not wrap in code blocks or markdown formatting\n",
        "            7. Do not include semicolons at the end\n",
        "            8. Only use column names that are explicitly listed in the schema above\n",
        "\n",
        "            Your corrected SQL query:\n",
        "        \"\"\"\n",
        "    \n",
        "    return ENHANCED_PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "474b321c",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Text2SQLWorkflow(Workflow):\n",
        "    \n",
        "    @step\n",
        "    async def input_step(self, ev: StartEvent) -> TableRetrievedEvent:\n",
        "        \"\"\"Process the initial query and retrieve relevant tables\"\"\"\n",
        "        query = ev.query\n",
        "        \n",
        "        # Retrieve table schemas (you'll need to define obj_retriever)\n",
        "        table_schema_objs = obj_retriever.retrieve(query)\n",
        "        \n",
        "        return TableRetrievedEvent(\n",
        "            tables=table_schema_objs,\n",
        "            query_str=query\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def table_output_parser_step(self, ev: TableRetrievedEvent) -> SchemaProcessedEvent:\n",
        "        \"\"\"Parse table schemas into string format\"\"\"\n",
        "        # You'll need to define get_table_context_str function\n",
        "        schema_str = get_table_context_str(ev.tables)\n",
        "        \n",
        "        return SchemaProcessedEvent(\n",
        "            table_schema=schema_str,\n",
        "            query_str=ev.query_str\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def text2sql_prompt_step(self, ev: SchemaProcessedEvent | SQLResultsEvent) -> SQLPromptReadyEvent:\n",
        "        \"\"\"Create the text-to-SQL prompt with optional error correction\"\"\"\n",
        "        \n",
        "        # Handle both initial attempt and retry attempts\n",
        "        if isinstance(ev, SchemaProcessedEvent):\n",
        "            table_schema = ev.table_schema\n",
        "            query_str = ev.query_str\n",
        "            retry_count = 0\n",
        "            error_message = \"\"\n",
        "        else:  # SQLResultsEvent (retry case)\n",
        "            table_schema = getattr(ev, 'table_schema', '')\n",
        "            query_str = ev.query_str\n",
        "            retry_count = getattr(ev, 'retry_count', 0) + 1\n",
        "            error_message = getattr(ev, 'error_message', '')\n",
        "        \n",
        "        prompt = create_enhanced_prompt(table_schema, query_str, retry_count, error_message)\n",
        "        \n",
        "        return SQLPromptReadyEvent(\n",
        "            t2s_prompt=prompt,\n",
        "            query_str=query_str,\n",
        "            table_schema=table_schema,\n",
        "            retry_count=retry_count,\n",
        "            error_message=error_message\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def text2sql_llm_step(self, ev: SQLPromptReadyEvent) -> SQLGeneratedEvent:\n",
        "        \"\"\"Generate SQL query using LLM\"\"\"\n",
        "        # You'll need to configure Settings.llm\n",
        "        sql_response = await Settings.llm.acomplete(ev.t2s_prompt)\n",
        "        \n",
        "        return SQLGeneratedEvent(\n",
        "            sql_query=str(sql_response).strip(),\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=ev.table_schema,\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=ev.error_message\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def sql_output_parser_step(self, ev: SQLGeneratedEvent) -> SQLParsedEvent:\n",
        "        \"\"\"Parse and clean the generated SQL query\"\"\"\n",
        "        # Extract clean SQL from the LLM response\n",
        "        clean_sql = extract_sql_from_response(ev.sql_query)\n",
        "        \n",
        "        print(f\"Attempt #{ev.retry_count + 1}\")\n",
        "        print(f\"Original LLM Response: {ev.sql_query}\")\n",
        "        print(f\"Cleaned SQL Query: {clean_sql}\")\n",
        "        \n",
        "        # Validate that we have a reasonable SQL query\n",
        "        if not clean_sql or clean_sql == \"SELECT 1\":\n",
        "            print(\"Warning: Could not extract valid SQL, using fallback\")\n",
        "        \n",
        "        return SQLParsedEvent(\n",
        "            sql_query=clean_sql,\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=ev.table_schema,\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=ev.error_message\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def sql_retriever_step(self, ev: SQLParsedEvent) -> SQLResultsEvent:\n",
        "        \"\"\"Execute SQL query and get results with retry logic\"\"\"\n",
        "        max_retries = 3\n",
        "        \n",
        "        try:\n",
        "            # You'll need to define sql_retriever\n",
        "            results = sql_retriever.retrieve(ev.sql_query)\n",
        "            \n",
        "            print(f\"[SUCCESS] SQL executed successfully on attempt #{ev.retry_count + 1}\")\n",
        "            return SQLResultsEvent(\n",
        "                context_str=str(results),\n",
        "                sql_query=ev.sql_query,\n",
        "                query_str=ev.query_str,\n",
        "                success=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            error_msg = str(e)\n",
        "            print(f\"[ERROR] SQL Execution Error (Attempt #{ev.retry_count + 1}): {error_msg}\")\n",
        "            print(f\"Failed SQL Query: {ev.sql_query}\")\n",
        "            \n",
        "            # Check if we should retry\n",
        "            if ev.retry_count < max_retries:\n",
        "                print(f\"[RETRY] Retrying... (Attempt #{ev.retry_count + 2}/{max_retries + 1})\")\n",
        "                \n",
        "                # Create a new event that will trigger a retry\n",
        "                error_analysis = analyze_sql_error(error_msg, ev.sql_query, ev.table_schema)\n",
        "                \n",
        "                # Return an SQLResultsEvent that will trigger a retry\n",
        "                retry_event = SQLResultsEvent(\n",
        "                    context_str=\"\",\n",
        "                    sql_query=ev.sql_query,\n",
        "                    query_str=ev.query_str,\n",
        "                    success=False\n",
        "                )\n",
        "                retry_event.retry_count = ev.retry_count + 1\n",
        "                retry_event.error_message = error_analysis\n",
        "                retry_event.table_schema = ev.table_schema\n",
        "                \n",
        "                return retry_event\n",
        "            else:\n",
        "                print(f\"[ERROR, RETRY FAILED] Max retries ({max_retries}) reached. Giving up.\")\n",
        "                return SQLResultsEvent(\n",
        "                    context_str=f\"Failed to execute SQL after {max_retries + 1} attempts. Final error: {error_msg}\",\n",
        "                    sql_query=ev.sql_query,\n",
        "                    query_str=ev.query_str,\n",
        "                    success=False\n",
        "                )\n",
        "    \n",
        "    @step\n",
        "    async def retry_handler_step(self, ev: SQLResultsEvent) -> SQLPromptReadyEvent:\n",
        "        \"\"\"Handle retry logic - only triggered when SQL execution fails\"\"\"\n",
        "        # This step only processes failed SQL results that need retrying\n",
        "        if ev.success or not hasattr(ev, 'retry_count'):\n",
        "            return None  # Let successful results pass through to response synthesis\n",
        "        \n",
        "        print(f\"[RETRY] Preparing retry #{ev.retry_count + 1}\")\n",
        "        \n",
        "        # Create a new prompt event for retry\n",
        "        return SQLPromptReadyEvent(\n",
        "            t2s_prompt=\"\",  # Will be filled in text2sql_prompt_step\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=getattr(ev, 'table_schema', ''),\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=getattr(ev, 'error_message', 'Unknown error')\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def response_synthesis_prompt_step(self, ev: SQLResultsEvent) -> ResponsePromptReadyEvent:\n",
        "        \"\"\"Create the response synthesis prompt - only for successful SQL results\"\"\"\n",
        "        # Only process successful SQL results\n",
        "        if not ev.success:\n",
        "            return None\n",
        "            \n",
        "        # You'll need to define response_synthesis_prompt template\n",
        "        prompt = response_synthesis_prompt.format(\n",
        "            query_str=ev.query_str,\n",
        "            context_str=ev.context_str,\n",
        "            sql_query=ev.sql_query\n",
        "        )\n",
        "        \n",
        "        return ResponsePromptReadyEvent(rs_prompt=prompt)\n",
        "    \n",
        "    @step\n",
        "    async def response_synthesis_llm_step(self, ev: ResponsePromptReadyEvent) -> StopEvent:\n",
        "        \"\"\"Generate final answer using LLM\"\"\"\n",
        "        answer = await Settings.llm.acomplete(ev.rs_prompt)\n",
        "        \n",
        "        return StopEvent(result=str(answer))\n",
        "\n",
        "\n",
        "async def run_text2sql_workflow(query: str):\n",
        "    workflow = Text2SQLWorkflow(timeout=240)\n",
        "    result = await workflow.run(query=query)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e250a417-42c3-49c2-a037-a282974d5f9a",
      "metadata": {
        "id": "e250a417-42c3-49c2-a037-a282974d5f9a"
      },
      "source": [
        "### Visualize Workflow\n",
        "\n",
        "A really nice property of the query pipeline syntax is you can easily visualize it in a graph via networkx."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5f419c-c128-4b04-b18f-0f8b671ff3a4",
      "metadata": {
        "id": "8c5f419c-c128-4b04-b18f-0f8b671ff3a4",
        "outputId": "713e82d3-ddae-4a41-bd65-0cfd802eae9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved text2sql_dag.html successfully.\n"
          ]
        }
      ],
      "source": [
        "# # Build a directed graph of steps\n",
        "# G = nx.DiGraph()\n",
        "\n",
        "# # Nodes\n",
        "# steps = [\n",
        "#     \"input\",\n",
        "#     \"table_retriever\",\n",
        "#     \"table_output_parser\",\n",
        "#     \"text2sql_prompt\",\n",
        "#     \"text2sql_llm\",\n",
        "#     \"sql_output_parser\",\n",
        "#     \"sql_retriever\",\n",
        "#     \"response_synthesis_prompt\",\n",
        "#     \"response_synthesis_llm\"\n",
        "# ]\n",
        "# G.add_nodes_from(steps)\n",
        "\n",
        "# # Edges\n",
        "# edges = [\n",
        "#     (\"input\", \"table_retriever\"),\n",
        "#     (\"table_retriever\", \"table_output_parser\"),\n",
        "    \n",
        "#     (\"input\", \"text2sql_prompt\"),\n",
        "#     (\"table_output_parser\", \"text2sql_prompt\"),\n",
        "\n",
        "#     (\"text2sql_prompt\", \"text2sql_llm\"),\n",
        "#     (\"text2sql_llm\", \"sql_output_parser\"),\n",
        "#     (\"sql_output_parser\", \"sql_retriever\"),\n",
        "    \n",
        "#     (\"sql_output_parser\", \"response_synthesis_prompt\"),\n",
        "#     (\"sql_retriever\", \"response_synthesis_prompt\"),\n",
        "#     (\"input\", \"response_synthesis_prompt\"),\n",
        "    \n",
        "#     (\"response_synthesis_prompt\", \"response_synthesis_llm\")\n",
        "# ]\n",
        "# G.add_edges_from(edges)\n",
        "\n",
        "# # Visualize\n",
        "# net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
        "# net.from_nx(G)\n",
        "\n",
        "# html_content = net.generate_html()\n",
        "# with open(\"../outputs/trials_v1/text2sql_dag.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "#     f.write(html_content)\n",
        "\n",
        "# print(\"Saved text2sql_dag.html successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "c0f9eed9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drawing workflow structure...\n",
            "../outputs/trials_v1\\fixed_text2sql_workflow_structure.html\n",
            "[SUCCESS] Workflow structure saved to: ../outputs/trials_v1\\fixed_text2sql_workflow_structure.html\n"
          ]
        }
      ],
      "source": [
        "async def visualize_text2sql_workflow():\n",
        "    \"\"\"\n",
        "    Function to visualize the Text2SQL workflow both as all possible flows\n",
        "    and a specific execution example\n",
        "    \"\"\"\n",
        "    output_dir = (\"../outputs/trials_v1\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # 1. Draw ALL possible flows through your workflow\n",
        "    print(\"Drawing all possible flows...\")\n",
        "    all_flows_path = os.path.join(output_dir, \"text2sql_workflow_all_flows.html\")\n",
        "    draw_all_possible_flows(\n",
        "        Text2SQLWorkflow, \n",
        "        filename=all_flows_path\n",
        "    )\n",
        "    print(f\"[SUCCESS] All possible flows saved to: {all_flows_path}\")\n",
        "\n",
        "    # 2. Draw a specific execution to see the actual path taken\n",
        "    print(\"Running workflow and drawing execution path...\")\n",
        "    \n",
        "    # Create workflow instance\n",
        "    workflow = Text2SQLWorkflow(timeout=240)\n",
        "    \n",
        "    # Run with a sample query\n",
        "    sample_query = \"What are the top 5 customers by total orders?\"\n",
        "    \n",
        "    try:\n",
        "        # Execute the workflow\n",
        "        result = await workflow.run(query=sample_query)\n",
        "        \n",
        "        # Draw the execution path\n",
        "        execution_path = os.path.join(output_dir, \"text2sql_workflow_recent_execution.html\")\n",
        "        draw_most_recent_execution(\n",
        "            workflow,\n",
        "            filename=execution_path\n",
        "        )\n",
        "        print(f\"[SUCCESS] Recent execution path saved to: {execution_path}\")\n",
        "        print(f\"Workflow result: {result}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Error during workflow execution: {e}\")\n",
        "        print(\"Note: You may need to set up your retriever and LLM settings first\")\n",
        "\n",
        "# Alternative: Just visualize all flows without execution\n",
        "def visualize_workflow_structure_only():\n",
        "    \"\"\"\n",
        "    Just visualize the workflow structure without executing it\n",
        "    \"\"\"\n",
        "    output_dir = \"../outputs/trials_v1\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    structure_path = os.path.join(output_dir, \"fixed_text2sql_workflow_structure.html\")\n",
        "    print(\"Drawing workflow structure...\")\n",
        "    draw_all_possible_flows(\n",
        "        Text2SQLWorkflow,\n",
        "        filename=structure_path\n",
        "    )\n",
        "    print(f\"[SUCCESS] Workflow structure saved to: {structure_path}\")\n",
        "\n",
        "\n",
        "# Option 1: Just structure\n",
        "visualize_workflow_structure_only()\n",
        "\n",
        "# Option 2: Full visualization with execution\n",
        "# asyncio.run(visualize_text2sql_workflow())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b525ef9b-cb94-401e-8fd8-47c94eb3eaa5",
      "metadata": {
        "id": "b525ef9b-cb94-401e-8fd8-47c94eb3eaa5"
      },
      "source": [
        "### Run Some Queries!\n",
        "\n",
        "Now we're ready to run some queries across this entire pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "f95196c7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table: table_name='people_info' context_str=\"Summary of information about artists' years of signing and album releases\", Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='grammy_awards' context_str='Summary of Grammy Award data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='drop_event_data' context_str='Summary of historical drop event data over time', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='award_data_1972' context_str='Summary of awards in 1972', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='movie_data' context_str='Summary of movie data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n"
          ]
        }
      ],
      "source": [
        "tables = obj_retriever.retrieve(\"What was the year that The Notorious B.I.G was signed to Bad Boy?\")\n",
        "for table in tables:\n",
        "    print(f\"Table: {table}, Type: {type(table)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "0c0d9411",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user is asking for the year that The Notorious B.I.G was signed to Bad Boy. So first, I need to figure out which tables can provide this information.\n",
            "\n",
            "The table 'people_info' has columns Act, Year_signed, and others. The user is asking about the year of signing, so maybe that's the relevant column. The 'grammy_awards' table has Year, but that's for Grammy awards. The question is about the year the artist was signed, not their awards. So probably the people_info table is the right one.\n",
            "\n",
            "Looking at the schema, the people_info table has Year_signed as a column. So the query should select Year_signed from people_info where Act is 'The Notorious B.I.G'. But wait, does the people_info table have the artist's name stored? The problem says the user question is about the year the artist was signed, so the Act column would contain the artist's name. So the SQL query would be SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G';\n",
            "\n",
            "Wait, but the table description says 'Summary of information about artists' years of signing and album releases'. So the people_info table's Year_signed is the year the artist signed, so that's correct. The other tables are for different data, like Grammy awards or drop events. So the answer is selecting that column from people_info with the correct artist name.\n",
            "</think>\n",
            "\n",
            "SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G';\n",
            "Cleaned SQL Query: SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G'\n",
            "[SUCCESS] SQL executed successfully on attempt #1\n",
            "<think>\n",
            "Okay, let's see. The user asked, \"What was the year that The Notorious B.I.G was signed to Bad Boy?\" and provided a SQL query that selects the Year_signed from the people_info table where the Act is 'The Notorious B.I.G'. The SQL response gives a result with the year 1993.\n",
            "\n",
            "Wait, so the SQL query is straightforward. It's a SELECT statement that filters by the Act and returns the Year_signed. The result from the query is a list with a single entry, which is 1993. So the answer should be 1993. The user probably wants that specific number, so I just need to state the year clearly.\n",
            "</think>\n",
            "\n",
            "The Notorious B.I.G was signed to Bad Boy in the year 1993.\n"
          ]
        }
      ],
      "source": [
        "result = await run_text2sql_workflow(\"What was the year that The Notorious B.I.G was signed to Bad Boy?\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "8b6d6881",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table: table_name='award_nominations' context_str='Summary of award data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='award_data_1972' context_str='Summary of awards in 1972', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='grammy_awards' context_str='Summary of Grammy Award data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='award_data' context_str='Summary of awards data across categories and years', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='movie_data' context_str='Summary of movie data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n"
          ]
        }
      ],
      "source": [
        "tables = obj_retriever.retrieve(\"Who won best director in the 1972 academy awards?\")\n",
        "for table in tables:\n",
        "    print(f\"Table: {table}, Type: {type(table)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "89dfbb01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user wants to know who won best director in the 1972 academy awards. First, I need to figure out which tables contain the relevant information.\n",
            "\n",
            "Looking at the tables provided: there's 'award_data_1972' which has columns like Award, Category, Nominee, Result. The user is asking about the 1972 academy awards, so maybe the 'award_data_1972' table is the right one. The 'award_data' table has Year, Award, Category, Nominated_work, Result. But the user is asking about best director, which might be a specific category. Wait, the 'award_data_1972' has 'Category' as a column. So, if the category is 'Best Director', then we can join with 'award_data_1972' to find the nominee.\n",
            "\n",
            "But the user's question is about the 1972 academy awards, which probably refers to the 'award_data_1972' table. So the SQL query should select the Nominee from that table where the Category matches 'Best Director' and the Year is 1972. Also, need to check if there's any other tables involved, but the user's question is directly about 1972, so probably just that table.\n",
            "\n",
            "So the SQL query would be SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Category = 'Best Director'; but wait, the example shows using a table name with quotes. Also, the user's example uses SELECT column_name FROM table_name WHERE condition. So the correct query would be as above.\n",
            "\n",
            "Wait, but the problem says to generate only a valid SQL query. So the answer should be that query. Let me double-check if there's another table. The 'grammy_awards' table also has awards, but the user is specifically asking about academy awards, so probably not needed. The 'movie_data' table is about movies, not awards. So yes, the correct query is as I mentioned.\n",
            "</think>\n",
            "\n",
            "SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Category = 'Best Director';\n",
            "Cleaned SQL Query: SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Category = 'Best Director'\n",
            "[ERROR] SQL Execution Error (Attempt #1): Statement \"SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Category = 'Best Director'\" is invalid SQL.\n",
            "Error: no such column: Year\n",
            "Failed SQL Query: SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Category = 'Best Director'\n",
            "[RETRY] Retrying... (Attempt #2/4)\n",
            "[RETRY] Preparing retry #2\n",
            "Attempt #3\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user wants to know who won the best director in the 1972 academy awards. The previous error was that column 'year' doesn't exist, so I need to check which table contains the data.\n",
            "\n",
            "Looking at the available tables, there's 'award_data_1972' which has columns like Award, Category, Nominee, Result. The user is asking about the 1972 academy awards, so that table seems relevant. The Nominee column would probably hold the winner's name. So the correct SQL query should select the Nominee from 'award_data_1972' where the Year is 1972. Also, need to make sure that the column names are as specified in the schema, and that there are no other columns to consider. The other tables don't seem related to the question. So the corrected query should be a simple SELECT with the appropriate fields and where clause.\n",
            "</think>\n",
            "\n",
            "SELECT Nominee FROM award_data_1972 WHERE Year = 1972;\n",
            "Cleaned SQL Query: SELECT Nominee FROM award_data_1972 WHERE Year = 1972\n",
            "[ERROR] SQL Execution Error (Attempt #3): Statement 'SELECT Nominee FROM award_data_1972 WHERE Year = 1972' is invalid SQL.\n",
            "Error: no such column: Year\n",
            "Failed SQL Query: SELECT Nominee FROM award_data_1972 WHERE Year = 1972\n",
            "[RETRY] Retrying... (Attempt #4/4)\n",
            "[RETRY] Preparing retry #4\n",
            "Warning: Could not extract SQL from response: The problem statement typically includes the following components:  \n",
            "\n",
            "1. **Problem Description**: Cl...\n",
            "Attempt #2\n",
            "Original LLM Response: <think>\n",
            "Okay, the user is asking me to explain the problem statement in the context of the given query. Let me start by understanding the problem. The query is about explaining the problem statement, and the user is probably looking for a clear breakdown of the problem.\n",
            "\n",
            "First, I need to identify the key components of the problem statement. Typically, it includes the problem itself, the context, the problem's goal, and the problem's constraints. Let me check if the user provided all these elements. The original query mentions a problem statement, context, goal, and constraints. So I should structure the explanation around these points.\n",
            "\n",
            "Next, I should ensure that the explanation is accurate and covers all necessary details. It's important to explain each element clearly without being too technical. Also, I need to make sure the language is straightforward and easy to understand. Finally, I'll review the explanation to confirm that it addresses all parts of the problem statement as requested.\n",
            "</think>\n",
            "\n",
            "The problem statement typically includes the following components:  \n",
            "\n",
            "1. **Problem Description**: Clearly describe the issue or challenge.  \n",
            "2. **Context**: Provide background or setting in which the problem exists.  \n",
            "3. **Goal**: Outline the objective or outcome the problem aims to achieve.  \n",
            "4. **Constraints**: Identify limitations or requirements that must be respected.  \n",
            "\n",
            "For example, if the problem is about optimizing a system, the explanation would detail the systemâ€™s current state, the goal (e.g., minimize cost), and any constraints (e.g., budget limits or performance thresholds).  \n",
            "\n",
            "Let me know if you'd like to refine this explanation further!\n",
            "Cleaned SQL Query: SELECT 1\n",
            "Warning: Could not extract valid SQL, using fallback\n",
            "[SUCCESS] SQL executed successfully on attempt #2\n",
            "Attempt #5\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user wants to find out who won the best director in the 1972 academy awards. The previous error was about the column 'year' not existing. So first, I need to figure out how to connect these tables.\n",
            "\n",
            "The user's question is about the 1972 Academy Awards. Looking at the tables, there's a table called 'award_data_1972' which seems to have that information. The columns there include 'Award', 'Category', 'Nominee', 'Result'. The user's question is about the best director, so the 'Nominee' column probably holds the winner. \n",
            "\n",
            "Wait, the available columns from the schema include 'Award' in 'award_data_1972', so I can use that. The 'Nominee' column in that table would correspond to the person who won. So the SQL query should select the Nominee from 'award_data_1972' where the Year is 1972 and the Award is 'best director'. \n",
            "\n",
            "But wait, the tables mentioned in the schema for Grammy awards and others have different years. But the user's question is about 1972, so I need to make sure that the correct table is used. Also, the 'award_data_1972' table has the necessary columns. So the corrected SQL should be a SELECT statement from that table with the Year set to 1972 and the Award as 'best director'. \n",
            "\n",
            "I should check if there's any other table involved. The user's question is specifically about Academy Awards, so the correct table is 'award_data_1972'. Therefore, the corrected query is to select the Nominee from that table where the Year is 1972 and the Award is 'best director'.\n",
            "</think>\n",
            "\n",
            "SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Award = 'best director';\n",
            "Cleaned SQL Query: SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Award = 'best director'\n",
            "[ERROR] SQL Execution Error (Attempt #5): Statement \"SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Award = 'best director'\" is invalid SQL.\n",
            "Error: no such column: Year\n",
            "Failed SQL Query: SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Award = 'best director'\n",
            "[ERROR, RETRY FAILED] Max retries (3) reached. Giving up.\n",
            "Warning: Could not extract SQL from response: \"I want to say something.\"...\n",
            "Attempt #4\n",
            "Original LLM Response: <think>\n",
            "Okay, the user is asking me to translate a sentence. Let me check the sentence they provided. The user wrote \"I want to say something.\" So the task is to translate that into another language. First, I need to ensure that the translation is accurate and that the language is correctly understood. Since there's no specific language mentioned, I should assume the user wants the translation in English. But maybe they want it in another language, like French or Spanish. However, the user just wrote \"I want to say something,\" so maybe they just need the translation in English. Alternatively, they might be testing if I can handle any language. Wait, the initial message says \"Please translate the sentence into another language.\" But the user's query is just \"I want to say something,\" so maybe they provided the sentence and want it translated. Let me confirm. Yes, the user wrote \"I want to say something\" as the input, so the task is to translate that sentence. The assistant's response should be the translation. Since there's no specific language, I'll proceed with English. But perhaps the user expects a different language. Let me make sure. The user's instructions are clear: translate the sentence. So the answer should be the translation in the chosen language. If there's no language specified, maybe the user expects a general response. Wait, the user's query is in English, so maybe they just need the translation in English. So the answer would be \"I want to say something.\" But maybe they need it in another language. However, without further information, I'll proceed with English. Alternatively, maybe they want the translation in another language. Wait, perhaps I should check if there's a specific language requested. The original query is in English, so the answer should be in English. So the final answer is \"I want to say something.\" But perhaps the user wants a more detailed response. Let me check once more. The user wrote the sentence, so the assistant's response should be the translation. Since there's no specific language, I'll assume English and provide the translation as such.\n",
            "</think>\n",
            "\n",
            "\"I want to say something.\"\n",
            "Cleaned SQL Query: SELECT 1\n",
            "Warning: Could not extract valid SQL, using fallback\n",
            "[SUCCESS] SQL executed successfully on attempt #4\n",
            "Attempt #2\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user provided a table schema and asked for a corrected SQL query to find who won the best director in 1972 Academy Awards.\n",
            "\n",
            "First, I need to check the schema they provided. Wait, the user mentioned the table schema, but in the previous error, there was no schema mentioned. Oh, maybe they included it in the query? Wait, looking back, the user's initial message says \"The previous SQL query failed with an error. Please generate a corrected SQL query.\" and then lists the table schema in their message. So the correct schema is there. But in the previous error, there was no schema. Wait, maybe the user included the schema in their message? Let me check again.\n",
            "\n",
            "The user wrote: \"Table Schema: [...]\". Then in the previous error, there was no error. So the correct schema is provided. So the corrected SQL query should use the columns from that schema. The question is about the best director in 1972 Academy Awards. So the SQL query needs to select from the appropriate table, filter by the year, and select the appropriate column. The error might have been due to missing columns, but since the schema is provided, I can proceed.\n",
            "\n",
            "Wait, the user says to only use column names that exist in the provided schema. So I need to make sure that the columns are correctly listed. For example, if the table is called \"Academy Awards\", the columns might be \"Year\", \"Director\", \"Winner\", etc. So the corrected query would select those columns and filter on the year 1972.\n",
            "\n",
            "So the corrected query would be something like SELECT * FROM Academy Awards WHERE Year = 1972; or similar. But the exact columns depend on the actual schema. Since the user's schema is provided, but in the message, it's just a placeholder, I assume that the columns are properly listed. Therefore, the answer is to write the corrected SQL query using the correct column names from the provided schema.\n",
            "</think>\n",
            "\n",
            "SELECT * FROM Academy Awards WHERE Year = 1972;\n",
            "Cleaned SQL Query: SELECT * FROM Academy Awards WHERE Year = 1972\n",
            "[ERROR] SQL Execution Error (Attempt #2): Statement 'SELECT * FROM Academy Awards WHERE Year = 1972' is invalid SQL.\n",
            "Error: no such table: Academy\n",
            "Failed SQL Query: SELECT * FROM Academy Awards WHERE Year = 1972\n",
            "[RETRY] Retrying... (Attempt #3/4)\n",
            "[RETRY] Preparing retry #3\n",
            "<think>\n",
            "Okay, let me try to figure this out. The user provided a query and an SQL result. The question is asking, \"Who won best director in the 1972 academy awards?\" and the SQL response is a single node with a score of 1. \n",
            "\n",
            "First, I need to understand what the SQL query is doing. The SELECT statement is returning a single result, which is a list with one element. The metadata shows that the score is 1. But the query is about a specific award in 1972, but the SQL response doesn't mention any specific year. Wait, the SQL query is part of an SQL response, so maybe the system is returning the score from the SQL query itself, which is a placeholder. \n",
            "\n",
            "But the user's question is asking for the person who won the 1972 Academy Awards for Best Director. However, the SQL result doesn't provide any information. It seems like there's a problem here. Maybe the SQL query is not correctly structured to retrieve the data. Alternatively, perhaps the system is testing if I can recognize the structure. Since the SQL query is a SELECT 1, which returns a single row with a score, but the actual data isn't available, the answer would be that there's no information to answer the question. \n",
            "\n",
            "Wait, but the user is asking for the answer based on the query results. Since the SQL response is empty, maybe the system expects me to infer that there's no winner and state that. So the answer would be that no one won in 1972, but the SQL result doesn't provide any data. Alternatively, maybe the system is expecting me to use the metadata to find the result. But the metadata shows that the score is 1, which is just a placeholder. Therefore, the answer is that the query doesn't provide information to answer the question, and the SQL result is empty.\n",
            "</think>\n",
            "\n",
            "The query results indicate no specific information about the 1972 Academy Awards for Best Director. The SQL response is empty, suggesting there is no data available to answer the question. Therefore, the answer is that the query does not provide relevant information.\n"
          ]
        }
      ],
      "source": [
        "response_1 = await run_text2sql_workflow(\"Who won best director in the 1972 academy awards?\")\n",
        "print(response_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "0dfffdd6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table: table_name='government_ministers' context_str='Summary of historical government ministers', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='new_municipality_old_municipality_seat' context_str='This table shows entries with the same values in two columns, but the third is unique.', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='people_terms' context_str='Summary of individual term data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='award_data_1972' context_str='Summary of awards in 1972', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='people_info' context_str=\"Summary of information about artists' years of signing and album releases\", Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n"
          ]
        }
      ],
      "source": [
        "tables = obj_retriever.retrieve(\"What was the term of Pasquale Preziosa?\")\n",
        "for table in tables:\n",
        "    print(f\"Table: {table}, Type: {type(table)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "16c87f2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user is asking for the term of Pasquale Preziosa. First, I need to figure out if there's a table that contains information about people, their terms, and maybe some connections.\n",
            "\n",
            "Looking at the tables provided: there's 'people_terms' which has Name, Term_start, Term_end. The question is about Pasquale Preziosa's term. So I need to check if there's a way to link Pasquale Preziosa to the 'people_terms' table.\n",
            "\n",
            "The problem mentions that the 'people_terms' table might be connected to other tables. Wait, the user's question doesn't specify any other tables. The only tables are 'government_ministers', 'new_municipality_old_municipality_seat', 'people_terms', 'award_data_1972', and 'people_info'. \n",
            "\n",
            "But the 'people_terms' table has Name, Term_start, Term_end. If Pasquale Preziosa is a person in 'people_terms', then her term would be in that table. So I need to check if there's a way to link her to the 'people_terms' table. But the user's question doesn't provide any other tables. Wait, maybe there's a connection through another table? But the question says to use the given tables. Unless there's a way to join them, but the problem states to use the given tables. \n",
            "\n",
            "Wait, maybe the answer is simply to select from 'people_terms' where Name is 'Pasquale Preziosa'. But the problem says to generate only a valid SQL query, so maybe that's the case. But the user's question is in the context of a table, but the tables provided don't include Pasquale Preziosa. Unless there's a typo and she's in another table, but the problem states to use the given schemas. \n",
            "\n",
            "Alternatively, perhaps the answer is to check if there's a 'people_terms' entry for her. But since the problem says to use the given tables, and the user's question is about Pasquale Preziosa, maybe the answer is to select her term from the 'people_terms' table. But without knowing her name, how can we get that? Wait, maybe there's a connection through another table. But the problem states to use the given tables. Unless there's a mistake in the problem, but I need to proceed.\n",
            "\n",
            "Wait, the user's question is in the context of the 'people_terms' table. So the answer would be a SELECT query that includes the Name column from 'people_terms' where Term_start or Term_end matches Pasquale Preziosa's data. But since the problem says to generate only a valid SQL query, perhaps the correct approach is to write a SELECT statement that selects Term_start or Term_end from 'people_terms' where Name is 'Pasquale Preziosa'. But the problem is that the user's question is about Pasquale, but the tables don't have her data. Unless there's an error in the question, but I need to proceed.\n",
            "\n",
            "Wait, maybe there's a way to link her to the 'people_terms' table. But perhaps the problem expects that the user knows her name, and the query is straightforward. But given that the problem says to use the provided tables, perhaps there's no other way. So the SQL query would be to select Term_start or Term_end from people_terms where Name is 'Pasquale Preziosa'. Therefore, the answer is to write that query as a single line.\n",
            "</think>\n",
            "\n",
            "SELECT Term_start FROM people_terms WHERE Name = 'Pasquale Preziosa';\n",
            "Cleaned SQL Query: SELECT Term_start FROM people_terms WHERE Name = 'Pasquale Preziosa'\n",
            "[SUCCESS] SQL executed successfully on attempt #1\n",
            "<think>\n",
            "Okay, let's see. The user is asking for the term of Pasquale Preziosa. They provided a SQL query and the response from that query.\n",
            "\n",
            "First, I need to parse the SQL response. The output is a list of terms, and the first term is \"25 February 2013\". So the answer should be that date. The SQL query was executed, and the result has that term. There are no other terms mentioned, so just that one. I should present it clearly in the answer.\n",
            "</think>\n",
            "\n",
            "The term associated with Pasquale Preziosa is **25 February 2013**.\n"
          ]
        }
      ],
      "source": [
        "response_2 = await run_text2sql_workflow(\"What was the term of Pasquale Preziosa?\")\n",
        "print(response_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "96f1ca00",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table: table_name='chart_positions' context_str='Summary of music chart data across countries', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='district_info' context_str='Summary of district data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='movie_chart_positions' context_str='Summary of movie chart positions across different countries', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='broadcasting_info' context_str='Summary of broadcasting data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='bbc_radio_costs' context_str='Summary of BBC Radio service costs compared to 2011.', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n"
          ]
        }
      ],
      "source": [
        "tables = obj_retriever.retrieve(\"Show me total sales by region\")\n",
        "for table in tables:\n",
        "    print(f\"Table: {table}, Type: {type(table)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "2e4461a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let me try to figure out how to answer the user's question. The user wants to show total sales by region. Looking at the tables provided, there's a table called 'chart_positions' which has columns related to chart positions in different countries. Another table is 'Certifications_sales_thresholds_'. Hmm, wait, the user mentioned 'total sales by region', and the chart_positions table has fields like Peak_chart_positions_US (VARCHAR), but I don't see a column for sales yet.\n",
            "\n",
            "Wait, the user's question is about total sales, so maybe there's a connection to the 'Certifications_sales_thresholds_'. Let me check the schema again. Oh, right, the 'chart_positions' table has a column named Certifications_sales_thresholds_ (INTEGER). But how does that relate to total sales? Maybe each entry in the 'chart_positions' table corresponds to a certification, and the sales threshold is a value. But how to aggregate that into total sales by region?\n",
            "\n",
            "Wait, perhaps the 'chart_positions' table has data for each certification, and each certification has a sales threshold. But to get total sales, maybe we need to sum the sales thresholds across all certifications. But the user wants it by region. So maybe the regions are specified in the 'chart_positions' table. Wait, the table has fields like Peak_chart_positions_GER, etc., but no region column. The problem is that the user's question is to show total sales by region, but the available tables don't have a region column. So how can we get that?\n",
            "\n",
            "Wait, maybe the 'chart_positions' table has entries for each country and each certification, and the sales threshold is a value. If I can find a way to sum the sales thresholds for each country and then sum them to get total sales, but the user wants it by region. But without knowing the regions, maybe the answer is to use the 'chart_positions' table and sum the sales thresholds for each country. But the user's question says \"total sales by region\", implying that each region is a country. But the problem is that the user hasn't provided the regions in the schema. Wait, the user's question is to show total sales by region, but the tables don't have a region column. So maybe there's a mistake here? Or perhaps the regions are implied in the 'chart_positions' table?\n",
            "\n",
            "Wait, the user's example uses a table, but in this case, there's no region column. Let me check again. The user's question is to show total sales by region, but the tables don't have a region column. Therefore, perhaps the answer is to use the 'chart_positions' table and sum the sales thresholds for each country, but since there's no region, maybe the user made a mistake in the schema, or perhaps I'm missing something.\n",
            "\n",
            "Alternatively, maybe the 'Certifications_sales_thresholds_' column is the sales threshold, and there's a way to aggregate by region. But since the user hasn't specified regions, perhaps there's an error in the question. However, the user's example format shows using a table, but in this case, there's no region. Maybe the answer is to use the 'chart_positions' table and sum the sales thresholds, but the user's question is to show by region, which might require joining with 'district_info' or another table. But the provided tables don't include a region column. So perhaps the correct approach is to use the 'chart_positions' table and sum the Certifications_sales_thresholds_ column, but that doesn't make sense. Alternatively, maybe the 'chart_positions' table has data for each country and each certification, and the sales threshold is a value. But how to sum by region? Unless the regions are already in the 'chart_positions' table, but the user didn't specify that.\n",
            "\n",
            "Wait, the user's question is to show total sales by region. Maybe 'region' refers to the country in the chart_positions table. But since there's no region column, perhaps the answer is to use the 'chart_positions' table and sum the Certifications_sales_thresholds_ for each country, but without knowing the regions, maybe the answer is to use the 'chart_positions' table and sum the sales threshold for each country, but the user's question is ambiguous. Since the example uses a table, perhaps the intended answer is to use the 'chart_positions' table and sum the sales threshold, but I'm not sure. Alternatively, maybe the 'chart_positions' table has data for each country, and the sales threshold is part of the data. But without knowing the regions, perhaps the answer is to use the 'chart_positions' table and sum the thresholds, but that's not clear.\n",
            "\n",
            "Wait, maybe the 'chart_positions' table has entries for each region, but the user hasn't provided that. Since the user's question is to show total sales by region, but the available tables don't have a region column, perhaps there's a mistake in the problem setup. However, the user's instruction says to generate only a valid SQL query, so maybe there's a way. Let me think again.\n",
            "\n",
            "If the user wants total sales by region, and the table 'chart_positions' has Certifications_sales_thresholds_ (INTEGER), perhaps each entry corresponds to a region. But since there's no region column, maybe the answer is to use the 'chart_positions' table and sum the threshold for each country, but without knowing the regions, perhaps the query is to sum all the thresholds from the 'chart_positions' table. However, the user's question explicitly says to show total sales by region, which suggests that each region is a country, and the sales threshold is per region. But since there's no region column, maybe the answer is to sum all the thresholds from the 'chart_positions' table. But that's not clear. Alternatively, maybe there's a mistake in the schema, and the regions are implied by the other tables. For example, in 'district_info', there's Population (VARCHAR), but not sure. Since the user's example uses a table, perhaps the intended answer is to use the 'chart_positions' table and sum the Certifications_sales_thresholds_ for each country, but without knowing the regions, maybe the answer is to sum all the thresholds. But I'm not sure. Given the information, perhaps the correct SQL query is to sum the Certifications_sales_thresholds_ column from the 'chart_positions' table. However, the user's question is to show total sales by region, which might mean to use the 'chart_positions' table and sum by region, but since there's no region, perhaps the answer is as follows.\n",
            "\n",
            "Wait, maybe the user intended to use the 'chart_positions' table and the 'Certifications_sales_thresholds_' column. If each entry corresponds to a region, then the total sales by region would be the sum of all Certifications_sales_thresholds_ for each country. So the query would be to sum those values. But without knowing the regions, perhaps the query is to sum the threshold. But the user's question is to show total sales by region, which suggests that each region is a country, and the sales threshold is per country. But since there's no region column, maybe the answer is to sum all the sales thresholds from the 'chart_positions' table. Therefore, the SQL query would be:\n",
            "\n",
            "SELECT SUM(Certifications_sales_thresholds_) FROM chart_positions;\n",
            "\n",
            "But the user's question is to show total sales by region, which might require joining with other tables, but given the information, perhaps this is the intended answer. However, I'm not sure. Alternatively, maybe the regions are in the 'chart_positions' table, but the user hasn't specified them. Since the user's example uses a table, perhaps the answer is to sum the thresholds, but the user's question is about regions. This is a bit confusing. Given the constraints, I'll proceed with the sum of the Certifications_sales_thresholds_ from the 'chart_positions' table, assuming that each entry corresponds to a region.\n",
            "</think>\n",
            "\n",
            "SELECT SUM(Certifications_sales_thresholds_) FROM chart_positions;\n",
            "Cleaned SQL Query: SELECT SUM(Certifications_sales_thresholds_) FROM chart_positions\n",
            "[SUCCESS] SQL executed successfully on attempt #1\n",
            "<think>\n",
            "Okay, let me try to figure this out. The user asked to show total sales by region, and there's an SQL query provided. The SQL is SELECT SUM(Certifications_sales_thresholds_) FROM chart_positions. The response from the SQL is a node with a score, and the content is [(None,)]. \n",
            "\n",
            "Hmm, so the SQL is a SELECT statement that sums the 'Certifications_sales_thresholds_' column from the 'chart_positions' table. The result is an empty list, which probably means that the query didn't find any records, or perhaps there's no data to sum. The score is None, which might indicate that the query wasn't successful.\n",
            "\n",
            "So the user wants total sales by region, but the SQL doesn't have any data. The response from the SQL tells us that the query returned nothing. Therefore, the total sales by region might be zero, or there's no data available. The answer should clarify that there's no sales data available and perhaps mention that the query didn't find any records.\n",
            "</think>\n",
            "\n",
            "There is no available data to calculate sales by region based on the provided SQL query. The query returns an empty list, indicating no records were found in the 'chart_positions' table. If sales data is available, it would be summed across regions, but currently, this information is not accessible.\n"
          ]
        }
      ],
      "source": [
        "response_3 = await run_text2sql_workflow(\"Show me total sales by region\")\n",
        "print(response_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9acab5f",
      "metadata": {},
      "source": [
        "# FINAL SCORE: 2/4 \n",
        "\n",
        "## -> Problem: Column names aren't getting specified properly"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
