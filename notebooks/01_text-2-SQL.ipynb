{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "855f9f50-ef38-4069-932a-fb49af02d28e",
      "metadata": {
        "id": "855f9f50-ef38-4069-932a-fb49af02d28e"
      },
      "source": [
        "# Query Pipeline for Advanced Text-to-SQL\n",
        "\n",
        "In this guide we show you how to setup a text-to-SQL pipeline over your data with our [query pipeline](https://docs.llamaindex.ai/en/stable/module_guides/querying/pipeline/root.html) syntax.\n",
        "\n",
        "This gives you flexibility to enhance text-to-SQL with additional techniques. We show these in the below sections:\n",
        "1. **Query-Time Table Retrieval**: Dynamically retrieve relevant tables in the text-to-SQL prompt.\n",
        "2. **Query-Time Sample Row retrieval**: Embed/Index each row, and dynamically retrieve example rows for each table in the text-to-SQL prompt.\n",
        "\n",
        "Our out-of-the box pipelines include our `NLSQLTableQueryEngine` and `SQLTableRetrieverQueryEngine`. (if you want to check out our text-to-SQL guide using these modules, take a look [here](https://docs.llamaindex.ai/en/stable/examples/index_structs/struct_indices/SQLIndexDemo.html)). This guide implements an advanced version of those modules, giving you the utmost flexibility to apply this to your own setting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e39cc96c-9fbc-44c3-b57f-017a9aa75473",
      "metadata": {
        "id": "e39cc96c-9fbc-44c3-b57f-017a9aa75473"
      },
      "source": [
        "## Load and Ingest Data\n",
        "\n",
        "\n",
        "### Load Data\n",
        "We use the [WikiTableQuestions dataset](https://ppasupat.github.io/WikiTableQuestions/) (Pasupat and Liang 2015) as our test dataset.\n",
        "\n",
        "We go through all the csv's in one folder, store each in a sqlite database (we will then build an object index over each table schema)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc8cd21",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import io, os, time, re, requests, zipfile, json\n",
        "import json as pyjson\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# put data into sqlite db\n",
        "from sqlalchemy import (\n",
        "    create_engine,\n",
        "    MetaData,\n",
        "    Table,\n",
        "    Column,\n",
        "    String,\n",
        "    Integer,\n",
        ")\n",
        "\n",
        "# setup Arize Phoenix for logging/observability\n",
        "import phoenix as px\n",
        "\n",
        "from llama_index.core import (\n",
        "    Settings,\n",
        "    load_index_from_storage,\n",
        "    set_global_handler,\n",
        "    SQLDatabase,\n",
        "    VectorStoreIndex,\n",
        ")\n",
        "from llama_index.core.objects import (\n",
        "    SQLTableNodeMapping,\n",
        "    ObjectIndex,\n",
        "    SQLTableSchema,\n",
        ")\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "from llama_index.llms.ollama import Ollama\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.retrievers import SQLRetriever\n",
        "from llama_index.core.prompts.default_prompts import DEFAULT_TEXT_TO_SQL_PROMPT\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.llms import ChatResponse\n",
        "from llama_index.core.workflow import Workflow, step, StartEvent, StopEvent\n",
        "from llama_index.core.workflow.events import Event\n",
        "from llama_index.utils.workflow import (\n",
        "    draw_all_possible_flows,\n",
        "    draw_most_recent_execution,\n",
        ")\n",
        "\n",
        "# import networkx as nx\n",
        "# from pyvis.network import Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cadfb28c",
      "metadata": {},
      "outputs": [],
      "source": [
        "URL = \"https://github.com/ppasupat/WikiTableQuestions/releases/download/v1.0.2/WikiTableQuestions-1.0.2-compact.zip\"\n",
        "\n",
        "OUTPUT_DIR = \"../data\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Downloading...\")\n",
        "response = requests.get(URL)\n",
        "response.raise_for_status()\n",
        "\n",
        "print(\"Extracting...\")\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "    z.extractall(OUTPUT_DIR)\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5a710f7a-74b4-48c3-98d1-a6d409a7af1a",
      "metadata": {
        "id": "5a710f7a-74b4-48c3-98d1-a6d409a7af1a",
        "outputId": "fb840754-8360-459d-fe4b-bbe92b24475e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\0.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\1.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\10.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\11.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\12.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\14.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\15.csv\n",
            "Error parsing ..\\data\\WikiTableQuestions\\csv\\200-csv\\15.csv: Error tokenizing data. C error: Expected 4 fields in line 16, saw 5\n",
            "\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\17.csv\n",
            "Error parsing ..\\data\\WikiTableQuestions\\csv\\200-csv\\17.csv: Error tokenizing data. C error: Expected 6 fields in line 5, saw 7\n",
            "\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\18.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\20.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\22.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\24.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\25.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\26.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\28.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\29.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\3.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\30.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\31.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\32.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\33.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\34.csv\n",
            "Error parsing ..\\data\\WikiTableQuestions\\csv\\200-csv\\34.csv: Error tokenizing data. C error: Expected 4 fields in line 6, saw 13\n",
            "\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\35.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\36.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\37.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\38.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\4.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\41.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\42.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\44.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\45.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\46.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\47.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\48.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\7.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\8.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\9.csv\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = Path(\"../data/WikiTableQuestions/csv/200-csv\")\n",
        "CSV_FILES = sorted([f for f in DATA_DIR.glob(\"*.csv\")])\n",
        "dfs = []\n",
        "\n",
        "for csv_file in CSV_FILES:\n",
        "    print(f\"processing file: {csv_file}\")\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        dfs.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {csv_file}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c271b986-9ed6-4a8a-a7c2-1dad7a642c06",
      "metadata": {
        "id": "c271b986-9ed6-4a8a-a7c2-1dad7a642c06"
      },
      "source": [
        "### Extract Table Name and Summary from each Table\n",
        "\n",
        "Here we use gpt-3.5 to extract a table name (with underscores) and summary from each table with our Pydantic program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4cef9585-87f8-4427-aaca-c0038c289e00",
      "metadata": {
        "id": "4cef9585-87f8-4427-aaca-c0038c289e00",
        "outputId": "03b3f4e4-93cf-4125-b745-a5f190208bbf"
      },
      "outputs": [],
      "source": [
        "TABLEINFO_DIR = \"../data/WikiTableQuestions_TableInfo\"\n",
        "os.makedirs(TABLEINFO_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9a81afbf-0870-41b1-baea-017026a1b7d6",
      "metadata": {
        "id": "9a81afbf-0870-41b1-baea-017026a1b7d6"
      },
      "outputs": [],
      "source": [
        "class TableInfo(BaseModel):\n",
        "    \"\"\"Information regarding a structured table.\"\"\"\n",
        "\n",
        "    table_name: str = Field(\n",
        "        ..., description=\"table name (must be underscores and NO spaces)\"\n",
        "    )\n",
        "    table_summary: str = Field(\n",
        "        ..., description=\"short, concise summary/caption of the table\"\n",
        "    )\n",
        "\n",
        "PROMPT_STR = \"\"\"\\\n",
        "    Return only a JSON object, with no explanation, no prose, no markdown, and no trailing text.\n",
        "    You are to produce **only** a JSON object matching the following exact schema:\n",
        "\n",
        "    {\n",
        "        \"table_name\": \"<short_name_in_snake_case_without_spaces>\",\n",
        "        \"table_summary\": \"<short concise caption of the table>\"\n",
        "    }\n",
        "\n",
        "    Example:\n",
        "    {\"table_name\": \"movie_info\", \"table_summary\": \"Summary of movie data\"}\n",
        "\n",
        "    Rules:\n",
        "    - The table_name must be unique to the table, describe it clearly, and be in snake_case.\n",
        "    - Do NOT output a generic table name (e.g., \"table\", \"my_table\").\n",
        "    - Do NOT make the table name one of the following: {exclude_table_name_list}.\n",
        "    - Do NOT include any keys other than \"table_name\" and \"table_summary\".\n",
        "    - Do NOT include extra text before/after the JSON.\n",
        "    - Do NOT include any other keys or text before/after the JSON.\n",
        "    - Do NOT wrap in ```json.\n",
        "\n",
        "    Table:\n",
        "    {table_str}\n",
        "\"\"\"\n",
        "\n",
        "Settings.llm = Ollama(\n",
        "    model=\"qwen3:0.6b\", \n",
        "    request_timeout=240,\n",
        "    format=\"json\",\n",
        "    # context_window=1000\n",
        ")\n",
        "\n",
        "program = LLMTextCompletionProgram.from_defaults(\n",
        "    output_cls=TableInfo,\n",
        "    prompt_template_str=PROMPT_STR,\n",
        "    llm=Settings.llm,\n",
        "    # verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "db30f75b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_first_json_block(text: str):\n",
        "    match = re.search(r\"\\{.*\\}\", text, re.S)  # grab first {...} block\n",
        "    if not match:\n",
        "        raise ValueError(\"No JSON object found in output\")\n",
        "    return pyjson.loads(match.group())\n",
        "\n",
        "\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "\n",
        "def _get_tableinfo_with_index(idx: int) -> str:\n",
        "    results_gen = Path(TABLEINFO_DIR).glob(f\"{idx}_*\")\n",
        "    results_list = list(results_gen)\n",
        "    \n",
        "    if len(results_list) == 0:\n",
        "        return None\n",
        "    elif len(results_list) == 1:\n",
        "        path = results_list[0]\n",
        "        json_str = path.read_text(encoding=\"utf-8\")\n",
        "        return TableInfo.model_validate_json(json_str)\n",
        "    else:\n",
        "        raise ValueError(f\"More than one file matching index: {list(results_gen)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f50a3c04-d1fb-4964-8f37-741fb98a5249",
      "metadata": {
        "id": "f50a3c04-d1fb-4964-8f37-741fb98a5249"
      },
      "outputs": [],
      "source": [
        "table_names = set()\n",
        "table_infos = []\n",
        "\n",
        "for idx, df in enumerate(dfs):\n",
        "    table_info = _get_tableinfo_with_index(idx)\n",
        "    if table_info:\n",
        "        table_infos.append(table_info)\n",
        "        continue\n",
        "\n",
        "    df_str = df.head(10).to_csv()\n",
        "\n",
        "    for attempt in range(MAX_RETRIES):\n",
        "        try:\n",
        "            raw_output = program(\n",
        "                table_str=df_str,\n",
        "                exclude_table_name_list=str(list(table_names)),\n",
        "            )\n",
        "\n",
        "            if isinstance(raw_output, TableInfo):\n",
        "                table_info = raw_output\n",
        "            elif isinstance(raw_output, dict):\n",
        "                table_info = TableInfo(**raw_output)\n",
        "            elif isinstance(raw_output, str):\n",
        "                parsed_dict = extract_first_json_block(raw_output)\n",
        "                table_info = TableInfo(**parsed_dict)\n",
        "            else:\n",
        "                raise TypeError(f\"Unexpected return type from program(): {type(raw_output)}\")\n",
        "\n",
        "            table_name = table_info.table_name\n",
        "            print(f\"Processed table: {table_name}\")\n",
        "\n",
        "            if table_name in table_names:\n",
        "                print(f\"Table name '{table_name}' already exists, skipping this table.\")\n",
        "                table_info = None  # don’t append duplicate\n",
        "                break  # skip\n",
        "\n",
        "            # save table info\n",
        "            table_names.add(table_name)\n",
        "            out_file = f\"{TABLEINFO_DIR}/{idx}_{table_name}.json\"\n",
        "            json.dump(table_info.model_dump(), open(out_file, \"w\"))\n",
        "            break  # move to next table\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with attempt {attempt+1}: {e}\")\n",
        "            time.sleep(2)\n",
        "\n",
        "    if table_info:\n",
        "        table_infos.append(table_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e667fde",
      "metadata": {},
      "source": [
        "To retry for a single index (in needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0a8dd7ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# idx = 20\n",
        "# df = dfs[idx]\n",
        "\n",
        "# table_info = _get_tableinfo_with_index(idx)\n",
        "# if table_info:\n",
        "#     table_infos.append(table_info)\n",
        "# else:\n",
        "#     df_str = df.head(20).to_csv()\n",
        "\n",
        "#     for attempt in range(MAX_RETRIES):\n",
        "#         try:\n",
        "#             raw_output = program(\n",
        "#                 table_str=df_str,\n",
        "#                 exclude_table_name_list=str(list(table_names)),\n",
        "#             )\n",
        "\n",
        "#             if isinstance(raw_output, TableInfo):\n",
        "#                 table_info = raw_output\n",
        "#             elif isinstance(raw_output, dict):\n",
        "#                 table_info = TableInfo(**raw_output)\n",
        "#             elif isinstance(raw_output, str):\n",
        "#                 parsed_dict = extract_first_json_block(raw_output)\n",
        "#                 table_info = TableInfo(**parsed_dict)\n",
        "#             else:\n",
        "#                 raise TypeError(f\"Unexpected return type from program(): {type(raw_output)}\")\n",
        "\n",
        "#             table_name = table_info.table_name\n",
        "#             print(f\"Processed table: {table_name}\")\n",
        "\n",
        "#             if table_name in table_names:\n",
        "#                 print(f\"Table name '{table_name}' already exists, skipping this table.\")\n",
        "#                 table_info = None\n",
        "#                 break\n",
        "\n",
        "#             table_names.add(table_name)\n",
        "#             out_file = f\"{TABLEINFO_DIR}/{idx}_{table_name}.json\"\n",
        "#             json.dump(table_info.model_dump(), open(out_file, \"w\"))\n",
        "#             break\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error with attempt {attempt+1}: {e}\")\n",
        "#             time.sleep(2)\n",
        "\n",
        "#     if table_info:\n",
        "#         table_infos.append(table_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1cc3230-d14c-4491-b79f-45159708badb",
      "metadata": {
        "id": "a1cc3230-d14c-4491-b79f-45159708badb"
      },
      "source": [
        "### Put Data in SQL Database\n",
        "\n",
        "We use `sqlalchemy`, a popular SQL database toolkit, to load all the tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "53544059-de7d-48dd-8e00-89517964852b",
      "metadata": {
        "id": "53544059-de7d-48dd-8e00-89517964852b",
        "outputId": "df224651-1765-4aa7-e841-d58546c20e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating table: movie_chart_positions\n",
            "Creating table: movie_data\n",
            "Creating table: death_accident_statistics\n",
            "Creating table: award_data_1972\n",
            "Creating table: award_data\n",
            "Creating table: people_info\n",
            "Creating table: broadcasting_info\n",
            "Creating table: person_info\n",
            "Creating table: chart_positions\n",
            "Creating table: kodachrome_film_info\n",
            "Creating table: bbc_radio_costs\n",
            "Creating table: airport_locations\n",
            "Creating table: party_voters\n",
            "Creating table: club_performance\n",
            "Creating table: horse_race_data\n",
            "Creating table: grammy_awards\n",
            "Creating table: boxing_matches\n",
            "Creating table: sports_performance_data\n",
            "Creating table: district_info\n",
            "Creating table: party_data\n",
            "Creating table: award_nominations\n",
            "Creating table: government_ministers\n",
            "Creating table: new_municipality_old_municipality_seat\n",
            "Creating table: team_performance\n",
            "Creating table: encoding_info\n",
            "Creating table: temperature_data\n",
            "Creating table: people_terms\n",
            "Creating table: new_mexico_governorships\n",
            "Creating table: weather_statistics\n",
            "Creating table: drop_event_data\n",
            "Creating table: precipitation_data\n",
            "Creating table: afrikaans_language_usage\n",
            "Creating table:  ohio_districts\n",
            "Creating table: gene_functions\n"
          ]
        }
      ],
      "source": [
        "# Function to create a sanitized column name\n",
        "def sanitize_column_name(col_name):\n",
        "    # Remove special characters and replace spaces with underscores\n",
        "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
        "\n",
        "\n",
        "# Function to create a table from a DataFrame using SQLAlchemy\n",
        "def create_table_from_dataframe(\n",
        "    df: pd.DataFrame, table_name: str, engine, metadata_obj\n",
        "):\n",
        "    # Sanitize column names\n",
        "    sanitized_columns = {col: sanitize_column_name(col) for col in df.columns}\n",
        "    df = df.rename(columns=sanitized_columns)\n",
        "\n",
        "    # Dynamically create columns based on DataFrame columns and data types\n",
        "    columns = [\n",
        "        Column(col, String if dtype == \"object\" else Integer)\n",
        "        for col, dtype in zip(df.columns, df.dtypes)\n",
        "    ]\n",
        "\n",
        "    # Create a table with the defined columns\n",
        "    table = Table(table_name, metadata_obj, *columns)\n",
        "\n",
        "    # Create the table in the database\n",
        "    metadata_obj.create_all(engine)\n",
        "\n",
        "    # Insert data from DataFrame into the table\n",
        "    with engine.connect() as conn:\n",
        "        for _, row in df.iterrows():\n",
        "            insert_stmt = table.insert().values(**row.to_dict())\n",
        "            conn.execute(insert_stmt)\n",
        "        conn.commit()\n",
        "\n",
        "\n",
        "# engine = create_engine(\"sqlite:///:memory:\")\n",
        "engine = create_engine(\"sqlite:///../sqlite/SQLite_db.db\")\n",
        "metadata_obj = MetaData()\n",
        "for idx, df in enumerate(dfs):\n",
        "    tableinfo = _get_tableinfo_with_index(idx)\n",
        "    if tableinfo is None:\n",
        "        print(f\"[ERROR] No TableInfo for index {idx}\")\n",
        "        continue  # skip this one or handle it differently\n",
        "    print(f\"Creating table: {tableinfo.table_name}\")\n",
        "    create_table_from_dataframe(df, tableinfo.table_name, engine, metadata_obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f12a34b5-1d91-4e85-a6ce-97adb5ddfa06",
      "metadata": {
        "id": "f12a34b5-1d91-4e85-a6ce-97adb5ddfa06",
        "outputId": "4527a7d1-6b5f-4f89-9a63-e5263f4e4441"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
            "  next(self.gen)\n",
            "C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
            "  next(self.gen)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
            "📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\sqlalchemy\\orm\\loading.py:1344: RuntimeWarning: coroutine 'visualize_text2sql_workflow' was never awaited\n",
            "  for key, getter in populators[\"quick\"]:\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "Unknown span: U3Bhbjo0Njc=\n",
            "\n",
            "GraphQL request:4:3\n",
            "3 | ) {\n",
            "4 |   span: node(id: $id) {\n",
            "  |   ^\n",
            "5 |     __typename\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\graphql\\execution\\execute.py\", line 530, in await_result\n",
            "    return_type, field_nodes, info, path, await result\n",
            "                                          ^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\strawberry\\schema\\schema_converter.py\", line 788, in _async_resolver\n",
            "    return await await_maybe(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\strawberry\\utils\\await_maybe.py\", line 13, in await_maybe\n",
            "    return await value\n",
            "           ^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\phoenix\\server\\api\\queries.py\", line 998, in node\n",
            "    raise NotFound(f\"Unknown span: {id}\")\n",
            "phoenix.server.api.exceptions.NotFound: Unknown span: U3Bhbjo0Njc=\n",
            "Unknown span: U3Bhbjo0Njc=\n",
            "\n",
            "GraphQL request:4:3\n",
            "3 | ) {\n",
            "4 |   span: node(id: $id) {\n",
            "  |   ^\n",
            "5 |     __typename\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\graphql\\execution\\execute.py\", line 530, in await_result\n",
            "    return_type, field_nodes, info, path, await result\n",
            "                                          ^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\strawberry\\schema\\schema_converter.py\", line 788, in _async_resolver\n",
            "    return await await_maybe(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\strawberry\\utils\\await_maybe.py\", line 13, in await_maybe\n",
            "    return await value\n",
            "           ^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\phoenix\\server\\api\\queries.py\", line 998, in node\n",
            "    raise NotFound(f\"Unknown span: {id}\")\n",
            "phoenix.server.api.exceptions.NotFound: Unknown span: U3Bhbjo0Njc=\n"
          ]
        }
      ],
      "source": [
        "px.launch_app()\n",
        "set_global_handler(\"arize_phoenix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5906e7-4e20-4b0a-bc42-615f6b86beb7",
      "metadata": {
        "id": "1b5906e7-4e20-4b0a-bc42-615f6b86beb7"
      },
      "source": [
        "## Advanced Capability 1: Text-to-SQL with Query-Time Table Retrieval.\n",
        "\n",
        "We now show you how to setup an e2e text-to-SQL with table retrieval.\n",
        "\n",
        "### Define Modules\n",
        "\n",
        "Here we define the core modules.\n",
        "1. Object index + retriever to store table schemas\n",
        "2. SQLDatabase object to connect to the above tables + SQLRetriever.\n",
        "3. Text-to-SQL Prompt\n",
        "4. Response synthesis Prompt\n",
        "5. LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0830ecca-9688-45b7-b011-d6d44d6fc551",
      "metadata": {
        "id": "0830ecca-9688-45b7-b011-d6d44d6fc551"
      },
      "source": [
        "Object index, retriever, SQLDatabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8a89bc36-a5ac-46bf-b9ae-801f34992019",
      "metadata": {
        "id": "8a89bc36-a5ac-46bf-b9ae-801f34992019"
      },
      "outputs": [],
      "source": [
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "sql_database = SQLDatabase(engine)\n",
        "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
        "\n",
        "table_schema_objs = [\n",
        "    SQLTableSchema(table_name=t.table_name, context_str=t.table_summary)\n",
        "    for t in table_infos\n",
        "]  # add a SQLTableSchema for each table\n",
        "\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    table_schema_objs,\n",
        "    table_node_mapping,\n",
        "    VectorStoreIndex,\n",
        "    embed_model=embed_model,\n",
        ")\n",
        "obj_retriever = obj_index.as_retriever(similarity_top_k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4620fbe4-eac6-4476-b373-0e48dfbd81e0",
      "metadata": {
        "id": "4620fbe4-eac6-4476-b373-0e48dfbd81e0"
      },
      "source": [
        "SQLRetriever + Table Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3e9d68bb-16a5-409c-a406-1432565dde99",
      "metadata": {
        "id": "3e9d68bb-16a5-409c-a406-1432565dde99"
      },
      "outputs": [],
      "source": [
        "sql_retriever = SQLRetriever(sql_database)\n",
        "\n",
        "\n",
        "def get_table_context_str(table_schema_objs: List[SQLTableSchema]):\n",
        "    \"\"\"Get table context string.\"\"\"\n",
        "    context_strs = []\n",
        "    for table_schema_obj in table_schema_objs:\n",
        "        table_info = sql_database.get_single_table_info(\n",
        "            table_schema_obj.table_name\n",
        "        )\n",
        "        if table_schema_obj.context_str:\n",
        "            table_opt_context = \" The table description is: \"\n",
        "            table_opt_context += table_schema_obj.context_str\n",
        "            table_info += table_opt_context\n",
        "\n",
        "        context_strs.append(table_info)\n",
        "    return \"\\n\\n\".join(context_strs)\n",
        "\n",
        "\n",
        "table_parser_component = get_table_context_str(table_schema_objs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830ff35b-72ba-42bc-ab49-14b2efc93d17",
      "metadata": {
        "id": "830ff35b-72ba-42bc-ab49-14b2efc93d17"
      },
      "source": [
        "Text-to-SQL Prompt + Output Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "246b8a28-a5b8-4103-b731-a6c09f8694ed",
      "metadata": {
        "id": "246b8a28-a5b8-4103-b731-a6c09f8694ed",
        "outputId": "479f47f2-f530-4984-d0fe-ded7a02a306e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.\n",
            "\n",
            "Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
            "\n",
            "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
            "\n",
            "Question: Question here\n",
            "SQLQuery: SQL Query to run\n",
            "SQLResult: Result of the SQLQuery\n",
            "Answer: Final answer here\n",
            "\n",
            "Only use tables listed below.\n",
            "{schema}\n",
            "\n",
            "Question: {query_str}\n",
            "SQLQuery: \n"
          ]
        }
      ],
      "source": [
        "def parse_response_to_sql(response: ChatResponse) -> str:\n",
        "    \"\"\"Parse response to SQL.\"\"\"\n",
        "    response = response.message.content\n",
        "    sql_query_start = response.find(\"SQLQuery:\")\n",
        "    if sql_query_start != -1:\n",
        "        response = response[sql_query_start:]\n",
        "        \n",
        "        if response.startswith(\"SQLQuery:\"):\n",
        "            response = response[len(\"SQLQuery:\") :]\n",
        "    sql_result_start = response.find(\"SQLResult:\")\n",
        "    if sql_result_start != -1:\n",
        "        response = response[:sql_result_start]\n",
        "    return response.strip().strip(\"```\").strip()\n",
        "\n",
        "\n",
        "sql_parser_component = FunctionTool.from_defaults(fn=parse_response_to_sql)\n",
        "\n",
        "text2sql_prompt = DEFAULT_TEXT_TO_SQL_PROMPT.partial_format(\n",
        "    dialect=engine.dialect.name,\n",
        ")\n",
        "print(text2sql_prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cf6a211-dd6b-4ffc-b781-0b0c38896e25",
      "metadata": {
        "id": "0cf6a211-dd6b-4ffc-b781-0b0c38896e25"
      },
      "source": [
        "Response Synthesis Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2fe48e8-ffdd-48f8-b59a-d13d973e8a19",
      "metadata": {
        "id": "a2fe48e8-ffdd-48f8-b59a-d13d973e8a19"
      },
      "outputs": [],
      "source": [
        "response_synthesis_prompt_str = (\n",
        "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
        "    \"Query: {query_str}\\n\"\n",
        "    \"SQL: {sql_query}\\n\"\n",
        "    \"SQL Response: {context_str}\\n\"\n",
        "    \"Response: \"\n",
        ")\n",
        "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ad7cc4-763b-4060-8cc3-ac198c6b956c",
      "metadata": {
        "id": "d4ad7cc4-763b-4060-8cc3-ac198c6b956c"
      },
      "source": [
        "### Define Workflow\n",
        "\n",
        "Now that the components are in place, let's define the query pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "dfe05227",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # custom events\n",
        "# class TableRetrievedEvent(Event):\n",
        "#     tables: list\n",
        "#     query_str: str\n",
        "\n",
        "# class SchemaProcessedEvent(Event):\n",
        "#     table_schema: str\n",
        "#     query_str: str\n",
        "\n",
        "# class SQLPromptReadyEvent(Event):\n",
        "#     t2s_prompt: str\n",
        "#     query_str: str\n",
        "#     table_schema: str\n",
        "\n",
        "# class SQLGeneratedEvent(Event):\n",
        "#     sql_query: str\n",
        "#     query_str: str\n",
        "#     table_schema: str\n",
        "\n",
        "# class SQLParsedEvent(Event):\n",
        "#     sql_query: str\n",
        "#     query_str: str\n",
        "#     table_schema: str\n",
        "\n",
        "# class SQLResultsEvent(Event):\n",
        "#     context_str: str\n",
        "#     sql_query: str\n",
        "#     query_str: str\n",
        "\n",
        "# class ResponsePromptReadyEvent(Event):\n",
        "#     rs_prompt: str\n",
        "\n",
        "\n",
        "# def extract_sql_from_response(llm_response: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Extract SQL query from LLM response that might contain reasoning or formatting.\n",
        "#     \"\"\"\n",
        "#     response = llm_response.strip()\n",
        "    \n",
        "#     # First, remove <think> blocks entirely\n",
        "#     response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()\n",
        "    \n",
        "#     # Method 1: Look for SQLQuery: pattern\n",
        "#     sql_query_match = re.search(r'SQLQuery:\\s*([^;]+;?)', response, re.IGNORECASE | re.DOTALL)\n",
        "#     if sql_query_match:\n",
        "#         sql = sql_query_match.group(1).strip()\n",
        "#         return clean_sql_query(sql)\n",
        "    \n",
        "#     # Method 2: Look for SQL in code blocks\n",
        "#     code_block_match = re.search(r'```sql\\s*\\n(.*?)\\n```', response, re.IGNORECASE | re.DOTALL)\n",
        "#     if code_block_match:\n",
        "#         sql = code_block_match.group(1).strip()\n",
        "#         return clean_sql_query(sql)\n",
        "    \n",
        "#     # Method 3: Look for standalone SQL statements (most common case)\n",
        "#     sql_keywords = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'WITH']\n",
        "    \n",
        "#     # Split by lines and look for SQL statements\n",
        "#     lines = response.split('\\n')\n",
        "#     for line in lines:\n",
        "#         line = line.strip()\n",
        "#         if not line:\n",
        "#             continue\n",
        "            \n",
        "#         # Check if line starts with SQL keyword\n",
        "#         if any(line.upper().startswith(keyword.upper()) for keyword in sql_keywords):\n",
        "#             return clean_sql_query(line)\n",
        "    \n",
        "#     # Method 4: Look for multi-line SQL statements\n",
        "#     for keyword in sql_keywords:\n",
        "#         pattern = rf'\\b{keyword}\\b.*?(?=\\n\\s*\\n|\\nSQLResult|\\nAnswer|$)'\n",
        "#         sql_match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
        "#         if sql_match:\n",
        "#             sql = sql_match.group(0).strip()\n",
        "#             return clean_sql_query(sql)\n",
        "    \n",
        "#     # Fallback: if nothing found, return empty string to avoid errors\n",
        "#     print(f\"Warning: Could not extract SQL from response: {response[:100]}...\")\n",
        "#     return \"SELECT 1\"  # Safe fallback query\n",
        "\n",
        "\n",
        "# def clean_sql_query(sql: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Clean and standardize SQL query.\n",
        "#     \"\"\"\n",
        "#     if not sql:\n",
        "#         return \"SELECT 1\"\n",
        "    \n",
        "#     # Remove extra whitespace\n",
        "#     sql = ' '.join(sql.split())\n",
        "    \n",
        "#     # Fix quote issues - convert double quotes to single quotes for string literals\n",
        "#     # This is a simple approach - for more complex cases, you'd need a proper SQL parser\n",
        "#     sql = re.sub(r'\"([^\"]*)\"', r\"'\\1'\", sql)\n",
        "    \n",
        "#     # Remove multiple semicolons\n",
        "#     sql = re.sub(r';+', ';', sql)\n",
        "    \n",
        "#     # Remove trailing semicolon and add it back cleanly\n",
        "#     sql = sql.rstrip(';').strip()\n",
        "    \n",
        "#     # Don't add semicolon for now since it might be causing issues\n",
        "#     return sql\n",
        "\n",
        "\n",
        "# class Text2SQLWorkflow(Workflow):\n",
        "    \n",
        "#     @step\n",
        "#     async def input_step(self, ev: StartEvent) -> TableRetrievedEvent:\n",
        "#         \"\"\"Process the initial query and retrieve relevant tables\"\"\"\n",
        "#         query = ev.query\n",
        "        \n",
        "#         # Retrieve table schemas (you'll need to define obj_retriever)\n",
        "#         table_schema_objs = obj_retriever.retrieve(query)\n",
        "        \n",
        "#         return TableRetrievedEvent(\n",
        "#             tables=table_schema_objs,\n",
        "#             query_str=query\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def table_output_parser_step(self, ev: TableRetrievedEvent) -> SchemaProcessedEvent:\n",
        "#         \"\"\"Parse table schemas into string format\"\"\"\n",
        "#         # You'll need to define get_table_context_str function\n",
        "#         schema_str = get_table_context_str(ev.tables)\n",
        "        \n",
        "#         return SchemaProcessedEvent(\n",
        "#             table_schema=schema_str,\n",
        "#             query_str=ev.query_str\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def text2sql_prompt_step(self, ev: SchemaProcessedEvent) -> SQLPromptReadyEvent:\n",
        "#         \"\"\"Create the text-to-SQL prompt\"\"\"\n",
        "#         # Enhanced prompt to ensure clean SQL output\n",
        "#         ENHANCED_PROMPT = f\"\"\"\n",
        "#             Given the following table schema and user question, generate a SQL query.\n",
        "\n",
        "#             Table Schema:\n",
        "#             {ev.table_schema}\n",
        "\n",
        "#             User Question: {ev.query_str}\n",
        "\n",
        "#             Instructions:\n",
        "#             1. Generate ONLY a valid SQL query\n",
        "#             2. Do not include any explanations, reasoning, or additional text\n",
        "#             3. Do not include SQLQuery:, SQLResult:, or Answer: labels\n",
        "#             4. Do not wrap in code blocks or other formatting\n",
        "#             5. End the query with a semicolon\n",
        "\n",
        "#             SQL Query:\n",
        "#         \"\"\"\n",
        "        \n",
        "#         # If you have a custom text2sql_prompt, use it instead\n",
        "#         # prompt = text2sql_prompt.format(\n",
        "#         #     query_str=ev.query_str,\n",
        "#         #     table_schema=ev.table_schema\n",
        "#         # )\n",
        "        \n",
        "#         return SQLPromptReadyEvent(\n",
        "#             t2s_prompt=ENHANCED_PROMPT,\n",
        "#             query_str=ev.query_str,\n",
        "#             table_schema=ev.table_schema\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def text2sql_llm_step(self, ev: SQLPromptReadyEvent) -> SQLGeneratedEvent:\n",
        "#         \"\"\"Generate SQL query using LLM\"\"\"\n",
        "#         # You'll need to configure Settings.llm\n",
        "#         sql_response = await Settings.llm.acomplete(ev.t2s_prompt)\n",
        "        \n",
        "#         return SQLGeneratedEvent(\n",
        "#             sql_query=str(sql_response).strip(),\n",
        "#             query_str=ev.query_str,\n",
        "#             table_schema=ev.table_schema\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def sql_output_parser_step(self, ev: SQLGeneratedEvent) -> SQLParsedEvent:\n",
        "#         \"\"\"Parse and clean the generated SQL query\"\"\"\n",
        "#         # Extract clean SQL from the LLM response\n",
        "#         clean_sql = extract_sql_from_response(ev.sql_query)\n",
        "        \n",
        "#         print(f\"Original LLM Response: {ev.sql_query}\")\n",
        "#         print(f\"Cleaned SQL Query: {clean_sql}\")\n",
        "        \n",
        "#         # Validate that we have a reasonable SQL query\n",
        "#         if not clean_sql or clean_sql == \"SELECT 1\":\n",
        "#             print(\"Warning: Could not extract valid SQL, using fallback\")\n",
        "        \n",
        "#         return SQLParsedEvent(\n",
        "#             sql_query=clean_sql,\n",
        "#             query_str=ev.query_str,\n",
        "#             table_schema=ev.table_schema\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def sql_retriever_step(self, ev: SQLParsedEvent) -> SQLResultsEvent:\n",
        "#         \"\"\"Execute SQL query and get results\"\"\"\n",
        "#         try:\n",
        "#             # You'll need to define sql_retriever\n",
        "#             results = sql_retriever.retrieve(ev.sql_query)\n",
        "            \n",
        "#             return SQLResultsEvent(\n",
        "#                 context_str=str(results),\n",
        "#                 sql_query=ev.sql_query,\n",
        "#                 query_str=ev.query_str\n",
        "#             )\n",
        "#         except Exception as e:\n",
        "#             print(f\"SQL Execution Error: {e}\")\n",
        "#             print(f\"Failed SQL Query: {ev.sql_query}\")\n",
        "#             # Return error information for debugging\n",
        "#             return SQLResultsEvent(\n",
        "#                 context_str=f\"SQL execution failed: {str(e)}\",\n",
        "#                 sql_query=ev.sql_query,\n",
        "#                 query_str=ev.query_str\n",
        "#             )\n",
        "    \n",
        "#     @step\n",
        "#     async def response_synthesis_prompt_step(self, ev: SQLResultsEvent) -> ResponsePromptReadyEvent:\n",
        "#         \"\"\"Create the response synthesis prompt\"\"\"\n",
        "#         # You'll need to define response_synthesis_prompt template\n",
        "#         prompt = response_synthesis_prompt.format(\n",
        "#             query_str=ev.query_str,\n",
        "#             context_str=ev.context_str,\n",
        "#             sql_query=ev.sql_query\n",
        "#         )\n",
        "        \n",
        "#         return ResponsePromptReadyEvent(rs_prompt=prompt)\n",
        "    \n",
        "#     @step\n",
        "#     async def response_synthesis_llm_step(self, ev: ResponsePromptReadyEvent) -> StopEvent:\n",
        "#         \"\"\"Generate final answer using LLM\"\"\"\n",
        "#         answer = await Settings.llm.acomplete(ev.rs_prompt)\n",
        "        \n",
        "#         return StopEvent(result=str(answer))\n",
        "\n",
        "\n",
        "# async def run_text2sql_workflow(query: str):\n",
        "#     workflow = Text2SQLWorkflow(timeout=120)\n",
        "#     result = await workflow.run(query=query)\n",
        "#     return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "96cac786",
      "metadata": {},
      "outputs": [],
      "source": [
        "# custom events\n",
        "class TableRetrievedEvent(Event):\n",
        "    tables: list\n",
        "    query_str: str\n",
        "\n",
        "class SchemaProcessedEvent(Event):\n",
        "    table_schema: str\n",
        "    query_str: str\n",
        "\n",
        "class SQLPromptReadyEvent(Event):\n",
        "    t2s_prompt: str\n",
        "    query_str: str\n",
        "    table_schema: str\n",
        "    retry_count: int = 0\n",
        "    error_message: str = \"\"\n",
        "\n",
        "class SQLGeneratedEvent(Event):\n",
        "    sql_query: str\n",
        "    query_str: str\n",
        "    table_schema: str\n",
        "    retry_count: int = 0\n",
        "    error_message: str = \"\"\n",
        "\n",
        "class SQLParsedEvent(Event):\n",
        "    sql_query: str\n",
        "    query_str: str\n",
        "    table_schema: str\n",
        "    retry_count: int = 0\n",
        "    error_message: str = \"\"\n",
        "\n",
        "class SQLResultsEvent(Event):\n",
        "    context_str: str\n",
        "    sql_query: str\n",
        "    query_str: str\n",
        "    success: bool = True\n",
        "\n",
        "class ResponsePromptReadyEvent(Event):\n",
        "    rs_prompt: str\n",
        "\n",
        "\n",
        "# helpers\n",
        "def _is_valid_sql_start(text: str) -> bool:\n",
        "    \"\"\"Check if text starts with valid SQL\"\"\"\n",
        "    if not text:\n",
        "        return False\n",
        "    \n",
        "    sql_keywords = ['SELECT', 'WITH', 'INSERT', 'UPDATE', 'DELETE']\n",
        "    text_upper = text.upper().strip()\n",
        "    return any(text_upper.startswith(keyword) for keyword in sql_keywords)\n",
        "\n",
        "def _clean_sql_query(sql: str) -> str:\n",
        "    \"\"\"\n",
        "    Clean and standardize SQL query.\n",
        "    \"\"\"\n",
        "    if not sql:\n",
        "        return \"SELECT 1\"\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    sql = ' '.join(sql.split())\n",
        "    \n",
        "    # Fix quote issues - convert double quotes to single quotes for string literals\n",
        "    # This is a simple approach - for more complex cases, you'd need a proper SQL parser\n",
        "    sql = re.sub(r'\"([^\"]*)\"', r\"'\\1'\", sql)\n",
        "    \n",
        "    # Remove multiple semicolons\n",
        "    sql = re.sub(r';+', ';', sql)\n",
        "    \n",
        "    # Remove trailing semicolon and add it back cleanly\n",
        "    sql = sql.rstrip(';').strip()\n",
        "    \n",
        "    # Don't add semicolon for now since it might be causing issues\n",
        "    return sql\n",
        "\n",
        "\n",
        "# custom fallbacks\n",
        "def extract_sql_from_response(llm_response: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract SQL query from LLM response that might contain reasoning or formatting.\n",
        "    \"\"\"\n",
        "    response = llm_response.strip()\n",
        "    \n",
        "    # First, remove <think> blocks entirely\n",
        "    response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()\n",
        "    \n",
        "    # Remove any non-SQL content at the beginning\n",
        "    response = re.sub(r'^[^S]*(?=SELECT|WITH|INSERT|UPDATE|DELETE)', '', response, flags=re.IGNORECASE)\n",
        "    \n",
        "    # Method 1: Look for SQLQuery: pattern\n",
        "    sql_query_match = re.search(r'SQLQuery:\\s*([^;]+;?)', response, re.IGNORECASE | re.DOTALL)\n",
        "    if sql_query_match:\n",
        "        sql = sql_query_match.group(1).strip()\n",
        "        return _clean_sql_query(sql)\n",
        "    \n",
        "    # Method 2: Look for SQL in code blocks\n",
        "    code_block_patterns = [\n",
        "        r'```sql\\s*\\n(.*?)\\n```',\n",
        "        r'```\\s*\\n(.*?)\\n```',\n",
        "        r'`([^`]+)`'\n",
        "    ]\n",
        "    \n",
        "    for pattern in code_block_patterns:\n",
        "        match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
        "        if match:\n",
        "            sql = match.group(1).strip()\n",
        "            if _is_valid_sql_start(sql):\n",
        "                return _clean_sql_query(sql)\n",
        "    \n",
        "    # Method 3: Look for standalone SQL statements\n",
        "    sql_keywords = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'WITH']\n",
        "    \n",
        "    # Split by lines and look for SQL statements\n",
        "    lines = response.split('\\n')\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "            \n",
        "        # Check if line starts with SQL keyword\n",
        "        if any(line.upper().startswith(keyword.upper()) for keyword in sql_keywords):\n",
        "            return _clean_sql_query(line)\n",
        "    \n",
        "    # Method 4: Look for multi-line SQL statements\n",
        "    for keyword in sql_keywords:\n",
        "        pattern = rf'\\b{keyword}\\b.*?(?=\\n\\s*\\n|\\nSQLResult|\\nAnswer|$)'\n",
        "        sql_match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
        "        if sql_match:\n",
        "            sql = sql_match.group(0).strip()\n",
        "            return _clean_sql_query(sql)\n",
        "    \n",
        "    # Fallback: if nothing found, return empty string to avoid errors\n",
        "    print(f\"Warning: Could not extract SQL from response: {response[:100]}...\")\n",
        "    return \"SELECT 1\"  # Safe fallback query\n",
        "\n",
        "def analyze_sql_error(error_message: str, sql_query: str, table_schema: str) -> str:\n",
        "    \"\"\"\n",
        "    Analyze SQL error and provide suggestions for fixing the query.\n",
        "    \"\"\"\n",
        "    error_lower = error_message.lower()\n",
        "    \n",
        "    if \"no such column\" in error_lower:\n",
        "        # Extract the problematic column name\n",
        "        column_match = re.search(r'no such column:\\s*(\\w+)', error_lower)\n",
        "        if column_match:\n",
        "            bad_column = column_match.group(1)\n",
        "            \n",
        "            # Try to suggest correct column names from schema\n",
        "            schema_lower = table_schema.lower()\n",
        "            possible_columns = re.findall(r'(\\w+):', schema_lower)\n",
        "            \n",
        "            suggestions = []\n",
        "            for col in possible_columns:\n",
        "                if bad_column.lower() in col.lower() or col.lower() in bad_column.lower():\n",
        "                    suggestions.append(col)\n",
        "            \n",
        "            error_msg = f\"Column '{bad_column}' does not exist.\"\n",
        "            if suggestions:\n",
        "                error_msg += f\" Did you mean: {', '.join(suggestions[:3])}?\"\n",
        "            error_msg += f\"\\n\\nAvailable columns from schema:\\n{table_schema}\"\n",
        "            return error_msg\n",
        "    \n",
        "    elif \"no such table\" in error_lower:\n",
        "        table_match = re.search(r'no such table:\\s*([\\w\\s\\[\\]]+)', error_lower)\n",
        "        if table_match:\n",
        "            bad_table = table_match.group(1).strip()\n",
        "            return f\"Table '{bad_table}' does not exist. Available tables from schema:\\n{table_schema}\"\n",
        "    \n",
        "    elif \"syntax error\" in error_lower:\n",
        "        return f\"SQL syntax error. Please check:\\n- Missing quotes around strings\\n- Proper parentheses\\n- Correct SQL keywords\\n\\nFailed query: {sql_query}\"\n",
        "    \n",
        "    return f\"SQL execution error: {error_message}\\n\\nFailed query: {sql_query}\\n\\nSchema: {table_schema}\"\n",
        "\n",
        "def create_enhanced_prompt(table_schema: str, query_str: str, retry_count: int = 0, error_message: str = \"\"):\n",
        "    if retry_count == 0:\n",
        "        # Initial attempt\n",
        "        ENHANCED_PROMPT = f\"\"\"Given the table schema and user question below, generate ONLY a valid SQL query.\n",
        "\n",
        "            Table Schema:\n",
        "            {table_schema}\n",
        "\n",
        "            User Question: {query_str}\n",
        "\n",
        "            IMPORTANT RULES:\n",
        "            1. Return ONLY the SQL query, nothing else\n",
        "            2. Use single quotes for string literals, not double quotes\n",
        "            3. Do not include any explanations, reasoning, or additional text\n",
        "            4. Do not include labels like \"SQLQuery:\", \"Answer:\", etc.\n",
        "            5. Do not wrap in code blocks or markdown formatting\n",
        "            6. Do not include semicolons at the end\n",
        "            7. Do not include any <think> tags or reasoning\n",
        "            8. Only use column names that exist in the provided schema\n",
        "\n",
        "            Example format:\n",
        "            SELECT column_name FROM table_name WHERE condition\n",
        "\n",
        "            Your SQL query:\n",
        "        \"\"\"\n",
        "    else:\n",
        "        # Retry attempt with error information\n",
        "        ENHANCED_PROMPT = f\"\"\"The previous SQL query failed with an error. Please generate a corrected SQL query.\n",
        "\n",
        "            Table Schema:\n",
        "            {table_schema}\n",
        "\n",
        "            User Question: {query_str}\n",
        "\n",
        "            Previous Error: {error_message}\n",
        "\n",
        "            IMPORTANT RULES:\n",
        "            1. Return ONLY the corrected SQL query, nothing else\n",
        "            2. Use single quotes for string literals, not double quotes\n",
        "            3. Carefully check that all column names exist in the provided schema\n",
        "            4. Do not include any explanations, reasoning, or additional text\n",
        "            5. Do not include labels like \"SQLQuery:\", \"Answer:\", etc.\n",
        "            6. Do not wrap in code blocks or markdown formatting\n",
        "            7. Do not include semicolons at the end\n",
        "            8. Only use column names that are explicitly listed in the schema above\n",
        "\n",
        "            Your corrected SQL query:\n",
        "        \"\"\"\n",
        "    \n",
        "    return ENHANCED_PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "474b321c",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Text2SQLWorkflow(Workflow):\n",
        "    \n",
        "    @step\n",
        "    async def input_step(self, ev: StartEvent) -> TableRetrievedEvent:\n",
        "        \"\"\"Process the initial query and retrieve relevant tables\"\"\"\n",
        "        query = ev.query\n",
        "        # Retrieve table schemas\n",
        "        table_schema_obj = obj_retriever.retrieve(query)\n",
        "        \n",
        "        return TableRetrievedEvent(\n",
        "            tables=table_schema_obj,\n",
        "            query_str=query\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def table_output_parser_step(self, ev: TableRetrievedEvent) -> SchemaProcessedEvent:\n",
        "        \"\"\"Parse table schemas into string format\"\"\"\n",
        "        schema_str = get_table_context_str(ev.tables)\n",
        "        \n",
        "        return SchemaProcessedEvent(\n",
        "            table_schema=schema_str,\n",
        "            query_str=ev.query_str\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def text2sql_prompt_step(self, ev: SchemaProcessedEvent | SQLResultsEvent) -> SQLPromptReadyEvent:\n",
        "        \"\"\"Create the text-to-SQL prompt with optional error correction\"\"\"\n",
        "        \n",
        "        # Handle both initial attempt and retry attempts\n",
        "        if isinstance(ev, SchemaProcessedEvent):\n",
        "            table_schema = ev.table_schema\n",
        "            query_str = ev.query_str\n",
        "            retry_count = 0\n",
        "            error_message = \"\"\n",
        "        else:  # SQLResultsEvent (retry case)\n",
        "            table_schema = getattr(ev, 'table_schema', '')\n",
        "            query_str = ev.query_str\n",
        "            retry_count = getattr(ev, 'retry_count', 0) + 1\n",
        "            error_message = getattr(ev, 'error_message', '')\n",
        "        \n",
        "        # try:\n",
        "        #     # LlamaIndex’s built-in template\n",
        "        #     prompt = DEFAULT_TEXT_TO_SQL_PROMPT.partial_format(\n",
        "        #         dialect=engine.dialect.name,\n",
        "        #         table_schema=table_schema,\n",
        "        #         query_str=query_str\n",
        "        #     ).template\n",
        "        # except Exception:\n",
        "        #     # Fallback to your custom enhanced prompt\n",
        "        #     prompt = create_enhanced_prompt(table_schema, query_str, retry_count, error_message)\n",
        "\n",
        "        prompt = create_enhanced_prompt(table_schema, query_str, retry_count, error_message)\n",
        "\n",
        "        return SQLPromptReadyEvent(\n",
        "            t2s_prompt=prompt,\n",
        "            query_str=query_str,\n",
        "            table_schema=table_schema,\n",
        "            retry_count=retry_count,\n",
        "            error_message=error_message\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def text2sql_llm_step(self, ev: SQLPromptReadyEvent) -> SQLGeneratedEvent:\n",
        "        \"\"\"Generate SQL query using LLM\"\"\"\n",
        "        sql_response = await Settings.llm.acomplete(ev.t2s_prompt)\n",
        "        \n",
        "        return SQLGeneratedEvent(\n",
        "            sql_query=str(sql_response).strip(),\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=ev.table_schema,\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=ev.error_message\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def sql_output_parser_step(self, ev: SQLGeneratedEvent) -> SQLParsedEvent:\n",
        "        \"\"\"Parse and clean the generated SQL query\"\"\"\n",
        "        # Extract clean SQL from the LLM response\n",
        "        try:\n",
        "            clean_sql = parse_response_to_sql(ev)  # Built-in parser\n",
        "        except Exception:\n",
        "            clean_sql = extract_sql_from_response(ev.sql_query)  # Fallback\n",
        "        \n",
        "        if not clean_sql:\n",
        "            clean_sql = extract_sql_from_response(ev.sql_query)\n",
        "        \n",
        "        print(f\"Attempt #{ev.retry_count + 1}\")\n",
        "        print(f\"Original LLM Response: {ev.sql_query}\")\n",
        "        print(f\"Cleaned SQL Query: {clean_sql}\")\n",
        "        \n",
        "        return SQLParsedEvent(\n",
        "            sql_query=clean_sql,\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=ev.table_schema,\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=ev.error_message\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def sql_retriever_step(self, ev: SQLParsedEvent) -> SQLResultsEvent:\n",
        "        \"\"\"Execute SQL query and get results with retry logic\"\"\"\n",
        "        \n",
        "        try:\n",
        "            results = sql_retriever.retrieve(ev.sql_query)\n",
        "            print(f\"[SUCCESS] SQL executed successfully on attempt #{ev.retry_count + 1}\")\n",
        "            return SQLResultsEvent(\n",
        "                context_str=str(results),\n",
        "                sql_query=ev.sql_query,\n",
        "                query_str=ev.query_str,\n",
        "                success=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            error_msg = str(e)\n",
        "            print(f\"[ERROR] SQL Execution Error (Attempt #{ev.retry_count + 1}): {error_msg}\")\n",
        "            print(f\"Failed SQL Query: {ev.sql_query}\")\n",
        "            \n",
        "            # Check if we should retry\n",
        "            if ev.retry_count < MAX_RETRIES:\n",
        "                print(f\"[RETRY] Retrying... (Attempt #{ev.retry_count + 2}/{MAX_RETRIES + 1})\")\n",
        "                \n",
        "                # Return an SQLResultsEvent that will trigger a retry\n",
        "                retry_event = SQLResultsEvent(\n",
        "                    context_str=\"\",\n",
        "                    sql_query=ev.sql_query,\n",
        "                    query_str=ev.query_str,\n",
        "                    success=False\n",
        "                )\n",
        "                retry_event.retry_count = ev.retry_count + 1\n",
        "                retry_event.error_message = analyze_sql_error(error_msg, ev.sql_query, ev.table_schema)\n",
        "                retry_event.table_schema = ev.table_schema\n",
        "                \n",
        "                return retry_event\n",
        "            else:\n",
        "                print(f\"[ERROR, RETRY FAILED] Max retries ({MAX_RETRIES}) reached. Giving up.\")\n",
        "                return SQLResultsEvent(\n",
        "                    context_str=f\"Failed to execute SQL after {MAX_RETRIES + 1} attempts. Final error: {error_msg}\",\n",
        "                    sql_query=ev.sql_query,\n",
        "                    query_str=ev.query_str,\n",
        "                    success=False\n",
        "                )\n",
        "    \n",
        "    @step\n",
        "    async def retry_handler_step(self, ev: SQLResultsEvent) -> SQLPromptReadyEvent:\n",
        "        \"\"\"Handle retry logic - only triggered when SQL execution fails\"\"\"\n",
        "        # This step only processes failed SQL results that need retrying\n",
        "        if ev.success or not hasattr(ev, 'retry_count'):\n",
        "            return None  # Let successful results pass through to response synthesis\n",
        "        \n",
        "        print(f\"[RETRY] Preparing retry #{ev.retry_count + 1}\")\n",
        "        \n",
        "        # Create a new prompt event for retry\n",
        "        return SQLPromptReadyEvent(\n",
        "            t2s_prompt=\"\",  # Will be filled in text2sql_prompt_step\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=getattr(ev, 'table_schema', ''),\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=getattr(ev, 'error_message', 'Unknown error')\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def response_synthesis_prompt_step(self, ev: SQLResultsEvent) -> ResponsePromptReadyEvent:\n",
        "        \"\"\"Create the response synthesis prompt - only for successful SQL results\"\"\"\n",
        "        # Only process successful SQL results\n",
        "        if not ev.success:\n",
        "            return None\n",
        "            \n",
        "        prompt = response_synthesis_prompt.format(\n",
        "            query_str=ev.query_str,\n",
        "            context_str=ev.context_str,\n",
        "            sql_query=ev.sql_query\n",
        "        )\n",
        "        \n",
        "        return ResponsePromptReadyEvent(rs_prompt=prompt)\n",
        "    \n",
        "    @step\n",
        "    async def response_synthesis_llm_step(self, ev: ResponsePromptReadyEvent) -> StopEvent:\n",
        "        \"\"\"Generate final answer using LLM\"\"\"\n",
        "        answer = await Settings.llm.acomplete(ev.rs_prompt)\n",
        "        \n",
        "        return StopEvent(result=str(answer))\n",
        "\n",
        "\n",
        "async def run_text2sql_workflow(query: str):\n",
        "    workflow = Text2SQLWorkflow(timeout=240)\n",
        "    result = await workflow.run(query=query)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e250a417-42c3-49c2-a037-a282974d5f9a",
      "metadata": {
        "id": "e250a417-42c3-49c2-a037-a282974d5f9a"
      },
      "source": [
        "### Visualize Workflow\n",
        "\n",
        "A really nice property of the query pipeline syntax is you can easily visualize it in a graph via networkx."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5f419c-c128-4b04-b18f-0f8b671ff3a4",
      "metadata": {
        "id": "8c5f419c-c128-4b04-b18f-0f8b671ff3a4",
        "outputId": "713e82d3-ddae-4a41-bd65-0cfd802eae9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved text2sql_dag.html successfully.\n"
          ]
        }
      ],
      "source": [
        "# # Build a directed graph of steps\n",
        "# G = nx.DiGraph()\n",
        "\n",
        "# # Nodes\n",
        "# steps = [\n",
        "#     \"input\",\n",
        "#     \"table_retriever\",\n",
        "#     \"table_output_parser\",\n",
        "#     \"text2sql_prompt\",\n",
        "#     \"text2sql_llm\",\n",
        "#     \"sql_output_parser\",\n",
        "#     \"sql_retriever\",\n",
        "#     \"response_synthesis_prompt\",\n",
        "#     \"response_synthesis_llm\"\n",
        "# ]\n",
        "# G.add_nodes_from(steps)\n",
        "\n",
        "# # Edges\n",
        "# edges = [\n",
        "#     (\"input\", \"table_retriever\"),\n",
        "#     (\"table_retriever\", \"table_output_parser\"),\n",
        "    \n",
        "#     (\"input\", \"text2sql_prompt\"),\n",
        "#     (\"table_output_parser\", \"text2sql_prompt\"),\n",
        "\n",
        "#     (\"text2sql_prompt\", \"text2sql_llm\"),\n",
        "#     (\"text2sql_llm\", \"sql_output_parser\"),\n",
        "#     (\"sql_output_parser\", \"sql_retriever\"),\n",
        "    \n",
        "#     (\"sql_output_parser\", \"response_synthesis_prompt\"),\n",
        "#     (\"sql_retriever\", \"response_synthesis_prompt\"),\n",
        "#     (\"input\", \"response_synthesis_prompt\"),\n",
        "    \n",
        "#     (\"response_synthesis_prompt\", \"response_synthesis_llm\")\n",
        "# ]\n",
        "# G.add_edges_from(edges)\n",
        "\n",
        "# # Visualize\n",
        "# net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
        "# net.from_nx(G)\n",
        "\n",
        "# html_content = net.generate_html()\n",
        "# with open(\"../outputs/trials_v1/text2sql_dag.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "#     f.write(html_content)\n",
        "\n",
        "# print(\"Saved text2sql_dag.html successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c0f9eed9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drawing workflow structure...\n",
            "../outputs/trials_v1/structure\\text2sql_workflow_structure.html\n",
            "[SUCCESS] Workflow structure saved to: ../outputs/trials_v1/structure\\text2sql_workflow_structure.html\n"
          ]
        }
      ],
      "source": [
        "async def visualize_text2sql_workflow(sample_query: str):\n",
        "    \"\"\"\n",
        "    Function to visualize the Text2SQL workflow both as all possible flows\n",
        "    and a specific execution example\n",
        "    \"\"\"\n",
        "    output_dir = (\"../outputs/trials_v1/execution\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # 1. Draw ALL possible flows through your workflow\n",
        "    print(\"Drawing all possible flows...\")\n",
        "    all_flows_path = os.path.join(output_dir, \"text2sql_workflow_all_flows.html\")\n",
        "    draw_all_possible_flows(\n",
        "        Text2SQLWorkflow, \n",
        "        filename=all_flows_path\n",
        "    )\n",
        "    print(f\"[SUCCESS] All possible flows saved to: {all_flows_path}\")\n",
        "\n",
        "    # 2. Run workflow + visualize the execution path\n",
        "    print(\"Running workflow and drawing execution path...\")\n",
        "    try:\n",
        "        workflow = Text2SQLWorkflow(timeout=240)\n",
        "        result = await workflow.run(query=sample_query)\n",
        "\n",
        "        # Draw the execution path\n",
        "        execution_path = os.path.join(output_dir, \"text2sql_workflow_recent_execution.html\")\n",
        "        draw_most_recent_execution(\n",
        "            workflow,\n",
        "            filename=execution_path\n",
        "        )\n",
        "        print(f\"[SUCCESS] Recent execution path saved to: {execution_path}\")\n",
        "        print(f\"Workflow result: {result}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Error during workflow execution: {e}\")\n",
        "        print(\"Note: You may need to set up your retriever and LLM settings first\")\n",
        "\n",
        "def visualize_workflow_structure_only():\n",
        "    \"\"\"\n",
        "    Just visualize the workflow structure without executing it\n",
        "    \"\"\"\n",
        "    output_dir = (\"../outputs/trials_v1/structure\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    structure_path = os.path.join(output_dir, \"text2sql_workflow_structure.html\")\n",
        "    print(\"Drawing workflow structure...\")\n",
        "    draw_all_possible_flows(\n",
        "        Text2SQLWorkflow,\n",
        "        filename=structure_path\n",
        "    )\n",
        "    print(f\"[SUCCESS] Workflow structure saved to: {structure_path}\")\n",
        "\n",
        "\n",
        "# Just structure\n",
        "visualize_workflow_structure_only()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b525ef9b-cb94-401e-8fd8-47c94eb3eaa5",
      "metadata": {
        "id": "b525ef9b-cb94-401e-8fd8-47c94eb3eaa5"
      },
      "source": [
        "### Run Some Queries!\n",
        "\n",
        "Now we're ready to run some queries across this entire pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f95196c7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table: table_name='people_info' context_str=\"Summary of information about artists' years of signing and album releases\", Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='grammy_awards' context_str='Summary of Grammy Award data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='drop_event_data' context_str='Summary of historical drop event data over time', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='award_data_1972' context_str='Summary of awards in 1972', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='movie_data' context_str='Summary of movie data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n"
          ]
        }
      ],
      "source": [
        "query = (\"What was the year that The Notorious B.I.G was signed to Bad Boy?\")\n",
        "tables = obj_retriever.retrieve(query)\n",
        "for table in tables:\n",
        "    print(f\"Table: {table}, Type: {type(table)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0c0d9411",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user wants to know the year The Notorious B.I.G was signed to Bad Boy. So first, I need to figure out which table contains this information.\n",
            "\n",
            "Looking at the tables provided, there's people_info, which has Act, Year_signed, and others. The table description is about artists' years of signing and album releases. The Notorious B.I.G is an artist, so maybe they're linked to the people_info table. \n",
            "\n",
            "The question is specifically about the signing year, which is stored in Year_signed. So I should check if there's a way to connect the people_info table to the award_data_1972 or Grammy awards. Wait, the Notorious B.I.G's signing year is mentioned in the people_info table. But how does that connect to the award data?\n",
            "\n",
            "Wait, the Grammy Awards are in the table 'grammy_awards', but the user is asking about their signing, not awards. The people_info table has the Year_signed, so maybe the correct way is to select Year_signed from people_info where Act is 'The Notorious B.I.G'. \n",
            "\n",
            "But wait, the problem says to use the given tables. The people_info table has columns Act, Year_signed, etc. So the SQL query would be SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G'; but the user wants a valid SQL query. Also, the example shows using column names and table names. So the correct query would be that. \n",
            "\n",
            "I need to make sure that there's no other table involved. The other tables are about awards, drop events, and movies, which don't relate to the Notorious B.I.G's signing year. So the answer is to select the Year_signed from people_info where Act is as specified.\n",
            "</think>\n",
            "\n",
            "SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G';\n",
            "Cleaned SQL Query: SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G'\n",
            "[SUCCESS] SQL executed successfully on attempt #1\n",
            "<think>\n",
            "Okay, let's see. The user provided a query asking for the year The Notorious B.I.G was signed to Bad Boy. They also included a SQL query that selects the Year_signed from the people_info table where the Act is 'The Notorious B.I.G'. The SQL response shows that the result has three entries, all 1993. So, the answer should be 1993. I need to make sure I'm not missing any other details, but the query seems straightforward. The SQL is correctly structured, and the response matches the expected data. So the final answer is 1993.\n",
            "</think>\n",
            "\n",
            "The Notorious B.I.G was signed to Bad Boy in the year 1993.\n"
          ]
        }
      ],
      "source": [
        "result = await run_text2sql_workflow(query)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "724dd844",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drawing all possible flows...\n",
            "../outputs/trials_v1/execution\\text2sql_workflow_all_flows.html\n",
            "[SUCCESS] All possible flows saved to: ../outputs/trials_v1/execution\\text2sql_workflow_all_flows.html\n",
            "Running workflow and drawing execution path...\n",
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user is asking for the year that The Notorious B.I.G was signed to Bad Boy. Hmm, I need to figure out which tables to use here.\n",
            "\n",
            "First, the table schema. The table 'people_info' has columns like Act, Year_signed, and AlbumReleasedUnderBadBoy. The problem is connecting the Notorious B.I.G to the Bad Boy. Wait, but the 'people_info' table's _Albums_released_under_Bad_Boy column seems to store the album releases under Bad Boy. So maybe I need to check the Year_signed in people_info to match the B.I.G's signing year.\n",
            "\n",
            "But wait, the question is about the year the B.I.G signed under Bad Boy. So maybe the people_info table has a column with that information. Let me check the columns again. The people_info table has Year_signed (INTEGER), so that's probably the year they signed. But how do I get the album release year from that table?\n",
            "\n",
            "Wait, the _Albums_released_under_Bad_Boy column in people_info might have the album release year. So the query would be selecting Year_signed from people_info where the album data is related to Bad Boy. But how do I check that? Maybe the people_info table has a column that links to the album. But the problem is that the user is asking for the year when The Notorious B.I.G signed, not the album release year. So the answer would be the Year_signed in people_info for that artist.\n",
            "\n",
            "So the SQL query would be SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G'; but wait, the user's question is about the year that was signed, not the album release. Wait, but maybe the people_info table has a column that includes the year when they signed, so the answer is Year_signed. But the example given in the problem is to select from people_info. So maybe the correct query is to select Year_signed from people_info where Act is 'The Notorious B.I.G'. But the user's question is phrased as \"What was the year that The Notorious B.I.G was signed to Bad Boy?\" implying that the album release year is also part of the answer. But the problem says to generate only a valid SQL query. So perhaps the answer is simply the Year_signed from people_info where Act is 'The Notorious B.I.G'.\n",
            "\n",
            "But wait, maybe there's a connection between the people_info and the other tables. For example, the _Albums_released_under_Bad_Boy might be part of the people_info table. So perhaps the query is to join the people_info table with the drop_event_data table or another table? But the user's question is about the signing, not the drop event. Alternatively, maybe the people_info table has the Year_signed, and the album data is stored in another column. But since the problem states to use the given schema, I have to use only the columns provided.\n",
            "\n",
            "So the correct SQL query would be to select Year_signed from people_info where Act is 'The Notorious B.I.G'. Therefore, the answer is that query.\n",
            "</think>\n",
            "\n",
            "SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G';\n",
            "Cleaned SQL Query: SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G'\n",
            "[SUCCESS] SQL executed successfully on attempt #1\n",
            "../outputs/trials_v1/execution\\text2sql_workflow_recent_execution.html\n",
            "[SUCCESS] Recent execution path saved to: ../outputs/trials_v1/execution\\text2sql_workflow_recent_execution.html\n",
            "Workflow result: <think>\n",
            "Okay, let's see. The user asked, \"What was the year that The Notorious B.I.G was signed to Bad Boy?\" and provided a SQL query result. The SQL response has a list of years: 1993, 1993, 1993. So, the answer should be 1993.\n",
            "\n",
            "Wait, but the SQL is selecting the Year_signed from the people_info table where Act is 'The Notorious B.I.G'. The result from the SQL query shows three entries of 1993. That probably means that there were three different people or acts named The Notorious B.I.G, each signed to Bad Boy in 1993. But the user's question is about the year when The Notorious B.I.G was signed to Bad Boy. If the SQL query is correct, then the result is 1993. So the answer is 1993. I should just state that the year is 1993.\n",
            "</think>\n",
            "\n",
            "The Notorious B.I.G was signed to Bad Boy in the year **1993**.\n"
          ]
        }
      ],
      "source": [
        "# Full visualization with execution\n",
        "await visualize_text2sql_workflow(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8b6d6881",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table: table_name='award_nominations' context_str='Summary of award data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='award_data_1972' context_str='Summary of awards in 1972', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='grammy_awards' context_str='Summary of Grammy Award data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='award_data' context_str='Summary of awards data across categories and years', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='movie_data' context_str='Summary of movie data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n"
          ]
        }
      ],
      "source": [
        "tables = obj_retriever.retrieve(\"Who won best director in the 1972 academy awards?\")\n",
        "for table in tables:\n",
        "    print(f\"Table: {table}, Type: {type(table)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "89dfbb01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's tackle this problem. The user is asking, \"Who won best director in the 1972 academy awards?\" So first, I need to figure out which tables and columns are relevant here.\n",
            "\n",
            "The question is about the Academy Awards, which are mentioned in the tables. The tables provided are award_nominations, award_data_1972, Grammy Awards, and movie_data. Wait, Academy Awards might be part of the Grammy Awards table, but the user is specifically talking about 1972 academy awards. Let me check the tables again.\n",
            "\n",
            "Looking at the tables, the 'award_data_1972' has columns like Award, Category, Nominee, Result. The 'award_data' table has columns Year, Award, Category, Nominated_work, Result. So maybe the answer is looking for the 'Award' and 'Result' in the 'award_data_1972' where the Year is 1972 and the Award is 'best director'. But how do I connect that with the other tables?\n",
            "\n",
            "Wait, the user is asking for the person who won best director in 1972 Academy Awards. So the nominee's name would be in the 'nominee' column of the 'award_data_1972' table. But the 'award_data_1972' has the Nominee as a column. So the query would be selecting the Nominee from award_data_1972 where Year is 1972 and the Award is 'best director'.\n",
            "\n",
            "But wait, the 'award_data_1972' has the category, but maybe the category is not needed here. The user just needs the best director. So the SQL query would be a SELECT from award_data_1972 where Year = 1972 and Award = 'best director'. But wait, does the 'award_data_1972' have that award? Let me check the table description again. The 'award_data_1972' says \"Summary of awards in 1972\". So the award in question is 'best director' and the year is 1972. So the correct SQL is to select the Nominee from that table.\n",
            "\n",
            "But wait, the user might be referring to the Grammy Awards or the Academy Awards. The problem states '1972 academy awards', so the query should use the 'award_data_1972' table. Therefore, the SQL query is as simple as SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Award = 'best director'.\n",
            "\n",
            "I need to make sure that the columns are exactly as provided. The 'award_data_1972' has 'Award' and 'Result' columns. The 'award_data' has 'Award' and 'Result' as well. But the user is specifically asking about the best director, which is in the 'Award' column of the 'award_data_1972' table. So the query is correct.\n",
            "</think>\n",
            "\n",
            "SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Award = 'best director';\n",
            "Cleaned SQL Query: SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Award = 'best director'\n",
            "[ERROR] SQL Execution Error (Attempt #1): Statement \"SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Award = 'best director'\" is invalid SQL.\n",
            "Error: no such column: Year\n",
            "Failed SQL Query: SELECT Nominee FROM award_data_1972 WHERE Year = 1972 AND Award = 'best director'\n",
            "[RETRY] Retrying... (Attempt #2/4)\n",
            "[RETRY] Preparing retry #2\n",
            "Warning: Could not extract SQL from response: Sure! Could you please provide more details or clarify your request? I'd be happy to assist! 😊...\n",
            "Attempt #2\n",
            "Original LLM Response: <think>\n",
            "Okay, the user just sent me a message. Let me check the context. They might be asking me to do something specific, but I need to make sure I understand their request. Maybe they want me to respond to their message or ask a question. Let me look at the message again. It's just a single message, so I should acknowledge their presence and ask them to provide more details. That way, I can address their needs effectively. I should keep it friendly and open-ended.\n",
            "</think>\n",
            "\n",
            "Sure! Could you please provide more details or clarify your request? I'd be happy to assist! 😊\n",
            "Cleaned SQL Query: SELECT 1\n",
            "[SUCCESS] SQL executed successfully on attempt #2\n",
            "Attempt #3\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user wants to know who won best director in the 1972 academy awards. The previous SQL query had an error with the column 'year' not existing. So I need to figure out how to correct this.\n",
            "\n",
            "First, looking at the available tables, the relevant ones are 'award_data_1972' and 'grammy_awards'. The user is asking about 1972 Academy Awards, so maybe the 'award_data_1972' table is the right one. But wait, the tables have different names. Let me check the columns again.\n",
            "\n",
            "The 'award_data_1972' has columns: Award, Category, Nominee, Result. The 'grammy_awards' has Year, Award, Work_Artist, Result. The 'award_data' has Year as a string, Award, Category, Nominated_work, Result. The movie_data has Year and Title, etc.\n",
            "\n",
            "The user's question is about the 1972 Academy Awards. The 'award_data_1972' table has the nominee's name, so maybe the correct SQL is to join these tables. But how?\n",
            "\n",
            "Wait, the error was column 'year' doesn't exist. But the user's question is about 1972 Academy Awards. So perhaps the correct approach is to check if there's a 'Year' column in the 'award_data_1972' table. Let me look at the columns again. The 'award_data_1972' has columns: Award, Category, Nominee, Result. The table description says it's the summary of awards in 1972. So the Nominee column would be the person who won. So the SQL query should select the Nominee from award_data_1972 where the Year is 1972. But the error was about the column 'year' not existing. Wait, maybe the original query used an incorrect column name, like 'year' instead of 'Year'. But the corrected query needs to be based on the correct column names. So the correct query would be to select the Nominee from the 'award_data_1972' table where the Year is 1972. Therefore, the corrected SQL is SELECT Nominee FROM award_data_1972 WHERE Year = 1972; but the error was that the column 'year' doesn't exist, so maybe the original query used a different column name, like 'year' instead of 'Year'. So the correct query would be to use the correct column names as provided in the schema.\n",
            "\n",
            "Wait, the user's previous error was column 'year' does not exist. So maybe the original query had a typo, like using 'year' instead of 'Year'. Therefore, the corrected SQL should use the correct column names. So the answer would be to select the Nominee from the award_data_1972 table where the Year is 1972. So the SQL query would be SELECT Nominee FROM award_data_1972 WHERE Year = 1972; but the user wants only the corrected query. So the final answer should be that query.\n",
            "</think>\n",
            "\n",
            "SELECT Nominee FROM award_data_1972 WHERE Year = 1972;\n",
            "Cleaned SQL Query: SELECT Nominee FROM award_data_1972 WHERE Year = 1972\n",
            "[ERROR] SQL Execution Error (Attempt #3): Statement 'SELECT Nominee FROM award_data_1972 WHERE Year = 1972' is invalid SQL.\n",
            "Error: no such column: Year\n",
            "Failed SQL Query: SELECT Nominee FROM award_data_1972 WHERE Year = 1972\n",
            "[RETRY] Retrying... (Attempt #4/4)\n",
            "[RETRY] Preparing retry #4\n",
            "<think>\n",
            "Okay, let's see. The user is asking about who won the best director in the 1972 Academy Awards. The SQL query provided is SELECT 1, but the response seems to be a node with a score and some metadata. Wait, the SQL query is not actually executed here. The response is just a placeholder or a node with score, which might be part of a larger system that's not showing the actual data.\n",
            "\n",
            "So the user's question is about the 1972 Academy Awards, but the SQL query they provided is a SELECT statement that returns 1, which doesn't make sense. Maybe there's a confusion between the query and the response. The user wants to know the winner, but the SQL is empty, and the response is just a node with a score. Since the SQL query is empty, perhaps the system is testing if the user is expecting an answer, but the SQL isn't providing any data. Therefore, the answer should be that there's no data available from the provided SQL query to answer the question.\n",
            "</think>\n",
            "\n",
            "The provided SQL query returns a placeholder result, indicating no data was retrieved. Since the question is about the 1972 Academy Awards winner, but no query results are available, there is insufficient information to answer the question.\n"
          ]
        }
      ],
      "source": [
        "response_1 = await run_text2sql_workflow(\"Who won best director in the 1972 academy awards?\")\n",
        "print(response_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "0dfffdd6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table: table_name='government_ministers' context_str='Summary of historical government ministers', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='new_municipality_old_municipality_seat' context_str='This table shows entries with the same values in two columns, but the third is unique.', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='people_terms' context_str='Summary of individual term data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='award_data_1972' context_str='Summary of awards in 1972', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='people_info' context_str=\"Summary of information about artists' years of signing and album releases\", Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n"
          ]
        }
      ],
      "source": [
        "tables = obj_retriever.retrieve(\"What was the term of Pasquale Preziosa?\")\n",
        "for table in tables:\n",
        "    print(f\"Table: {table}, Type: {type(table)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "16c87f2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user is asking for the term of Pasquale Preziosa. First, I need to figure out if there's a table that contains information about people, their terms, and their names. Looking at the provided tables, there's 'people_terms' which has a column named Name. So maybe I can use that.\n",
            "\n",
            "The user's question mentions \"Pasquale Preziosa,\" so I need to check if there's a person named Pasquale Preziosa in any of the tables. But in the given tables, the only people mentioned are from 'government_ministers' and 'people_terms'. Wait, the 'people_terms' table has a Name column. So if Pasquale Preziosa is a person in that table, I can query for their term.\n",
            "\n",
            "But wait, the problem is that the user's question is about Pasquale Preziosa, but there's no explicit mention of that person in any of the tables. Unless there's a way to link Pasquale Preziosa with someone else. Wait, maybe I'm missing something. Let me check again.\n",
            "\n",
            "Looking at the tables again: 'people_terms' has Name, Term_start, Term_end. So if there's a record where the Name is Pasquale Preziosa, then we can find the term. But the question is, how do we know that Pasquale Preziosa exists in the database?\n",
            "\n",
            "Wait, maybe the user is referring to a specific individual. But in the provided tables, there's no direct record of Pasquale Preziosa. Unless there's an error in the question, or maybe the user expects me to use the given tables and assume that Pasquale Preziosa exists. But that's a stretch. Alternatively, perhaps there's a way to connect the tables.\n",
            "\n",
            "Wait, maybe the 'government_ministers' table has a member of Parliament name, but that's different. The 'people_terms' table is for individual terms. So if Pasquale Preziosa is a person in people_terms, then the query would be SELECT Term_start, Term_end FROM people_terms WHERE Name = 'Pasquale Preziosa'; but the problem is that the user's question is about the term, not the start and end dates. So the answer would be the Term_start and Term_end columns. But the user is asking for the term, so maybe the answer is just selecting those columns.\n",
            "\n",
            "But according to the example provided, the user asked for \"What was the term of Pasquale Preziosa?\" and the example query is SELECT column_name FROM table_name WHERE condition. So in this case, the correct approach would be to select Term_start and Term_end from people_terms where Name is Pasquale Preziosa. But since the problem states that the user's question is to find the term, and if there's no existing data, maybe the answer is that there's no record. But that's not possible because the user is asking for it, implying that the answer exists.\n",
            "\n",
            "Wait, perhaps there's a mistake in the problem setup. Let me double-check. The user says to generate only a valid SQL query, so maybe there's an assumption here. Alternatively, maybe the answer is that there's no information available, but since the question is posed, it's expecting an SQL query that would return the term. Therefore, the correct SQL query would be to select Term_start and Term_end from people_terms where Name is 'Pasquale Preziosa'.\n",
            "\n",
            "So the final answer would be a SELECT statement with those columns. But the user's example uses a WHERE clause. So the query would be:\n",
            "\n",
            "SELECT Term_start, Term_end\n",
            "FROM people_terms\n",
            "WHERE Name = 'Pasquale Preziosa';\n",
            "\n",
            "That's it. No other columns, and the rules are followed.\n",
            "</think>\n",
            "\n",
            "SELECT Term_start, Term_end FROM people_terms WHERE Name = 'Pasquale Preziosa';\n",
            "Cleaned SQL Query: SELECT Term_start, Term_end FROM people_terms WHERE Name = 'Pasquale Preziosa'\n",
            "[SUCCESS] SQL executed successfully on attempt #1\n",
            "<think>\n",
            "Okay, let's see. The user is asking for the term of Pasquale Preziosa from the SQL query. The SQL query is a SELECT statement that selects Term_start and Term_end from the people_terms table where the Name is 'Pasquale Preziosa'. The response provided is a text node with some metadata.\n",
            "\n",
            "First, I need to parse the metadata. The metadata includes the sql_query, result, col_keys, and some other fields. The result has three entries: '25 February 2013' for Term_start and Term_end. The col_keys are Term_start and Term_end. \n",
            "\n",
            "So the main thing here is to extract the Term_start and Term_end values. The result has three entries, but the metadata shows that there are three entries. Wait, but maybe the SQL query is returning multiple results, but the user might just need the first one. However, looking at the metadata, it's structured with [('25 February 2013', 'Incumbent'), ...], so each pair is a row. \n",
            "\n",
            "But the user's question is asking for the term, which is probably the primary term. Since all three entries have the same date and term, the answer would be that Pasquale Preziosa's term is 'Incumbent' on 25 February 2013. However, the exact term is given in the result as 'Incumbent' for each entry. So the answer is that the term is 'Incumbent' on that specific date. I need to present that clearly.\n",
            "</think>\n",
            "\n",
            "The term for Pasquale Preziosa is **\"Incumbent\"** on **25 February 2013**.\n"
          ]
        }
      ],
      "source": [
        "response_2 = await run_text2sql_workflow(\"What was the term of Pasquale Preziosa?\")\n",
        "print(response_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "96f1ca00",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Table: table_name='chart_positions' context_str='Summary of music chart data across countries', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='district_info' context_str='Summary of district data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='movie_chart_positions' context_str='Summary of movie chart positions across different countries', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='broadcasting_info' context_str='Summary of broadcasting data', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n",
            "Table: table_name='bbc_radio_costs' context_str='Summary of BBC Radio service costs compared to 2011.', Type: <class 'llama_index.core.objects.table_node_mapping.SQLTableSchema'>\n"
          ]
        }
      ],
      "source": [
        "tables = obj_retriever.retrieve(\"Show me total sales by region\")\n",
        "for table in tables:\n",
        "    print(f\"Table: {table}, Type: {type(table)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2e4461a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user wants to show total sales by region. First, I need to figure out which tables and columns are relevant here.\n",
            "\n",
            "Looking at the table schemas, there's 'chart_positions' with columns like Certifications_sales_thresholds_ (INTEGER). But the user's question is about total sales, not thresholds. Maybe that's part of the chart data. Then there's 'movie_chart_positions', which has Chart_Positions_US (VARCHAR), but sales aren't mentioned there. Wait, the user's question is about total sales, so maybe that's in 'chart_positions' or another table.\n",
            "\n",
            "Wait, the 'chart_positions' table has Certifications_sales_thresholds_ (INTEGER). But the user wants total sales, not thresholds. Maybe the Sales column isn't there. But the user's example query uses 'column_name' from a table. Maybe they are referring to the sales threshold as a column, but that's not matching the question. Alternatively, maybe there's a mistake in the schema, but according to the provided information, I have to go with what's given.\n",
            "\n",
            "Wait, the user's question is \"Show me total sales by region\". Let me check the tables again. The 'chart_positions' has 'Certifications_sales_thresholds_ (INTEGER)', but that's not the sales. The other tables don't mention sales. The 'movie_chart_positions' also doesn't have a sales column. The 'bbc_radio_costs' has service costs, but that's not sales. The 'district_info' has population, but that's a separate data point. The 'broadcasting_info' has Format, but again not sales.\n",
            "\n",
            "So maybe there's a missing table or there's a confusion in the question. But according to the provided schema, there's no table that directly relates to total sales. However, the user's example query uses 'column_name' from a table. Perhaps the user intended to use the 'certifications_sales_thresholds_ (INTEGER)' column, but that's not the sales. Alternatively, maybe there's a mistake in the schema, and the correct approach is to use the 'certifications_sales_thresholds_ (INTEGER)' as a sales metric, even though it's not clear. Wait, but the question is about total sales, not thresholds. So perhaps the answer is that there's no such table, but the user's example shows using a column. Alternatively, maybe I'm misunderstanding the tables.\n",
            "\n",
            "Wait, the user's example query uses 'column_name' from a table, but in this case, there's no such column. So maybe there's a mistake in the problem setup. But since the user is asking, perhaps I need to proceed with what's given, even if there's no direct connection. Alternatively, maybe the 'certifications_sales_thresholds_ (INTEGER)' is part of the data, and the user wants to sum that, but that would be a different question. Alternatively, maybe the answer is to use the 'certifications_sales_thresholds_ (INTEGER)' as a sales metric, even though it's not the total. But the user's question is about total sales, so perhaps that's the intended approach.\n",
            "\n",
            "Wait, the user's example query uses 'column_name' from a table. But in this case, there's no such column. So perhaps there's an error, but since the user expects an answer, maybe I should proceed by assuming that the 'certifications_sales_thresholds_ (INTEGER)' is the sales, and that the query is to sum it by region. But how? The 'chart_positions' table has 'certifications_sales_thresholds_ (INTEGER)', but without knowing the regions, how would that sum? Unless there's a 'Region' column, but in the provided schema, there's no 'Region' column.\n",
            "\n",
            "Alternatively, maybe the 'certifications_sales_thresholds_ (INTEGER)' is part of a region-based calculation, but the schema doesn't mention it. This is confusing. Since the user's example shows using a column, perhaps they intended to use 'certifications_sales_thresholds_ (INTEGER)' as the sales, but that's not the total. Or maybe the user made a mistake in the schema, and there's no way to answer based on the given data.\n",
            "\n",
            "But given the problem statement, I have to generate a SQL query based on the provided schema. Since there's no table with sales data, perhaps the answer is that there's no such table, but the user's example shows using a column. Alternatively, maybe the answer is to use the 'certifications_sales_thresholds_ (INTEGER)' as a sales metric, even though that's not the total. But without knowing the regions, how can that be? This is a problem.\n",
            "\n",
            "Wait, maybe the 'certifications_sales_thresholds_ (INTEGER)' is a sales metric, and the user wants to sum that by region, but there's no 'Region' column. Therefore, the answer is that there's no valid table to use, but the user's example shows using a column. This seems like a contradiction. Therefore, perhaps there's a mistake in the problem setup, but the user expects an answer. Since I must provide something, maybe I should proceed by assuming that the 'certifications_sales_thresholds_ (INTEGER)' is the sales, and that the query is to sum it by region, even though the schema doesn't mention regions. But that's not possible. Alternatively, maybe the answer is to use the 'certifications_sales_thresholds_ (INTEGER)' as a sales metric, but the question is about total sales, so perhaps that's the total sum. But how?\n",
            "\n",
            "Wait, the user's question is \"total sales by region\". If there's no sales data, then the answer is impossible. But since the user is asking, perhaps there's a way. Maybe the 'certifications_sales_thresholds_ (INTEGER)' is the sales, and the query is to sum that by region, but the 'chart_positions' table doesn't have region columns. Therefore, the answer is that there's no way to answer, but the user's example shows using a column. This is very confusing.\n",
            "\n",
            "Given the constraints, perhaps the intended answer is to use the 'certifications_sales_thresholds_ (INTEGER)' column and assume that it's the sales, even though that's not the total. So the SQL query would be SELECT Certifications_sales_thresholds_ FROM chart_positions GROUP BY Year, Single, etc. But that's not correct. Alternatively, maybe the user made a mistake in the schema, and the intended query is to use the 'certifications_sales_thresholds_ (INTEGER)' column, but that's not the total. This is really a problem.\n",
            "\n",
            "Alternatively, maybe the 'certifications_sales_thresholds_ (INTEGER)' is part of the 'chart_positions' table, and the user wants to sum that by region, but there's no region data. Therefore, the answer is that there's no valid query, but since the user expects an answer, perhaps the intended query is to sum that column, even though it's not the total. But this is not valid. Therefore, perhaps there's a mistake in the problem setup, but given that, I have to proceed.\n",
            "\n",
            "Wait, maybe the user intended to use the 'certifications_sales_thresholds_ (INTEGER)' as the sales, and that's the total, so the query would be SELECT certifications_sales_thresholds_ FROM chart_positions GROUP BY Year, Single, Peak_chart_positions_GER, etc. But the user's question is about total sales by region, not by country. Therefore, perhaps there's a missing table, but since the user's example shows using a column, maybe that's the intended approach. But this seems incorrect.\n",
            "\n",
            "Given the confusion, perhaps the correct answer is to use the 'certifications_sales_thresholds_ (INTEGER)' column, assuming that it's the sales, and that the query is to sum it by region, even though there's no region data. But that's not valid. Therefore, the answer might be that there's no such table, but since the user requires an answer, perhaps the correct approach is to use the 'certifications_sales_thresholds_ (INTEGER)' as the sales, and the query is to sum that by region, even though it's not possible. But this is a stretch.\n",
            "\n",
            "Alternatively, maybe the 'chart_positions' table has a 'Region' column, but in the provided schema, it's not present. So I'm stuck. Given that, perhaps the correct answer is to use the 'certifications_sales_thresholds_ (INTEGER)' column, even though it's not the total sales, as per the example. So the SQL query would be SELECT Certifications_sales_thresholds_ FROM chart_positions GROUP BY Year, Single, Peak_chart_positions_GER, etc. But since the user's question is about total sales by region, this query doesn't make sense. Hence, I'm forced to conclude that there's no valid query based on the provided schema.\n",
            "</think>\n",
            "\n",
            "SELECT Certifications_sales_thresholds_ FROM chart_positions GROUP BY Year, Single, Peak_chart_positions_GER, Peak_chart_positions_IRE, Peak_chart_positions_UK, Peak_chart_positions_US, Peak_chart_positions_US_Main, Peak_chart_positions_US_Dance;\n",
            "Cleaned SQL Query: SELECT Certifications_sales_thresholds_ FROM chart_positions GROUP BY Year, Single, Peak_chart_positions_GER, Peak_chart_positions_IRE, Peak_chart_positions_UK, Peak_chart_positions_US, Peak_chart_positions_US_Main, Peak_chart_positions_US_Dance\n",
            "[SUCCESS] SQL executed successfully on attempt #1\n",
            "<think>\n",
            "Okay, let's see. The user wants to show total sales by region based on the given SQL query. The SQL query is selecting Certifications_sales_thresholds_ from chart_positions grouped by various regions. The response from the SQL is a list of tuples with None values, which probably means that the query didn't find any relevant data or there were no matching records.\n",
            "\n",
            "First, I need to parse the SQL query. The query GROUP BY the specified columns, which are Year, Single, Peak_chart_positions_GER, etc. The result is a list of tuples, each indicating some sales data. But all the entries are None, so there's no actual data to show. That suggests that maybe the query is trying to fetch data from a table but the fields being grouped don't exist, or the table isn't populated with those columns.\n",
            "\n",
            "Wait, the user's question is to show total sales by region. But the SQL is structured to group by those specific columns. If those columns don't exist in the table, then grouping by them would result in NULL values. So the result is empty, meaning there's no information available to answer the query. The response provided is a text with these None tuples, indicating that the query's execution didn't return any data.\n",
            "\n",
            "So the conclusion is that there's no total sales data available by region based on the provided SQL, as the query's structure might not correspond to the actual data in the chart_positions table. The user needs to check if the table structure is correct or if there's a typo in the SQL query.\n",
            "</think>\n",
            "\n",
            "The SQL query attempted to group sales data by specified regions (`Year`, `Single`, etc.) but returned empty results (`[None, ...]`). This indicates that either the table structure does not support those specific columns, or there is no data available to compute total sales by region. No valid data was retrieved from the query.\n"
          ]
        }
      ],
      "source": [
        "response_3 = await run_text2sql_workflow(\"Show me total sales by region\")\n",
        "print(response_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9acab5f",
      "metadata": {},
      "source": [
        "# FINAL SCORE: 2/4 \n",
        "\n",
        "## -> Problem: Column names aren't getting specified properly"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
