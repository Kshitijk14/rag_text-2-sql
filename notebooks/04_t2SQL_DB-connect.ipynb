{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "855f9f50-ef38-4069-932a-fb49af02d28e",
      "metadata": {
        "id": "855f9f50-ef38-4069-932a-fb49af02d28e"
      },
      "source": [
        "1. **Query-Time Table Retrieval**: Dynamically retrieve relevant tables in the text-to-SQL prompt.\n",
        "2. **Query-Time Sample Row retrieval**: Embed/Index each row, and dynamically retrieve example rows for each table in the text-to-SQL prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "997717d9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\Hp\\\\Documents\\\\GitHub\\\\rag_text-2-sql\\\\notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6ad056f1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\Hp\\\\Documents\\\\GitHub\\\\rag_text-2-sql'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"../\")\n",
        "\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc8cd21",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from utils.helpers.other_imports import (\n",
        "    io,\n",
        "    time,\n",
        "    re,\n",
        "    requests,\n",
        "    zipfile,\n",
        "    shutil,\n",
        "    gc,\n",
        "    traceback,\n",
        "    json,\n",
        "    pyjson,\n",
        "    pd,\n",
        "    Path,\n",
        "    List,\n",
        "    Dict,\n",
        "    BaseModel,\n",
        "    Field,\n",
        "    px,\n",
        "    chromadb,\n",
        ")\n",
        "\n",
        "from utils.helpers.sql_alchemy_imports import (\n",
        "    create_engine,\n",
        "    text,\n",
        "    inspect,\n",
        "    MetaData,\n",
        "    Table,\n",
        "    Column,\n",
        "    String,\n",
        "    Integer,\n",
        ")\n",
        "\n",
        "from utils.helpers.llama_index_imports import (\n",
        "    Settings, \n",
        "    SQLDatabase, \n",
        "    VectorStoreIndex, \n",
        "    ChromaVectorStore,\n",
        "    load_index_from_storage,\n",
        "    set_global_handler,\n",
        "    LLMTextCompletionProgram,\n",
        "    SQLTableNodeMapping,\n",
        "    ObjectIndex,\n",
        "    SQLTableSchema,\n",
        "    SQLRetriever,\n",
        "    DEFAULT_TEXT_TO_SQL_PROMPT,\n",
        "    PromptTemplate,\n",
        "    FunctionTool,\n",
        "    ChatResponse,\n",
        "    TextNode,\n",
        "    StorageContext,\n",
        "    Workflow,\n",
        "    step,\n",
        "    StartEvent,\n",
        "    StopEvent,\n",
        "    draw_all_possible_flows,\n",
        "    draw_most_recent_execution,\n",
        ")\n",
        "\n",
        "from utils.config import CONFIG\n",
        "from utils.logger import setup_logger\n",
        "\n",
        "\n",
        "# configurations\n",
        "LOG_PATH = Path(CONFIG[\"LOG_PATH\"])\n",
        "\n",
        "CHINOOK_DBEAVER_DB_PATH = Path(CONFIG[\"CHINOOK_DBEAVER_DB_PATH\"])\n",
        "CHINOOK_TABLE_INDEX_DIR = Path(CONFIG[\"CHINOOK_TABLE_INDEX_DIR\"])\n",
        "SQLITE_DB_DIR = Path(CONFIG[\"SQLITE_DB_DIR\"])\n",
        "CHROMA_DB_DIR = Path(CONFIG[\"CHROMA_DB_DIR\"])\n",
        "\n",
        "WORKFLOW_VISUALIZATION_DIR = Path(CONFIG[\"WORKFLOW_VISUALIZATION_DIR\"])\n",
        "\n",
        "QUERY_1 = CONFIG[\"QUERY_1\"]\n",
        "QUERY_1_INITIAL = CONFIG[\"QUERY_1_INITIAL\"]\n",
        "\n",
        "TOP_K = CONFIG[\"TOP_K\"]\n",
        "TOP_N = CONFIG[\"TOP_N\"]\n",
        "MAX_RETRIES = CONFIG[\"MAX_RETRIES\"]\n",
        "\n",
        "\n",
        "# setup logging\n",
        "LOG_DIR = os.path.join(os.getcwd(), LOG_PATH)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)  # Create the logs directory if it doesn't exist\n",
        "\n",
        "# comment out line 15 in utils/logger.py -> only for notebooks\n",
        "LOG_FILE = os.path.join(LOG_DIR, \"db_connect_notebook.log\")\n",
        "logger = setup_logger(\"db_connect_notebook_logger\", LOG_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fe7acbf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-20 20:31:54,655 [INFO] Creating SQLite DB Engine for the new summaries database: db\\Chinook\\sqlite\\table_summaries.db\n",
            "2025-08-20 20:31:54,659 [INFO]  - Ensuring the table exists (id, table_name, table_summary, created_at)\n",
            "2025-08-20 20:31:54,664 [INFO] Creating SQLite DB Engine for the existing Chinook database at C:\\Users\\Hp\\AppData\\Roaming\\DBeaverData\\workspace6\\.metadata\\sample-database-sqlite-1\\Chinook.db\n",
            "2025-08-20 20:31:54,669 [INFO] Generating table summaries...\n",
            "2025-08-20 20:31:54,670 [INFO] Fetching existing summaries from the summaries database...\n",
            "2025-08-20 20:31:54,671 [INFO] Found 10 existing summaries in DB\n",
            "2025-08-20 20:31:54,673 [INFO]  - Skipping table 'Album' — summary already exists.\n",
            "2025-08-20 20:31:54,674 [INFO]  - Processing new table: Artist\n",
            "2025-08-20 20:32:16,205 [INFO] Normalize LLM output\n",
            "2025-08-20 20:32:16,207 [INFO] Processed table: Artist\n",
            "2025-08-20 20:32:16,207 [INFO] Saving table summary for Artist immediately to summaries DB\n",
            "2025-08-20 20:32:16,216 [INFO]  - Skipping table 'Customer' — summary already exists.\n",
            "2025-08-20 20:32:16,217 [INFO]  - Skipping table 'Employee' — summary already exists.\n",
            "2025-08-20 20:32:16,218 [INFO]  - Skipping table 'Genre' — summary already exists.\n",
            "2025-08-20 20:32:16,219 [INFO]  - Skipping table 'Invoice' — summary already exists.\n",
            "2025-08-20 20:32:16,220 [INFO]  - Skipping table 'InvoiceLine' — summary already exists.\n",
            "2025-08-20 20:32:16,221 [INFO]  - Skipping table 'MediaType' — summary already exists.\n",
            "2025-08-20 20:32:16,222 [INFO]  - Skipping table 'Playlist' — summary already exists.\n",
            "2025-08-20 20:32:16,223 [INFO]  - Skipping table 'PlaylistTrack' — summary already exists.\n",
            "2025-08-20 20:32:16,224 [INFO]  - Skipping table 'Track' — summary already exists.\n",
            "2025-08-20 20:32:16,225 [INFO] \n",
            " FINAL TABLE SUMMARIES\n",
            "2025-08-20 20:32:16,228 [INFO] - Artist: Summary of artist data\n",
            "2025-08-20 20:32:16,232 [INFO] \n",
            "Saved 1 summaries to:\n",
            "2025-08-20 20:32:16,234 [INFO]  - SQLite DB: db\\Chinook\\sqlite\\table_summaries.db\n",
            "2025-08-20 20:32:16,235 [INFO]  - JSON backup: db\\Chinook\\sqlite\\table_summaries.json\n"
          ]
        }
      ],
      "source": [
        "from utils.llm.get_prompt_temp import TABLE_INFO_PROMPT\n",
        "from utils.llm.get_llm_func import get_llm_func\n",
        "\n",
        "\n",
        "class TableInfo(BaseModel):\n",
        "    \"\"\"Information regarding a structured table.\"\"\"\n",
        "\n",
        "    table_name: str = Field(\n",
        "        ..., description=\"table name (must be underscores and NO spaces)\"\n",
        "    )\n",
        "    table_summary: str = Field(\n",
        "        ..., description=\"short, concise summary/caption of the table\"\n",
        "    )\n",
        "\n",
        "\n",
        "program = LLMTextCompletionProgram.from_defaults(\n",
        "    output_cls=TableInfo,\n",
        "    prompt_template_str=TABLE_INFO_PROMPT,\n",
        "    llm=get_llm_func(),\n",
        ")\n",
        "\n",
        "\n",
        "def extract_first_json_block(text: str):\n",
        "    logger.info(\"Extracting the first valid JSON object from text, ignoring extra trailing text.\")\n",
        "    \n",
        "    match = re.search(r\"\\{.*\\}\", text, re.S)\n",
        "    if not match:\n",
        "        logger.error(f\"No JSON object found in text: {text}\")\n",
        "        raise ValueError(\"No JSON object found in output\")\n",
        "    \n",
        "    try:\n",
        "        logger.info(f\"Extracted JSON: {match.group()}\")\n",
        "        return pyjson.loads(match.group())\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to parse JSON: {e}\\nRaw text: {text}\")\n",
        "        raise ValueError(f\"Failed to parse JSON: {e}\\nRaw text: {text}\")\n",
        "\n",
        "\n",
        "os.makedirs(SQLITE_DB_DIR, exist_ok=True)\n",
        "SUMMARY_DB_PATH = os.path.join(SQLITE_DB_DIR, \"table_summaries.db\")\n",
        "\n",
        "logger.info(f\"Creating SQLite DB Engine for the new summaries database: {SUMMARY_DB_PATH}\")\n",
        "summary_engine = create_engine(f\"sqlite:///{SUMMARY_DB_PATH}\")\n",
        "\n",
        "logger.info(f\" - Ensuring the table exists (id, table_name, table_summary, created_at)\")\n",
        "with summary_engine.begin() as conn:\n",
        "    conn.execute(text(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS table_summaries (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        table_name TEXT NOT NULL,\n",
        "        table_summary TEXT NOT NULL,\n",
        "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "    )\n",
        "    \"\"\"))\n",
        "\n",
        "table_infos = []\n",
        "\n",
        "logger.info(f\"Creating SQLite DB Engine for the existing Chinook database at {CHINOOK_DBEAVER_DB_PATH}\")\n",
        "engine = create_engine(f\"sqlite:///{CHINOOK_DBEAVER_DB_PATH}\")\n",
        "inspector = inspect(engine)\n",
        "\n",
        "logger.info(\"Generating table summaries...\")\n",
        "with engine.connect() as conn:\n",
        "    existing_tables = set()\n",
        "    \n",
        "    logger.info(\"Fetching existing summaries from the summaries database...\")\n",
        "    with summary_engine.connect() as summary_conn:\n",
        "        rows = summary_conn.execute(text(\"SELECT table_name FROM table_summaries\")).fetchall()\n",
        "        existing_tables = {row[0] for row in rows}\n",
        "        logger.info(f\"Found {len(existing_tables)} existing summaries in DB\")\n",
        "    \n",
        "    for idx, table in enumerate(inspector.get_table_names()):\n",
        "        if table in existing_tables:\n",
        "            logger.info(f\" - Skipping table '{table}' — summary already exists.\")\n",
        "            continue\n",
        "        \n",
        "        logger.info(f\" - Processing new table: {table}\")\n",
        "        df = pd.read_sql(f\"SELECT * FROM {table} LIMIT 10;\", conn)\n",
        "        df_str = df.to_csv(index=False)\n",
        "\n",
        "        table_info = None\n",
        "        for attempt in range(MAX_RETRIES):\n",
        "            try:\n",
        "                raw_output = program(\n",
        "                    table_str=df_str,\n",
        "                    exclude_table_name_list=str(list(inspector.get_table_names())),\n",
        "                )\n",
        "\n",
        "                logger.info(f\"Normalize LLM output\")\n",
        "                if isinstance(raw_output, str):\n",
        "                    parsed_dict = extract_first_json_block(raw_output)\n",
        "                elif isinstance(raw_output, dict):\n",
        "                    parsed_dict = raw_output\n",
        "                elif isinstance(raw_output, TableInfo):\n",
        "                    parsed_dict = raw_output.model_dump()\n",
        "                else:\n",
        "                    logger.error(f\"Unexpected return type: {type(raw_output)}\")\n",
        "                    raise TypeError(f\"Unexpected return type: {type(raw_output)}\")\n",
        "\n",
        "                table_info = TableInfo(\n",
        "                    table_name=table,  # use actual SQLAlchemy inspector name\n",
        "                    table_summary=parsed_dict[\"table_summary\"],\n",
        "                )\n",
        "\n",
        "                logger.info(f\"Processed table: {table_info.table_name}\")\n",
        "                break  # success → next table\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error with attempt {attempt+1} for {table}: {e}\")\n",
        "                time.sleep(2)\n",
        "\n",
        "        if table_info:\n",
        "            table_infos.append(table_info)\n",
        "            \n",
        "            try:\n",
        "                logger.info(f\"Saving table summary for {table_info.table_name} immediately to summaries DB\")\n",
        "                with summary_engine.begin() as conn2:\n",
        "                    conn2.execute(\n",
        "                        text(\"INSERT INTO table_summaries (table_name, table_summary) VALUES (:name, :summary)\"),\n",
        "                        {\"name\": table_info.table_name, \"summary\": table_info.table_summary},\n",
        "                    )\n",
        "                \n",
        "                logger.debug(\"JSON dump for testing purposes only\")\n",
        "                json_path = os.path.join(SQLITE_DB_DIR, \"table_summaries.json\")\n",
        "                with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    json.dump([t.model_dump() for t in table_infos], f, indent=2, ensure_ascii=False)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Failed to save table summary for {table_info.table_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "logger.info(\"\\n FINAL TABLE SUMMARIES\")\n",
        "for t in table_infos:\n",
        "    logger.info(f\"- {t.table_name}: {t.table_summary}\")\n",
        "\n",
        "logger.info(f\"\\nSaved {len(table_infos)} summaries to:\")\n",
        "logger.info(f\" - SQLite DB: {SUMMARY_DB_PATH}\")\n",
        "logger.info(f\" - JSON backup: {json_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "53544059-de7d-48dd-8e00-89517964852b",
      "metadata": {
        "id": "53544059-de7d-48dd-8e00-89517964852b",
        "outputId": "df224651-1765-4aa7-e841-d58546c20e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-20 20:32:22,787 [INFO] Table Schemas\n",
            "2025-08-20 20:32:22,789 [INFO] \n",
            "Table: Album\n",
            "2025-08-20 20:32:22,790 [INFO]   AlbumId: INTEGER\n",
            "2025-08-20 20:32:22,791 [INFO]   Title: NVARCHAR(160)\n",
            "2025-08-20 20:32:22,791 [INFO]   ArtistId: INTEGER\n",
            "2025-08-20 20:32:22,792 [INFO] \n",
            "Table: Artist\n",
            "2025-08-20 20:32:22,793 [INFO]   ArtistId: INTEGER\n",
            "2025-08-20 20:32:22,793 [INFO]   Name: NVARCHAR(120)\n",
            "2025-08-20 20:32:22,795 [INFO] \n",
            "Table: Customer\n",
            "2025-08-20 20:32:22,797 [INFO]   CustomerId: INTEGER\n",
            "2025-08-20 20:32:22,800 [INFO]   FirstName: NVARCHAR(40)\n",
            "2025-08-20 20:32:22,800 [INFO]   LastName: NVARCHAR(20)\n",
            "2025-08-20 20:32:22,801 [INFO]   Company: NVARCHAR(80)\n",
            "2025-08-20 20:32:22,801 [INFO]   Address: NVARCHAR(70)\n",
            "2025-08-20 20:32:22,802 [INFO]   City: NVARCHAR(40)\n",
            "2025-08-20 20:32:22,802 [INFO]   State: NVARCHAR(40)\n",
            "2025-08-20 20:32:22,803 [INFO]   Country: NVARCHAR(40)\n",
            "2025-08-20 20:32:22,804 [INFO]   PostalCode: NVARCHAR(10)\n",
            "2025-08-20 20:32:22,804 [INFO]   Phone: NVARCHAR(24)\n",
            "2025-08-20 20:32:22,805 [INFO]   Fax: NVARCHAR(24)\n",
            "2025-08-20 20:32:22,805 [INFO]   Email: NVARCHAR(60)\n",
            "2025-08-20 20:32:22,806 [INFO]   SupportRepId: INTEGER\n",
            "2025-08-20 20:32:22,808 [INFO] \n",
            "Table: Employee\n",
            "2025-08-20 20:32:22,808 [INFO]   EmployeeId: INTEGER\n",
            "2025-08-20 20:32:22,809 [INFO]   LastName: NVARCHAR(20)\n",
            "2025-08-20 20:32:22,809 [INFO]   FirstName: NVARCHAR(20)\n",
            "2025-08-20 20:32:22,810 [INFO]   Title: NVARCHAR(30)\n",
            "2025-08-20 20:32:22,811 [INFO]   ReportsTo: INTEGER\n",
            "2025-08-20 20:32:22,811 [INFO]   BirthDate: DATETIME\n",
            "2025-08-20 20:32:22,812 [INFO]   HireDate: DATETIME\n",
            "2025-08-20 20:32:22,813 [INFO]   Address: NVARCHAR(70)\n",
            "2025-08-20 20:32:22,814 [INFO]   City: NVARCHAR(40)\n",
            "2025-08-20 20:32:22,814 [INFO]   State: NVARCHAR(40)\n",
            "2025-08-20 20:32:22,815 [INFO]   Country: NVARCHAR(40)\n",
            "2025-08-20 20:32:22,816 [INFO]   PostalCode: NVARCHAR(10)\n",
            "2025-08-20 20:32:22,817 [INFO]   Phone: NVARCHAR(24)\n",
            "2025-08-20 20:32:22,819 [INFO]   Fax: NVARCHAR(24)\n",
            "2025-08-20 20:32:22,820 [INFO]   Email: NVARCHAR(60)\n",
            "2025-08-20 20:32:22,821 [INFO] \n",
            "Table: Genre\n",
            "2025-08-20 20:32:22,823 [INFO]   GenreId: INTEGER\n",
            "2025-08-20 20:32:22,823 [INFO]   Name: NVARCHAR(120)\n",
            "2025-08-20 20:32:22,825 [INFO] \n",
            "Table: Invoice\n",
            "2025-08-20 20:32:22,827 [INFO]   InvoiceId: INTEGER\n",
            "2025-08-20 20:32:22,829 [INFO]   CustomerId: INTEGER\n",
            "2025-08-20 20:32:22,830 [INFO]   InvoiceDate: DATETIME\n",
            "2025-08-20 20:32:22,831 [INFO]   BillingAddress: NVARCHAR(70)\n",
            "2025-08-20 20:32:22,831 [INFO]   BillingCity: NVARCHAR(40)\n",
            "2025-08-20 20:32:22,832 [INFO]   BillingState: NVARCHAR(40)\n",
            "2025-08-20 20:32:22,833 [INFO]   BillingCountry: NVARCHAR(40)\n",
            "2025-08-20 20:32:22,834 [INFO]   BillingPostalCode: NVARCHAR(10)\n",
            "2025-08-20 20:32:22,834 [INFO]   Total: NUMERIC(10, 2)\n",
            "2025-08-20 20:32:22,836 [INFO] \n",
            "Table: InvoiceLine\n",
            "2025-08-20 20:32:22,837 [INFO]   InvoiceLineId: INTEGER\n",
            "2025-08-20 20:32:22,838 [INFO]   InvoiceId: INTEGER\n",
            "2025-08-20 20:32:22,840 [INFO]   TrackId: INTEGER\n",
            "2025-08-20 20:32:22,841 [INFO]   UnitPrice: NUMERIC(10, 2)\n",
            "2025-08-20 20:32:22,842 [INFO]   Quantity: INTEGER\n",
            "2025-08-20 20:32:22,844 [INFO] \n",
            "Table: MediaType\n",
            "2025-08-20 20:32:22,845 [INFO]   MediaTypeId: INTEGER\n",
            "2025-08-20 20:32:22,845 [INFO]   Name: NVARCHAR(120)\n",
            "2025-08-20 20:32:22,846 [INFO] \n",
            "Table: Playlist\n",
            "2025-08-20 20:32:22,847 [INFO]   PlaylistId: INTEGER\n",
            "2025-08-20 20:32:22,848 [INFO]   Name: NVARCHAR(120)\n",
            "2025-08-20 20:32:22,849 [INFO] \n",
            "Table: PlaylistTrack\n",
            "2025-08-20 20:32:22,849 [INFO]   PlaylistId: INTEGER\n",
            "2025-08-20 20:32:22,850 [INFO]   TrackId: INTEGER\n",
            "2025-08-20 20:32:22,851 [INFO] \n",
            "Table: Track\n",
            "2025-08-20 20:32:22,852 [INFO]   TrackId: INTEGER\n",
            "2025-08-20 20:32:22,852 [INFO]   Name: NVARCHAR(200)\n",
            "2025-08-20 20:32:22,853 [INFO]   AlbumId: INTEGER\n",
            "2025-08-20 20:32:22,854 [INFO]   MediaTypeId: INTEGER\n",
            "2025-08-20 20:32:22,855 [INFO]   GenreId: INTEGER\n",
            "2025-08-20 20:32:22,857 [INFO]   Composer: NVARCHAR(220)\n",
            "2025-08-20 20:32:22,858 [INFO]   Milliseconds: INTEGER\n",
            "2025-08-20 20:32:22,859 [INFO]   Bytes: INTEGER\n",
            "2025-08-20 20:32:22,861 [INFO]   UnitPrice: NUMERIC(10, 2)\n"
          ]
        }
      ],
      "source": [
        "def get_table_schema(table_name: str):\n",
        "    \"\"\"Fetch column names and types for an existing table.\"\"\"\n",
        "    columns = inspector.get_columns(table_name)\n",
        "    schema = {col[\"name\"]: str(col[\"type\"]) for col in columns}\n",
        "    return schema\n",
        "\n",
        "\n",
        "logger.info(\"Table Schemas\")\n",
        "for table_name in inspector.get_table_names():\n",
        "    schema = get_table_schema(table_name)\n",
        "    logger.info(f\"\\nTable: {table_name}\")\n",
        "    for col, dtype in schema.items():\n",
        "        logger.info(f\"  {col}: {dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f12a34b5-1d91-4e85-a6ce-97adb5ddfa06",
      "metadata": {
        "id": "f12a34b5-1d91-4e85-a6ce-97adb5ddfa06",
        "outputId": "4527a7d1-6b5f-4f89-9a63-e5263f4e4441"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:148: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
            "  next(self.gen)\n",
            "C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:148: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
            "  next(self.gen)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
            "📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
            "2025-08-20 20:28:48,100 [INFO] Phoenix launched and global handler set.\n"
          ]
        }
      ],
      "source": [
        "px.launch_app()\n",
        "set_global_handler(\"arize_phoenix\")\n",
        "\n",
        "# logger.info(\"🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\")\n",
        "# logger.info(\"📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\")\n",
        "\n",
        "logger.info(\"Phoenix launched and global handler set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "266b9e05",
      "metadata": {},
      "source": [
        "1. Object index, retriever, SQLDatabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8a89bc36-a5ac-46bf-b9ae-801f34992019",
      "metadata": {
        "id": "8a89bc36-a5ac-46bf-b9ae-801f34992019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-20 20:32:28,872 [INFO] Wrapping engine into LlamaIndex SQLDatabase\n",
            "2025-08-20 20:32:28,906 [INFO] Creating table node mapping, i.e. mapping from SQL tables -> nodes\n",
            "2025-08-20 20:32:28,907 [INFO] Loading all existing summaries from SQLite DB\n",
            "2025-08-20 20:32:28,910 [INFO] Filtering out only valid tables from loaded summaries that exist in the db\n",
            "2025-08-20 20:32:28,913 [INFO] Adding table: Album with summary: Summary of album data\n",
            "2025-08-20 20:32:28,915 [INFO] Adding table: Customer with summary: Summary of customer data including ID, name, company, etc.\n",
            "2025-08-20 20:32:28,920 [INFO] Adding table: Employee with summary: Summary of employee data\n",
            "2025-08-20 20:32:28,921 [INFO] Adding table: Genre with summary: Summary of genre data\n",
            "2025-08-20 20:32:28,922 [INFO] Adding table: Invoice with summary: Summary of invoice details\n",
            "2025-08-20 20:32:28,922 [INFO] Adding table: InvoiceLine with summary: Summary of invoice and track details\n",
            "2025-08-20 20:32:28,923 [INFO] Adding table: MediaType with summary: Summary of media type categories\n",
            "2025-08-20 20:32:28,924 [INFO] Adding table: Playlist with summary: Summary of playlist data including different categories\n",
            "2025-08-20 20:32:28,925 [INFO] Adding table: PlaylistTrack with summary: Summary of playlist and track data\n",
            "2025-08-20 20:32:28,926 [INFO] Adding table: Track with summary: Summary of track data\n",
            "2025-08-20 20:32:28,927 [INFO] Adding table: Artist with summary: Summary of artist data\n",
            "2025-08-20 20:32:28,928 [INFO] Building object index for table retrieval\n",
            "2025-08-20 20:32:32,903 [INFO] Creating SQL retriever for query execution\n"
          ]
        }
      ],
      "source": [
        "from utils.llm.get_llm_func import get_embedding_func\n",
        "from utils.llm.get_prompt_temp import RESPONSE_SYNTHESIS_PROMPT\n",
        "\n",
        "\n",
        "logger.info(\"Wrapping engine into LlamaIndex SQLDatabase\")\n",
        "sql_database = SQLDatabase(engine)\n",
        "\n",
        "logger.info(\"Creating table node mapping, i.e. mapping from SQL tables -> nodes\")\n",
        "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
        "\n",
        "logger.info(\"Loading all existing summaries from SQLite DB\")\n",
        "with summary_engine.connect() as conn:\n",
        "    rows = conn.execute(text(\"SELECT table_name, table_summary FROM table_summaries\")).fetchall()\n",
        "\n",
        "logger.info(\"Filtering out only valid tables from loaded summaries that exist in the db\")\n",
        "table_schema_objs = []\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    inspector = inspect(conn)\n",
        "    existing_tables = inspector.get_table_names()\n",
        "\n",
        "# for t in table_infos:\n",
        "#     if t.table_name in existing_tables and t.table_summary:\n",
        "#         table_schema_objs.append(\n",
        "#             SQLTableSchema(table_name=t.table_name, context_str=t.table_summary)\n",
        "#         )\n",
        "#         logger.info(f\"Adding table: {t.table_name} with summary: {t.table_summary}\")\n",
        "#     else:\n",
        "#         logger.warning(f\"Skipping missing/unextracted table: {t.table_name}\")\n",
        "\n",
        "for row in rows:\n",
        "    if row.table_name in existing_tables and row.table_summary:\n",
        "        table_schema_objs.append(\n",
        "            SQLTableSchema(table_name=row.table_name, context_str=row.table_summary)\n",
        "        )\n",
        "        logger.info(f\"Adding table: {row.table_name} with summary: {row.table_summary}\")\n",
        "    else:\n",
        "        logger.warning(f\"Skipping missing/unextracted table: {row.table_name}\")\n",
        "\n",
        "logger.info(\"Building object index for table retrieval\")\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    table_schema_objs,\n",
        "    table_node_mapping,\n",
        "    VectorStoreIndex,\n",
        "    embed_model=get_embedding_func(),\n",
        ")\n",
        "obj_retriever = obj_index.as_retriever(similarity_top_k=TOP_K)\n",
        "\n",
        "logger.info(\"Creating SQL retriever for query execution\")\n",
        "sql_retriever = SQLRetriever(sql_database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b25bf248",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-20 20:32:32,918 [INFO] Table Context: Table 'Album' has columns: AlbumId (INTEGER), Title (NVARCHAR(160)), ArtistId (INTEGER),  and foreign keys: ['ArtistId'] -> Artist.['ArtistId']. The table description is: Summary of album data\n",
            "\n",
            "Table 'Customer' has columns: CustomerId (INTEGER), FirstName (NVARCHAR(40)), LastName (NVARCHAR(20)), Company (NVARCHAR(80)), Address (NVARCHAR(70)), City (NVARCHAR(40)), State (NVARCHAR(40)), Country (NVARCHAR(40)), PostalCode (NVARCHAR(10)), Phone (NVARCHAR(24)), Fax (NVARCHAR(24)), Email (NVARCHAR(60)), SupportRepId (INTEGER),  and foreign keys: ['SupportRepId'] -> Employee.['EmployeeId']. The table description is: Summary of customer data including ID, name, company, etc.\n",
            "\n",
            "Table 'Employee' has columns: EmployeeId (INTEGER), LastName (NVARCHAR(20)), FirstName (NVARCHAR(20)), Title (NVARCHAR(30)), ReportsTo (INTEGER), BirthDate (DATETIME), HireDate (DATETIME), Address (NVARCHAR(70)), City (NVARCHAR(40)), State (NVARCHAR(40)), Country (NVARCHAR(40)), PostalCode (NVARCHAR(10)), Phone (NVARCHAR(24)), Fax (NVARCHAR(24)), Email (NVARCHAR(60)),  and foreign keys: ['ReportsTo'] -> Employee.['EmployeeId']. The table description is: Summary of employee data\n",
            "\n",
            "Table 'Genre' has columns: GenreId (INTEGER), Name (NVARCHAR(120)), . The table description is: Summary of genre data\n",
            "\n",
            "Table 'Invoice' has columns: InvoiceId (INTEGER), CustomerId (INTEGER), InvoiceDate (DATETIME), BillingAddress (NVARCHAR(70)), BillingCity (NVARCHAR(40)), BillingState (NVARCHAR(40)), BillingCountry (NVARCHAR(40)), BillingPostalCode (NVARCHAR(10)), Total (NUMERIC(10, 2)),  and foreign keys: ['CustomerId'] -> Customer.['CustomerId']. The table description is: Summary of invoice details\n",
            "\n",
            "Table 'InvoiceLine' has columns: InvoiceLineId (INTEGER), InvoiceId (INTEGER), TrackId (INTEGER), UnitPrice (NUMERIC(10, 2)), Quantity (INTEGER),  and foreign keys: ['TrackId'] -> Track.['TrackId'], ['InvoiceId'] -> Invoice.['InvoiceId']. The table description is: Summary of invoice and track details\n",
            "\n",
            "Table 'MediaType' has columns: MediaTypeId (INTEGER), Name (NVARCHAR(120)), . The table description is: Summary of media type categories\n",
            "\n",
            "Table 'Playlist' has columns: PlaylistId (INTEGER), Name (NVARCHAR(120)), . The table description is: Summary of playlist data including different categories\n",
            "\n",
            "Table 'PlaylistTrack' has columns: PlaylistId (INTEGER), TrackId (INTEGER),  and foreign keys: ['TrackId'] -> Track.['TrackId'], ['PlaylistId'] -> Playlist.['PlaylistId']. The table description is: Summary of playlist and track data\n",
            "\n",
            "Table 'Track' has columns: TrackId (INTEGER), Name (NVARCHAR(200)), AlbumId (INTEGER), MediaTypeId (INTEGER), GenreId (INTEGER), Composer (NVARCHAR(220)), Milliseconds (INTEGER), Bytes (INTEGER), UnitPrice (NUMERIC(10, 2)),  and foreign keys: ['MediaTypeId'] -> MediaType.['MediaTypeId'], ['GenreId'] -> Genre.['GenreId'], ['AlbumId'] -> Album.['AlbumId']. The table description is: Summary of track data\n",
            "\n",
            "Table 'Artist' has columns: ArtistId (INTEGER), Name (NVARCHAR(120)), . The table description is: Summary of artist data\n"
          ]
        }
      ],
      "source": [
        "# Table Context String\n",
        "def get_table_context_str(table_schema_objs: List[SQLTableSchema]):\n",
        "    \"\"\"Get table context string (schema + summary).\"\"\"\n",
        "    context_strs = []\n",
        "    for table_schema_obj in table_schema_objs:\n",
        "        try:\n",
        "            # pull schema directly from DB\n",
        "            table_info = sql_database.get_single_table_info(\n",
        "                table_schema_obj.table_name\n",
        "            )\n",
        "            if table_schema_obj.context_str:\n",
        "                table_opt_context = \" The table description is: \"\n",
        "                table_opt_context += table_schema_obj.context_str\n",
        "                table_info += table_opt_context\n",
        "            context_strs.append(table_info)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Skipping table {table_schema_obj.table_name}: {e}\")\n",
        "    return \"\\n\\n\".join(context_strs)\n",
        "\n",
        "\n",
        "table_parser_component = get_table_context_str(table_schema_objs)\n",
        "logger.info(f\"Table Context: {table_parser_component}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9e8a31c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-20 20:32:36,280 [INFO] \n",
            " Text-to-SQL Prompt: Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.\n",
            "\n",
            "Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
            "\n",
            "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
            "\n",
            "Question: Question here\n",
            "SQLQuery: SQL Query to run\n",
            "SQLResult: Result of the SQLQuery\n",
            "Answer: Final answer here\n",
            "\n",
            "Only use tables listed below.\n",
            "{schema}\n",
            "\n",
            "Question: {query_str}\n",
            "SQLQuery: \n"
          ]
        }
      ],
      "source": [
        "# SQL Output Parser\n",
        "def parse_response_to_sql(response: ChatResponse) -> str:\n",
        "    \"\"\"Parse response into a clean SQL string.\"\"\"\n",
        "    response = response.message.content\n",
        "\n",
        "    sql_query_start = response.find(\"SQLQuery:\")\n",
        "    if sql_query_start != -1:\n",
        "        response = response[sql_query_start:]\n",
        "        if response.startswith(\"SQLQuery:\"):\n",
        "            response = response[len(\"SQLQuery:\") :]\n",
        "\n",
        "    sql_result_start = response.find(\"SQLResult:\")\n",
        "    if sql_result_start != -1:\n",
        "        response = response[:sql_result_start]\n",
        "\n",
        "    return response.strip().strip(\"```\").strip()\n",
        "\n",
        "\n",
        "sql_parser_component = FunctionTool.from_defaults(fn=parse_response_to_sql)\n",
        "\n",
        "\n",
        "# Prompts\n",
        "text2sql_prompt = DEFAULT_TEXT_TO_SQL_PROMPT.partial_format(\n",
        "    dialect=engine.dialect.name\n",
        ")\n",
        "logger.info(f\"\\n Text-to-SQL Prompt: {text2sql_prompt.template}\")\n",
        "\n",
        "\n",
        "response_synthesis_prompt = PromptTemplate(RESPONSE_SYNTHESIS_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15203320",
      "metadata": {},
      "source": [
        "### Index Each Table\n",
        "\n",
        "We embed/index the rows of each table, resulting in one index per table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b103cbc0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-20 20:32:38,871 [INFO]  [00] Creating persistent Chroma client at: db\\Chinook\\chromadb\n",
            "2025-08-20 20:32:38,920 [INFO] [01] Processing table: Album\n",
            "2025-08-20 20:32:38,948 [INFO] [03] Reusing existing collection with 347 items: Album\n",
            "2025-08-20 20:32:38,950 [INFO] [04] Successfully indexed table: Album\n",
            "2025-08-20 20:32:38,951 [INFO] [01] Processing table: Artist\n",
            "2025-08-20 20:32:38,977 [INFO] [03] Reusing existing collection with 275 items: Artist\n",
            "2025-08-20 20:32:38,979 [INFO] [04] Successfully indexed table: Artist\n",
            "2025-08-20 20:32:38,980 [INFO] [01] Processing table: Customer\n",
            "2025-08-20 20:32:39,005 [INFO] [03] Reusing existing collection with 59 items: Customer\n",
            "2025-08-20 20:32:39,012 [INFO] [04] Successfully indexed table: Customer\n",
            "2025-08-20 20:32:39,012 [INFO] [01] Processing table: Employee\n",
            "2025-08-20 20:32:39,035 [INFO] [03] Reusing existing collection with 8 items: Employee\n",
            "2025-08-20 20:32:39,039 [INFO] [04] Successfully indexed table: Employee\n",
            "2025-08-20 20:32:39,040 [INFO] [01] Processing table: Genre\n",
            "2025-08-20 20:32:39,065 [INFO] [03] Reusing existing collection with 25 items: Genre\n",
            "2025-08-20 20:32:39,067 [INFO] [04] Successfully indexed table: Genre\n",
            "2025-08-20 20:32:39,068 [INFO] [01] Processing table: Invoice\n",
            "2025-08-20 20:32:39,090 [INFO] [03] Reusing existing collection with 412 items: Invoice\n",
            "2025-08-20 20:32:39,095 [INFO] [04] Successfully indexed table: Invoice\n",
            "2025-08-20 20:32:39,095 [INFO] [01] Processing table: InvoiceLine\n",
            "2025-08-20 20:32:39,115 [INFO] [03] Reusing existing collection with 2240 items: InvoiceLine\n",
            "2025-08-20 20:32:39,118 [INFO] [04] Successfully indexed table: InvoiceLine\n",
            "2025-08-20 20:32:39,119 [INFO] [01] Processing table: MediaType\n",
            "2025-08-20 20:32:39,145 [INFO] [03] Reusing existing collection with 5 items: MediaType\n",
            "2025-08-20 20:32:39,148 [INFO] [04] Successfully indexed table: MediaType\n",
            "2025-08-20 20:32:39,149 [INFO] [01] Processing table: Playlist\n",
            "2025-08-20 20:32:39,171 [INFO] [03] Reusing existing collection with 18 items: Playlist\n",
            "2025-08-20 20:32:39,175 [INFO] [04] Successfully indexed table: Playlist\n",
            "2025-08-20 20:32:39,177 [INFO] [01] Processing table: PlaylistTrack\n",
            "2025-08-20 20:32:39,203 [INFO] [03] Reusing existing collection with 8715 items: PlaylistTrack\n",
            "2025-08-20 20:32:39,206 [INFO] [04] Successfully indexed table: PlaylistTrack\n",
            "2025-08-20 20:32:39,207 [INFO] [01] Processing table: Track\n",
            "2025-08-20 20:32:39,235 [INFO] [03] Reusing existing collection with 3503 items: Track\n",
            "2025-08-20 20:32:39,238 [INFO] [04] Successfully indexed table: Track\n",
            "2025-08-20 20:32:39,240 [INFO] [05] Successfully indexed 11 tables\n"
          ]
        }
      ],
      "source": [
        "def index_all_tables_with_chroma(sql_database, chroma_db_dir: str = CHROMA_DB_DIR) -> Dict[str, VectorStoreIndex]:\n",
        "    \"\"\"Index all tables in the SQL database using ChromaDB as the backend.\n",
        "    Args:\n",
        "        sql_database: SQLDatabase instance\n",
        "        chroma_db_dir: Directory for ChromaDB persistence\n",
        "        \n",
        "    Returns:\n",
        "        Dict mapping table names to VectorStoreIndex instances\n",
        "    \"\"\"\n",
        "    os.makedirs(chroma_db_dir, exist_ok=True)\n",
        "\n",
        "    vector_index_dict = {}\n",
        "    engine = sql_database.engine\n",
        "\n",
        "    logger.info(f\" [00] Creating persistent Chroma client at: {chroma_db_dir}\")\n",
        "    chroma_client = chromadb.PersistentClient(path=chroma_db_dir)\n",
        "\n",
        "    for table_name in sql_database.get_usable_table_names():\n",
        "        logger.info(f\"[01] Processing table: {table_name}\")\n",
        "        \n",
        "        try:\n",
        "            # Create or get collection - ChromaDB handles persistence internally\n",
        "            collection = chroma_client.get_or_create_collection(name=f\"table_{table_name}\")\n",
        "            \n",
        "            # Check if collection already has data\n",
        "            if collection.count() == 0:\n",
        "                logger.info(f\"[02] Building new index for empty collection: {table_name}\")\n",
        "                \n",
        "                # Fetch data from database\n",
        "                with engine.connect() as conn:\n",
        "                    result = conn.execute(text(f'SELECT * FROM \"{table_name}\"'))\n",
        "                    col_names = list(result.keys())\n",
        "                    rows = result.fetchall()\n",
        "                \n",
        "                if not rows:\n",
        "                    logger.warning(f\"[02.1] Table {table_name} is empty, skipping...\")\n",
        "                    continue\n",
        "                \n",
        "                logger.info(f\"[02.2] Converting {len(rows)} rows to structured text\")\n",
        "                row_texts = [\n",
        "                    \" | \".join([f\"{col}={val}\" for col, val in zip(col_names, row)])\n",
        "                    for row in rows\n",
        "                ]\n",
        "                \n",
        "                # Create TextNodes with proper IDs\n",
        "                nodes = [\n",
        "                    TextNode(\n",
        "                        text=row_text, \n",
        "                        id_=f\"{table_name}_row_{idx}\"\n",
        "                    ) \n",
        "                    for idx, row_text in enumerate(row_texts)\n",
        "                ]\n",
        "                \n",
        "                logger.info(f\"[02.3] Creating vector store for table: {table_name}\")\n",
        "                vector_store = ChromaVectorStore(chroma_collection=collection)\n",
        "                \n",
        "                # Create index - this will automatically add nodes to ChromaDB\n",
        "                logger.info(f\"[02.4] Building vector index with {len(nodes)} nodes\")\n",
        "                storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "                index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
        "                \n",
        "                logger.info(f\"[02.5] Index created successfully for table: {table_name}\")\n",
        "                \n",
        "            else:\n",
        "                logger.info(f\"[03] Reusing existing collection with {collection.count()} items: {table_name}\")\n",
        "                \n",
        "                # Create vector store from existing collection\n",
        "                vector_store = ChromaVectorStore(chroma_collection=collection)\n",
        "                storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "                \n",
        "                # Create index from existing vector store\n",
        "                index = VectorStoreIndex.from_vector_store(\n",
        "                    vector_store=vector_store,\n",
        "                    storage_context=storage_context\n",
        "                )\n",
        "            \n",
        "            vector_index_dict[table_name] = index\n",
        "            logger.info(f\"[04] Successfully indexed table: {table_name}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"[ERROR] Failed to index table {table_name}: {str(e)}\")\n",
        "            raise\n",
        "    \n",
        "    logger.info(f\"[05] Successfully indexed {len(vector_index_dict)} tables\")\n",
        "    return vector_index_dict\n",
        "\n",
        "# Build vector indexes for all tables using ChromaDB\n",
        "vector_index_dict = index_all_tables_with_chroma(sql_database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "31906c11",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-20 20:32:44,981 [INFO] [01] Getting schema for table: Album\n",
            "2025-08-20 20:32:44,983 [INFO] [02] Retrieving example rows for table: Album\n",
            "2025-08-20 20:32:45,028 [INFO] [03] Retrieved 2 relevant nodes for table: Album\n",
            "2025-08-20 20:32:45,031 [INFO] [01] Getting schema for table: Customer\n",
            "2025-08-20 20:32:45,032 [INFO] [02] Retrieving example rows for table: Customer\n",
            "2025-08-20 20:32:45,074 [INFO] [03] Retrieved 2 relevant nodes for table: Customer\n",
            "2025-08-20 20:32:45,076 [INFO] [01] Getting schema for table: Employee\n",
            "2025-08-20 20:32:45,077 [INFO] [02] Retrieving example rows for table: Employee\n",
            "2025-08-20 20:32:45,132 [INFO] [03] Retrieved 2 relevant nodes for table: Employee\n",
            "2025-08-20 20:32:45,133 [INFO] [01] Getting schema for table: Genre\n",
            "2025-08-20 20:32:45,135 [INFO] [02] Retrieving example rows for table: Genre\n",
            "2025-08-20 20:32:45,335 [INFO] [03] Retrieved 2 relevant nodes for table: Genre\n",
            "2025-08-20 20:32:45,336 [INFO] [01] Getting schema for table: Invoice\n",
            "2025-08-20 20:32:45,337 [INFO] [02] Retrieving example rows for table: Invoice\n",
            "2025-08-20 20:32:45,370 [INFO] [03] Retrieved 2 relevant nodes for table: Invoice\n",
            "2025-08-20 20:32:45,371 [INFO] [01] Getting schema for table: InvoiceLine\n",
            "2025-08-20 20:32:45,372 [INFO] [02] Retrieving example rows for table: InvoiceLine\n",
            "2025-08-20 20:32:45,444 [INFO] [03] Retrieved 2 relevant nodes for table: InvoiceLine\n",
            "2025-08-20 20:32:45,445 [INFO] [01] Getting schema for table: MediaType\n",
            "2025-08-20 20:32:45,447 [INFO] [02] Retrieving example rows for table: MediaType\n",
            "2025-08-20 20:32:45,538 [INFO] [03] Retrieved 2 relevant nodes for table: MediaType\n",
            "2025-08-20 20:32:45,540 [INFO] [01] Getting schema for table: Playlist\n",
            "2025-08-20 20:32:45,542 [INFO] [02] Retrieving example rows for table: Playlist\n",
            "2025-08-20 20:32:45,658 [INFO] [03] Retrieved 2 relevant nodes for table: Playlist\n",
            "2025-08-20 20:32:45,660 [INFO] [01] Getting schema for table: PlaylistTrack\n",
            "2025-08-20 20:32:45,661 [INFO] [02] Retrieving example rows for table: PlaylistTrack\n",
            "2025-08-20 20:32:45,794 [INFO] [03] Retrieved 2 relevant nodes for table: PlaylistTrack\n",
            "2025-08-20 20:32:45,795 [INFO] [01] Getting schema for table: Track\n",
            "2025-08-20 20:32:45,796 [INFO] [02] Retrieving example rows for table: Track\n",
            "2025-08-20 20:32:45,913 [INFO] [03] Retrieved 2 relevant nodes for table: Track\n",
            "2025-08-20 20:32:45,915 [INFO] [01] Getting schema for table: Artist\n",
            "2025-08-20 20:32:45,917 [INFO] [02] Retrieving example rows for table: Artist\n",
            "2025-08-20 20:32:46,046 [INFO] [03] Retrieved 2 relevant nodes for table: Artist\n",
            "2025-08-20 20:32:46,048 [INFO] Updated table context with rows:\n",
            "Table 'Album' has columns: AlbumId (INTEGER), Title (NVARCHAR(160)), ArtistId (INTEGER),  and foreign keys: ['ArtistId'] -> Artist.['ArtistId'].\n",
            "Here are some relevant example rows (column=value):\n",
            "- AlbumId=71 | Title=Elis Regina-Minha História | ArtistId=41\n",
            "- AlbumId=124 | Title=Cafezinho | ArtistId=97\n",
            "\n",
            "\n",
            "Table 'Customer' has columns: CustomerId (INTEGER), FirstName (NVARCHAR(40)), LastName (NVARCHAR(20)), Company (NVARCHAR(80)), Address (NVARCHAR(70)), City (NVARCHAR(40)), State (NVARCHAR(40)), Country (NVARCHAR(40)), PostalCode (NVARCHAR(10)), Phone (NVARCHAR(24)), Fax (NVARCHAR(24)), Email (NVARCHAR(60)), SupportRepId (INTEGER),  and foreign keys: ['SupportRepId'] -> Employee.['EmployeeId'].\n",
            "Here are some relevant example rows (column=value):\n",
            "- CustomerId=2 | FirstName=Leonie | LastName=Köhler | Company=None | Address=Theodor-Heuss-Straße 34 | City=Stuttgart | State=None | Country=Germany | PostalCode=70174 | Phone=+49 0711 2842222 | Fax=None | Email=leonekohler@surfeu.de | SupportRepId=5\n",
            "- CustomerId=6 | FirstName=Helena | LastName=Holý | Company=None | Address=Rilská 3174/6 | City=Prague | State=None | Country=Czech Republic | PostalCode=14300 | Phone=+420 2 4177 0449 | Fax=None | Email=hholy@gmail.com | SupportRepId=5\n",
            "\n",
            "\n",
            "Table 'Employee' has columns: EmployeeId (INTEGER), LastName (NVARCHAR(20)), FirstName (NVARCHAR(20)), Title (NVARCHAR(30)), ReportsTo (INTEGER), BirthDate (DATETIME), HireDate (DATETIME), Address (NVARCHAR(70)), City (NVARCHAR(40)), State (NVARCHAR(40)), Country (NVARCHAR(40)), PostalCode (NVARCHAR(10)), Phone (NVARCHAR(24)), Fax (NVARCHAR(24)), Email (NVARCHAR(60)),  and foreign keys: ['ReportsTo'] -> Employee.['EmployeeId'].\n",
            "Here are some relevant example rows (column=value):\n",
            "- EmployeeId=4 | LastName=Park | FirstName=Margaret | Title=Sales Support Agent | ReportsTo=2 | BirthDate=1947-09-19 00:00:00 | HireDate=2003-05-03 00:00:00 | Address=683 10 Street SW | City=Calgary | State=AB | Country=Canada | PostalCode=T2P 5G3 | Phone=+1 (403) 263-4423 | Fax=+1 (403) 263-4289 | Email=margaret@chinookcorp.com\n",
            "- EmployeeId=1 | LastName=Adams | FirstName=Andrew | Title=General Manager | ReportsTo=None | BirthDate=1962-02-18 00:00:00 | HireDate=2002-08-14 00:00:00 | Address=11120 Jasper Ave NW | City=Edmonton | State=AB | Country=Canada | PostalCode=T5K 2N1 | Phone=+1 (780) 428-9482 | Fax=+1 (780) 428-3457 | Email=andrew@chinookcorp.com\n",
            "\n",
            "\n",
            "Table 'Genre' has columns: GenreId (INTEGER), Name (NVARCHAR(120)), .\n",
            "Here are some relevant example rows (column=value):\n",
            "- GenreId=25 | Name=Opera\n",
            "- GenreId=11 | Name=Bossa Nova\n",
            "\n",
            "\n",
            "Table 'Invoice' has columns: InvoiceId (INTEGER), CustomerId (INTEGER), InvoiceDate (DATETIME), BillingAddress (NVARCHAR(70)), BillingCity (NVARCHAR(40)), BillingState (NVARCHAR(40)), BillingCountry (NVARCHAR(40)), BillingPostalCode (NVARCHAR(10)), Total (NUMERIC(10, 2)),  and foreign keys: ['CustomerId'] -> Customer.['CustomerId'].\n",
            "Here are some relevant example rows (column=value):\n",
            "- InvoiceId=83 | CustomerId=42 | InvoiceDate=2009-12-26 00:00:00 | BillingAddress=9, Place Louis Barthou | BillingCity=Bordeaux | BillingState=None | BillingCountry=France | BillingPostalCode=33000 | Total=0.99\n",
            "- InvoiceId=270 | CustomerId=42 | InvoiceDate=2012-03-29 00:00:00 | BillingAddress=9, Place Louis Barthou | BillingCity=Bordeaux | BillingState=None | BillingCountry=France | BillingPostalCode=33000 | Total=8.91\n",
            "\n",
            "\n",
            "Table 'InvoiceLine' has columns: InvoiceLineId (INTEGER), InvoiceId (INTEGER), TrackId (INTEGER), UnitPrice (NUMERIC(10, 2)), Quantity (INTEGER),  and foreign keys: ['TrackId'] -> Track.['TrackId'], ['InvoiceId'] -> Invoice.['InvoiceId'].\n",
            "Here are some relevant example rows (column=value):\n",
            "- InvoiceLineId=1724 | InvoiceId=319 | TrackId=3482 | UnitPrice=0.99 | Quantity=1\n",
            "- InvoiceLineId=1817 | InvoiceId=334 | TrackId=575 | UnitPrice=0.99 | Quantity=1\n",
            "\n",
            "\n",
            "Table 'MediaType' has columns: MediaTypeId (INTEGER), Name (NVARCHAR(120)), .\n",
            "Here are some relevant example rows (column=value):\n",
            "- MediaTypeId=4 | Name=Purchased AAC audio file\n",
            "- MediaTypeId=5 | Name=AAC audio file\n",
            "\n",
            "\n",
            "Table 'Playlist' has columns: PlaylistId (INTEGER), Name (NVARCHAR(120)), .\n",
            "Here are some relevant example rows (column=value):\n",
            "- PlaylistId=11 | Name=Brazilian Music\n",
            "- PlaylistId=15 | Name=Classical 101 - The Basics\n",
            "\n",
            "\n",
            "Table 'PlaylistTrack' has columns: PlaylistId (INTEGER), TrackId (INTEGER),  and foreign keys: ['TrackId'] -> Track.['TrackId'], ['PlaylistId'] -> Playlist.['PlaylistId'].\n",
            "Here are some relevant example rows (column=value):\n",
            "- PlaylistId=5 | TrackId=1821\n",
            "- PlaylistId=8 | TrackId=1732\n",
            "\n",
            "\n",
            "Table 'Track' has columns: TrackId (INTEGER), Name (NVARCHAR(200)), AlbumId (INTEGER), MediaTypeId (INTEGER), GenreId (INTEGER), Composer (NVARCHAR(220)), Milliseconds (INTEGER), Bytes (INTEGER), UnitPrice (NUMERIC(10, 2)),  and foreign keys: ['MediaTypeId'] -> MediaType.['MediaTypeId'], ['GenreId'] -> Genre.['GenreId'], ['AlbumId'] -> Album.['AlbumId'].\n",
            "Here are some relevant example rows (column=value):\n",
            "- TrackId=3503 | Name=Koyaanisqatsi | AlbumId=347 | MediaTypeId=2 | GenreId=10 | Composer=Philip Glass | Milliseconds=206005 | Bytes=3305164 | UnitPrice=0.99\n",
            "- TrackId=1762 | Name=Panis Et Circenses | AlbumId=145 | MediaTypeId=1 | GenreId=7 | Composer=Caetano Veloso e Gilberto Gil | Milliseconds=192339 | Bytes=6318373 | UnitPrice=0.99\n",
            "\n",
            "\n",
            "Table 'Artist' has columns: ArtistId (INTEGER), Name (NVARCHAR(120)), .\n",
            "Here are some relevant example rows (column=value):\n",
            "- ArtistId=240 | Name=Gustav Mahler\n",
            "- ArtistId=253 | Name=Calexico\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_table_context_and_rows_str(query_str: str, table_schema_objs: List[TableInfo]) -> str:\n",
        "    \"\"\"Get table context string for relevant example rows.\n",
        "    Args:\n",
        "        query_str: Query string for similarity search\n",
        "        table_schema_objs: List of TableInfo objects\n",
        "        \n",
        "    Returns:\n",
        "        Combined context string for all tables\n",
        "    \"\"\"\n",
        "    context_strs = []\n",
        "    \n",
        "    for table_info_obj in table_schema_objs:\n",
        "        table_name = table_info_obj.table_name\n",
        "        \n",
        "        try:\n",
        "            logger.info(f\"[01] Getting schema for table: {table_name}\")\n",
        "            table_info = sql_database.get_single_table_info(table_name)\n",
        "            \n",
        "            # Check if we have a vector index for this table\n",
        "            if table_name not in vector_index_dict:\n",
        "                logger.warning(f\"[02] No vector index found for table: {table_name}\")\n",
        "                context_strs.append(table_info)\n",
        "                continue\n",
        "            \n",
        "            logger.info(f\"[02] Retrieving example rows for table: {table_name}\")\n",
        "            vector_retriever = vector_index_dict[table_name].as_retriever(\n",
        "                similarity_top_k=TOP_N\n",
        "            )\n",
        "            \n",
        "            relevant_nodes = vector_retriever.retrieve(query_str)\n",
        "            logger.info(f\"[03] Retrieved {len(relevant_nodes)} relevant nodes for table: {table_name}\")\n",
        "            \n",
        "            if relevant_nodes:\n",
        "                table_row_context = \"\\nHere are some relevant example rows (column=value):\\n\"\n",
        "                for node in relevant_nodes:\n",
        "                    table_row_context += f\"- {node.get_content()}\\n\"\n",
        "                table_info += table_row_context\n",
        "            else:\n",
        "                logger.info(f\"[03.1] No relevant rows found for query in table: {table_name}\")\n",
        "            \n",
        "            context_strs.append(table_info)\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"[ERROR] Failed to get context for table {table_name}: {str(e)}\")\n",
        "            # Still add basic table info even if retrieval fails\n",
        "            try:\n",
        "                table_info = sql_database.get_single_table_info(table_name)\n",
        "                context_strs.append(table_info)\n",
        "            except Exception as schema_error:\n",
        "                logger.error(f\"[ERROR] Failed to get schema for table {table_name}: {str(schema_error)}\")\n",
        "    \n",
        "    return \"\\n\\n\".join(context_strs)\n",
        "\n",
        "table_parser_component = get_table_context_and_rows_str(QUERY_1, table_schema_objs)\n",
        "logger.info(f\"Updated table context with rows:\\n{table_parser_component}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab71cf00",
      "metadata": {},
      "source": [
        "### Define Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "22323164",
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.t2SQL_workflow.custom_events import (\n",
        "    TableRetrievedEvent,\n",
        "    SchemaProcessedEvent,\n",
        "    SQLPromptReadyEvent,\n",
        "    SQLGeneratedEvent,\n",
        "    SQLParsedEvent,\n",
        "    SQLResultsEvent,\n",
        "    ResponsePromptReadyEvent,\n",
        ")\n",
        "from utils.t2SQL_workflow.custom_fallbacks import (\n",
        "    extract_sql_from_response,\n",
        "    analyze_sql_error,\n",
        "    create_t2s_prompt,\n",
        ")\n",
        "\n",
        "\n",
        "class Text2SQLWorkflowRowRetrieval(Workflow):\n",
        "    @step\n",
        "    async def input_step(self, ev: StartEvent) -> TableRetrievedEvent:\n",
        "        logger.info(f\"[Step 01] Process initial query and retrieve relevant tables\")\n",
        "        query = ev.query\n",
        "\n",
        "        logger.info(f\" - Use object retriever built from your table summaries\")\n",
        "        tables = obj_retriever.retrieve(query)  # candidate schemas\n",
        "        logger.info(f\" - Retrieved {len(tables)} candidate tables for query: {query}\")\n",
        "        \n",
        "        return TableRetrievedEvent(\n",
        "            tables=tables, \n",
        "            query_str=query\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def table_output_parser_step(self, ev: TableRetrievedEvent) -> SchemaProcessedEvent:\n",
        "        logger.info(f\"[Step 02] Parsing schemas and retrieving relevant rows for query: {ev.query_str}\")\n",
        "\n",
        "        logger.info(f\" - Enriching context function with vector row retrieval for tables: {ev.tables}\")\n",
        "        schema_str = get_table_context_and_rows_str(ev.query_str, ev.tables)\n",
        "        \n",
        "        return SchemaProcessedEvent(\n",
        "            table_schema=schema_str, \n",
        "            query_str=ev.query_str\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def text2sql_prompt_step(self, ev: SchemaProcessedEvent | SQLResultsEvent) -> SQLPromptReadyEvent:\n",
        "        logger.info(f\"[Step 03] Creating SQL prompt for query: {ev.query_str}\")\n",
        "        if isinstance(ev, SchemaProcessedEvent):\n",
        "            table_schema = ev.table_schema\n",
        "            query_str = ev.query_str\n",
        "            retry_count = 0\n",
        "            error_message = \"\"\n",
        "        else:\n",
        "            table_schema = getattr(ev, 'table_schema', '')\n",
        "            query_str = ev.query_str\n",
        "            retry_count = getattr(ev, 'retry_count', 0) + 1\n",
        "            error_message = getattr(ev, 'error_message', '')\n",
        "\n",
        "        prompt = create_t2s_prompt(table_schema, query_str, retry_count, error_message)\n",
        "        \n",
        "        return SQLPromptReadyEvent(\n",
        "            t2s_prompt=prompt,\n",
        "            query_str=query_str,\n",
        "            table_schema=table_schema,\n",
        "            retry_count=retry_count,\n",
        "            error_message=error_message\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def text2sql_llm_step(self, ev: SQLPromptReadyEvent) -> SQLGeneratedEvent:\n",
        "        logger.info(f\"[Step 04] Running LLM to generate SQL for query: {ev.query_str}\")\n",
        "        sql_response = await Settings.llm.acomplete(ev.t2s_prompt)\n",
        "        \n",
        "        return SQLGeneratedEvent(\n",
        "            sql_query=str(sql_response).strip(),\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=ev.table_schema,\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=ev.error_message\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def sql_output_parser_step(self, ev: SQLGeneratedEvent) -> SQLParsedEvent:\n",
        "        logger.info(f\"[Step 05] Parsing LLM response to extract clean SQL for query: {ev.query_str}\")\n",
        "        try:\n",
        "            clean_sql = parse_response_to_sql(ev.sql_query)  # primary parser\n",
        "        except Exception:\n",
        "            clean_sql = extract_sql_from_response(ev.sql_query, logger)  # fallback\n",
        "        \n",
        "        if not clean_sql:\n",
        "            clean_sql = extract_sql_from_response(ev.sql_query, logger)\n",
        "\n",
        "        logger.info(f\"Attempt #{ev.retry_count + 1}\")\n",
        "        logger.info(f\"LLM Response: {ev.sql_query}\")\n",
        "        logger.info(f\"Cleaned SQL: {clean_sql}\")\n",
        "\n",
        "        return SQLParsedEvent(\n",
        "            sql_query=clean_sql,\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=ev.table_schema,\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=ev.error_message\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def sql_retriever_step(self, ev: SQLParsedEvent) -> SQLResultsEvent:\n",
        "        logger.info(f\"[Step 06] Executing SQL for query: {ev.query_str}\")\n",
        "        try:\n",
        "            results = sql_retriever.retrieve(ev.sql_query)\n",
        "            logger.info(f\"[SUCCESS] Executed on Attempt #{ev.retry_count + 1}\")\n",
        "\n",
        "            return SQLResultsEvent(\n",
        "                context_str=str(results),\n",
        "                sql_query=ev.sql_query,\n",
        "                query_str=ev.query_str,\n",
        "                success=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            error_msg = str(e)\n",
        "            logger.error(f\"Execution failed (Attempt #{ev.retry_count + 1}): {error_msg}\")\n",
        "\n",
        "            if ev.retry_count < MAX_RETRIES:\n",
        "                retry_event = SQLResultsEvent(\n",
        "                    context_str=\"\",\n",
        "                    sql_query=ev.sql_query,\n",
        "                    query_str=ev.query_str,\n",
        "                    success=False,\n",
        "                    retry_count=ev.retry_count + 1,\n",
        "                )\n",
        "                retry_event.retry_count = ev.retry_count + 1\n",
        "                retry_event.error_message = analyze_sql_error(error_msg, ev.sql_query, ev.table_schema, logger)\n",
        "                retry_event.table_schema = ev.table_schema\n",
        "                \n",
        "                return retry_event\n",
        "            else:\n",
        "                return SQLResultsEvent(\n",
        "                    context_str=(f\"Failed after {MAX_RETRIES+1} attempts. Final error: {error_msg}\"),\n",
        "                    sql_query=ev.sql_query,\n",
        "                    query_str=ev.query_str,\n",
        "                    success=False,\n",
        "                    retry_count=ev.retry_count + 1,\n",
        "                )\n",
        "\n",
        "    @step\n",
        "    async def retry_handler_step(self, ev: SQLResultsEvent) -> SQLPromptReadyEvent:\n",
        "        logger.info(f\"[Step 07] Handling retry for query: {ev.query_str}\")\n",
        "        if ev.success:\n",
        "            return None\n",
        "        \n",
        "        return SQLPromptReadyEvent(\n",
        "            t2s_prompt=\"\",  # regenerated later\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=getattr(ev, 'table_schema', ''),\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=getattr(ev, 'error_message', 'Unknown error')\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def response_synthesis_prompt_step(self, ev: SQLResultsEvent) -> ResponsePromptReadyEvent:\n",
        "        logger.info(f\"[Step 08] Preparing synthesis prompt for query: {ev.query_str}\")\n",
        "        if not ev.success:\n",
        "            return None\n",
        "        prompt = response_synthesis_prompt.format(\n",
        "            query_str=ev.query_str,\n",
        "            context_str=ev.context_str,\n",
        "            sql_query=ev.sql_query\n",
        "        )\n",
        "        \n",
        "        return ResponsePromptReadyEvent(\n",
        "            query_str=ev.query_str,\n",
        "            rs_prompt=prompt\n",
        "        )\n",
        "\n",
        "    @step\n",
        "    async def response_synthesis_llm_step(self, ev: ResponsePromptReadyEvent) -> StopEvent:\n",
        "        logger.info(f\"[Step 09] Generating final answer for query: {ev.query_str}\")\n",
        "        answer = await Settings.llm.acomplete(ev.rs_prompt)\n",
        "        \n",
        "        return StopEvent(result=str(answer))\n",
        "\n",
        "\n",
        "# Runner\n",
        "async def run_text2sql_workflow_row(query: str):\n",
        "    workflow = Text2SQLWorkflowRowRetrieval(timeout=480)\n",
        "    result = await workflow.run(query=query)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "702f159a",
      "metadata": {},
      "source": [
        "Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0129d573",
      "metadata": {},
      "outputs": [],
      "source": [
        "async def visualize_text2sql_workflow_row(sample_query: str, execution_name: str, output_dir: str = WORKFLOW_VISUALIZATION_DIR):\n",
        "    \"\"\"\n",
        "    Function to visualize the Text2SQL workflow in your version:\n",
        "    - Draws all possible flows\n",
        "    - Runs your row-retrieval Text2SQL workflow\n",
        "    - Draws execution path of the actual run\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    logger.info(\"[01] Drawing all possible flows...\")\n",
        "    all_flows_path = os.path.join(output_dir, f\"{execution_name}_text2sql_workflow_flow.html\")\n",
        "    draw_all_possible_flows(\n",
        "        Text2SQLWorkflowRowRetrieval,\n",
        "        filename=all_flows_path\n",
        "    )\n",
        "    logger.info(f\"[SUCCESS] All possible flows saved to: {all_flows_path}\")\n",
        "\n",
        "    logger.info(\"[02] Running workflow and drawing execution path...\")\n",
        "    try:\n",
        "        logger.info(\" - wrapper function instead of manual instantiation\")\n",
        "        result = await run_text2sql_workflow_row(sample_query)\n",
        "\n",
        "        logger.info(\" - Recreating workflow object for execution path drawing\")\n",
        "        workflow = Text2SQLWorkflowRowRetrieval(timeout=240)\n",
        "\n",
        "        execution_path = os.path.join(output_dir, f\"{execution_name}_text2sql_workflow_execution.html\")\n",
        "        draw_most_recent_execution(\n",
        "            workflow,\n",
        "            filename=execution_path\n",
        "        )\n",
        "        logger.info(f\"[SUCCESS] Recent execution path saved to: {execution_path}\")\n",
        "        logger.info(f\"Workflow result: {result.result}\")  \n",
        "        logger.debug(\"this `.result` holds final answer\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during workflow execution: {e}\")\n",
        "        logger.info(\"Note: Ensure retrievers + LLM configs are initialized correctly\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb9637d",
      "metadata": {},
      "source": [
        "### Run Some Queries\n",
        "\n",
        "We can now ask about relevant entries even if it doesn't exactly match the entry in the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e3daf393",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-20 20:35:27,282 [INFO] [Step 01] Process initial query and retrieve relevant tables\n",
            "2025-08-20 20:35:27,283 [INFO]  - Use object retriever built from your table summaries\n",
            "2025-08-20 20:35:27,330 [INFO]  - Retrieved 5 candidate tables for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:35:27,338 [INFO] [Step 02] Parsing schemas and retrieving relevant rows for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:35:27,339 [INFO]  - Enriching context function with vector row retrieval for tables: [SQLTableSchema(table_name='Invoice', context_str='Summary of invoice details'), SQLTableSchema(table_name='Customer', context_str='Summary of customer data including ID, name, company, etc.'), SQLTableSchema(table_name='Employee', context_str='Summary of employee data'), SQLTableSchema(table_name='Artist', context_str='Summary of artist data'), SQLTableSchema(table_name='InvoiceLine', context_str='Summary of invoice and track details')]\n",
            "2025-08-20 20:35:27,340 [INFO] [01] Getting schema for table: Invoice\n",
            "2025-08-20 20:35:27,341 [INFO] [02] Retrieving example rows for table: Invoice\n",
            "2025-08-20 20:35:27,383 [INFO] [03] Retrieved 2 relevant nodes for table: Invoice\n",
            "2025-08-20 20:35:27,385 [INFO] [01] Getting schema for table: Customer\n",
            "2025-08-20 20:35:27,386 [INFO] [02] Retrieving example rows for table: Customer\n",
            "2025-08-20 20:35:27,439 [INFO] [03] Retrieved 2 relevant nodes for table: Customer\n",
            "2025-08-20 20:35:27,441 [INFO] [01] Getting schema for table: Employee\n",
            "2025-08-20 20:35:27,442 [INFO] [02] Retrieving example rows for table: Employee\n",
            "2025-08-20 20:35:27,522 [INFO] [03] Retrieved 2 relevant nodes for table: Employee\n",
            "2025-08-20 20:35:27,523 [INFO] [01] Getting schema for table: Artist\n",
            "2025-08-20 20:35:27,524 [INFO] [02] Retrieving example rows for table: Artist\n",
            "2025-08-20 20:35:27,604 [INFO] [03] Retrieved 2 relevant nodes for table: Artist\n",
            "2025-08-20 20:35:27,605 [INFO] [01] Getting schema for table: InvoiceLine\n",
            "2025-08-20 20:35:27,606 [INFO] [02] Retrieving example rows for table: InvoiceLine\n",
            "2025-08-20 20:35:27,673 [INFO] [03] Retrieved 2 relevant nodes for table: InvoiceLine\n",
            "2025-08-20 20:35:27,680 [INFO] [Step 03] Creating SQL prompt for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:35:27,690 [INFO] [Step 04] Running LLM to generate SQL for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:36:34,489 [INFO] [Step 05] Parsing LLM response to extract clean SQL for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:36:34,491 [INFO] Extracting SQL from LLM response that might contain reasoning or formatting.\n",
            "2025-08-20 20:36:34,492 [INFO] Removing <think> blocks from response\n",
            "2025-08-20 20:36:34,494 [INFO] Removing non-SQL content at the beginning of response\n",
            "2025-08-20 20:36:34,495 [INFO]  [Method 1] Looking for SQLQuery: pattern\n",
            "2025-08-20 20:36:34,496 [INFO]  [Method 2] Looking for SQL in code blocks\n",
            "2025-08-20 20:36:34,498 [INFO]  [Method 3] Looking for standalone SQL statements\n",
            "2025-08-20 20:36:34,498 [INFO]  - Split by lines and look for SQL statements\n",
            "2025-08-20 20:36:34,499 [INFO]  - Checking line for SQL keywords: SELECT BillingCity FROM Invoice JOIN Customer ON Invoice.CustomerId = Customer.CustomerId WHERE Customer.FirstName = 'Leonie';\n",
            "2025-08-20 20:36:34,500 [INFO] Attempt #1\n",
            "2025-08-20 20:36:34,501 [INFO] LLM Response: <think>\n",
            "Okay, let's see. The user is asking for the billing city of Leonie Köhler. First, I need to figure out which table to use. The billing city is in the Invoice table, right? Because the Invoice has BillingCity as a column.\n",
            "\n",
            "So, the customer's ID is 42 in the example rows. But how do I get Leonie's billing city from that? Wait, the Invoice table has CustomerId, and the Customer table has CustomerId. So maybe I need to join the Invoice and Customer tables on CustomerId.\n",
            "\n",
            "The user provided an example where InvoiceId=42, CustomerId=42. So if I can find Leonie's InvoiceId, I can get her BillingCity. But how do I get that from the given data?\n",
            "\n",
            "Looking at the example rows, for CustomerId=42, the BillingCity is Bordeaux. So if I can find the InvoiceId where CustomerId is 42, then I can get the BillingCity. But how do I know the InvoiceId? Maybe the example shows that InvoiceId=83, but maybe in the actual data, there's another one. Wait, the user's question is about Leonie, so maybe the example row for CustomerId=42 has that data. But in the example, the first row has InvoiceId=83, so perhaps the correct approach is to select BillingCity from Invoice where CustomerId is 42.\n",
            "\n",
            "So the SQL query would be SELECT BillingCity FROM Invoice WHERE CustomerId = 42; but wait, the example shows that InvoiceId=83, but maybe in the actual data, there's another InvoiceId. But since the question is about Leonie, maybe the correct approach is to use the CustomerId from the example. But how do I know that? The problem says to generate a valid SQL query based on the provided schema and the user's question. Since the example rows have CustomerId=42, maybe the correct query is to select BillingCity from Invoice where CustomerId is 42. But in the example, the BillingCity is Bordeaux. So the SQL would be SELECT BillingCity FROM Invoice WHERE CustomerId = 42; but wait, the example row has InvoiceId=83, but maybe in the actual data, the InvoiceId is different. But since the question is about Leonie, perhaps the correct approach is to use the CustomerId from the example. But how do I know that? Maybe the user expects that the query is to join the Invoice and Customer tables on CustomerId. So the correct SQL would be:\n",
            "\n",
            "SELECT Invoice.BillingCity\n",
            "FROM Invoice\n",
            "JOIN Customer ON Invoice.CustomerId = Customer.CustomerId\n",
            "WHERE Customer.FirstName = 'Leonie';\n",
            "\n",
            "But wait, the example shows that CustomerId=42, so maybe the query is SELECT BillingCity FROM Invoice JOIN Customer ON Invoice.CustomerId = Customer.CustomerId WHERE Customer.FirstName = 'Leonie';\n",
            "\n",
            "Yes, that makes sense. So the SQL query would be that. But I need to make sure that the columns are correctly referenced. The BillingCity is in the Invoice table, and Customer's FirstName is 'Leonie'. So the query is correct.\n",
            "</think>\n",
            "\n",
            "SELECT BillingCity FROM Invoice JOIN Customer ON Invoice.CustomerId = Customer.CustomerId WHERE Customer.FirstName = 'Leonie';\n",
            "2025-08-20 20:36:34,502 [INFO] Cleaned SQL: SELECT BillingCity FROM Invoice JOIN Customer ON Invoice.CustomerId = Customer.CustomerId WHERE Customer.FirstName = 'Leonie'\n",
            "2025-08-20 20:36:34,515 [INFO] [Step 06] Executing SQL for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:36:34,542 [INFO] [SUCCESS] Executed on Attempt #1\n",
            "2025-08-20 20:36:34,558 [INFO] [Step 03] Creating SQL prompt for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:36:34,574 [INFO] [Step 08] Preparing synthesis prompt for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:36:34,590 [INFO] [Step 07] Handling retry for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:36:34,604 [INFO] [Step 04] Running LLM to generate SQL for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:36:34,621 [INFO] [Step 09] Generating final answer for query: What is the billing city of Leonie Köhler?\n",
            "<think>\n",
            "Okay, let's see. The user is asking for the billing city of Leonie Köhler. They provided a SQL query that joins the Invoice table with the Customer table and filters by Leonie's first name. The SQL response shows that the BillingCity column has values like 'Stuttgart' repeated multiple times.\n",
            "\n",
            "First, I need to parse the SQL query. The query selects BillingCity from Invoice joined with Customer where Customer.FirstName is 'Leonie'. The result has multiple entries of Stuttgart. So, the answer should be that Leonie's billing city is Stuttgart. But wait, the user might expect a single answer. Since there are multiple entries, maybe the system is returning all occurrences, but the question is about the billing city, which is a single value. However, the SQL response lists all the cities, so perhaps the correct answer is that all entries point to Stuttgart, hence the billing city is Stuttgart.\n",
            "\n",
            "I should check if there's any other information in the SQL response. The metadata says the result has [('Stuttgart',), ...], so the billing city is consistently Stuttgart. Therefore, the answer is Stuttgart.\n",
            "</think>\n",
            "\n",
            "The billing city of Leonie Köhler is **Stuttgart**. All entries in the result list point to this city.\n"
          ]
        }
      ],
      "source": [
        "result = await run_text2sql_workflow_row(QUERY_1)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "963acccf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-20 20:53:36,284 [INFO] [01] Drawing all possible flows...\n",
            "outputs\\Chinook\\workflow_visualization\\LK_text2sql_workflow_flow.html\n",
            "2025-08-20 20:53:36,656 [INFO] [SUCCESS] All possible flows saved to: outputs\\Chinook\\workflow_visualization\\LK_text2sql_workflow_flow.html\n",
            "2025-08-20 20:53:36,660 [INFO] [02] Running workflow and drawing execution path...\n",
            "2025-08-20 20:53:36,662 [INFO]  - wrapper function instead of manual instantiation\n",
            "2025-08-20 20:53:36,677 [INFO] [Step 01] Process initial query and retrieve relevant tables\n",
            "2025-08-20 20:53:36,680 [INFO]  - Use object retriever built from your table summaries\n",
            "2025-08-20 20:53:37,504 [INFO]  - Retrieved 5 candidate tables for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:53:37,523 [INFO] [Step 02] Parsing schemas and retrieving relevant rows for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:53:37,526 [INFO]  - Enriching context function with vector row retrieval for tables: [SQLTableSchema(table_name='Invoice', context_str='Summary of invoice details'), SQLTableSchema(table_name='Customer', context_str='Summary of customer data including ID, name, company, etc.'), SQLTableSchema(table_name='Employee', context_str='Summary of employee data'), SQLTableSchema(table_name='Artist', context_str='Summary of artist data'), SQLTableSchema(table_name='InvoiceLine', context_str='Summary of invoice and track details')]\n",
            "2025-08-20 20:53:37,528 [INFO] [01] Getting schema for table: Invoice\n",
            "2025-08-20 20:53:37,531 [INFO] [02] Retrieving example rows for table: Invoice\n",
            "2025-08-20 20:53:37,661 [INFO] [03] Retrieved 2 relevant nodes for table: Invoice\n",
            "2025-08-20 20:53:37,664 [INFO] [01] Getting schema for table: Customer\n",
            "2025-08-20 20:53:37,667 [INFO] [02] Retrieving example rows for table: Customer\n",
            "2025-08-20 20:53:37,773 [INFO] [03] Retrieved 2 relevant nodes for table: Customer\n",
            "2025-08-20 20:53:37,776 [INFO] [01] Getting schema for table: Employee\n",
            "2025-08-20 20:53:37,778 [INFO] [02] Retrieving example rows for table: Employee\n",
            "2025-08-20 20:53:37,956 [INFO] [03] Retrieved 2 relevant nodes for table: Employee\n",
            "2025-08-20 20:53:37,958 [INFO] [01] Getting schema for table: Artist\n",
            "2025-08-20 20:53:37,965 [INFO] [02] Retrieving example rows for table: Artist\n",
            "2025-08-20 20:53:38,705 [INFO] [03] Retrieved 2 relevant nodes for table: Artist\n",
            "2025-08-20 20:53:38,709 [INFO] [01] Getting schema for table: InvoiceLine\n",
            "2025-08-20 20:53:38,712 [INFO] [02] Retrieving example rows for table: InvoiceLine\n",
            "2025-08-20 20:53:38,853 [INFO] [03] Retrieved 2 relevant nodes for table: InvoiceLine\n",
            "2025-08-20 20:53:38,876 [INFO] [Step 03] Creating SQL prompt for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:53:38,892 [INFO] [Step 04] Running LLM to generate SQL for query: What is the billing city of Leonie Köhler?\n"
          ]
        },
        {
          "ename": "CancelledError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m visualize_text2sql_workflow_row(QUERY_1, QUERY_1_INITIAL)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mvisualize_text2sql_workflow_row\u001b[39m\u001b[34m(sample_query, execution_name, output_dir)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     20\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33m - wrapper function instead of manual instantiation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m run_text2sql_workflow_row(sample_query)\n\u001b[32m     23\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33m - Recreating workflow object for execution path drawing\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m     workflow = Text2SQLWorkflowRowRetrieval(timeout=\u001b[32m240\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 184\u001b[39m, in \u001b[36mrun_text2sql_workflow_row\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_text2sql_workflow_row\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    183\u001b[39m     workflow = Text2SQLWorkflowRowRetrieval(timeout=\u001b[32m480\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m workflow.run(query=query)\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[31mCancelledError\u001b[39m: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-20 20:56:14,573 [INFO] [Step 05] Parsing LLM response to extract clean SQL for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:56:14,578 [INFO] Extracting SQL from LLM response that might contain reasoning or formatting.\n",
            "2025-08-20 20:56:14,579 [INFO] Removing <think> blocks from response\n",
            "2025-08-20 20:56:14,580 [INFO] Removing non-SQL content at the beginning of response\n",
            "2025-08-20 20:56:14,582 [INFO]  [Method 1] Looking for SQLQuery: pattern\n",
            "2025-08-20 20:56:14,586 [INFO]  [Method 2] Looking for SQL in code blocks\n",
            "2025-08-20 20:56:14,587 [INFO]  [Method 3] Looking for standalone SQL statements\n",
            "2025-08-20 20:56:14,589 [INFO]  - Split by lines and look for SQL statements\n",
            "2025-08-20 20:56:14,593 [INFO]  - Checking line for SQL keywords: SELECT BillingCity FROM Invoice WHERE CustomerId = 2;\n",
            "2025-08-20 20:56:14,597 [INFO] Attempt #1\n",
            "2025-08-20 20:56:14,599 [INFO] LLM Response: <think>\n",
            "Okay, let's see. The user is asking for the billing city of Leonie Köhler. First, I need to figure out which table to use. The billing city is in the Invoice table, right? Because the Invoice has BillingCity as a column. So the main table here is Invoice.\n",
            "\n",
            "Now, Leonie's CustomerId is 2 from the example rows. Wait, in the example rows, CustomerId 2 has FirstName Leonie. So I need to find the Invoice where CustomerId is 2. Then, from that Invoice, select the BillingCity.\n",
            "\n",
            "So the steps are: join the Invoice and Customer tables on CustomerId, then get the BillingCity. But wait, the Invoice table has CustomerId as a foreign key. So maybe I can use a JOIN between Invoice and Customer. But the question is about the billing city, so maybe just get the BillingCity from the Invoice where CustomerId is 2.\n",
            "\n",
            "Wait, but how to get that from the Invoice table. Since the Invoice has CustomerId, I can select BillingCity from Invoice where CustomerId = 2. That would directly answer the question. So the SQL query would be SELECT BillingCity FROM Invoice WHERE CustomerId = 2; but wait, the example shows that InvoiceId=83 has CustomerId=42. So in the example, the BillingCity is Bordeaux. So for CustomerId 2, the BillingCity is Stuttgart. So the query would be correct.\n",
            "\n",
            "But the user's question is about the billing city, so the answer is Stuttgart. But the question is to generate the SQL query. So the answer is to select BillingCity from Invoice where CustomerId is 2. But how to write that in SQL without any explanation.\n",
            "\n",
            "So the SQL query would be SELECT BillingCity FROM Invoice WHERE CustomerId = 2; but wait, the example shows that InvoiceId=83 has CustomerId=42. So the query would be SELECT BillingCity FROM Invoice WHERE CustomerId = 2. But the example rows have CustomerId 2, so that's correct.\n",
            "\n",
            "Therefore, the correct SQL query is as above.\n",
            "</think>\n",
            "\n",
            "SELECT BillingCity FROM Invoice WHERE CustomerId = 2;\n",
            "2025-08-20 20:56:14,606 [INFO] Cleaned SQL: SELECT BillingCity FROM Invoice WHERE CustomerId = 2\n",
            "2025-08-20 20:56:14,627 [INFO] [Step 06] Executing SQL for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:56:14,683 [INFO] [SUCCESS] Executed on Attempt #1\n",
            "2025-08-20 20:56:14,702 [INFO] [Step 03] Creating SQL prompt for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:56:14,715 [INFO] [Step 08] Preparing synthesis prompt for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:56:14,728 [INFO] [Step 07] Handling retry for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:56:14,760 [INFO] [Step 04] Running LLM to generate SQL for query: What is the billing city of Leonie Köhler?\n",
            "2025-08-20 20:56:14,769 [INFO] [Step 09] Generating final answer for query: What is the billing city of Leonie Köhler?\n"
          ]
        }
      ],
      "source": [
        "await visualize_text2sql_workflow_row(QUERY_1, QUERY_1_INITIAL)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rag-text-2-sql",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
