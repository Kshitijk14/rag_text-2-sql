{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "855f9f50-ef38-4069-932a-fb49af02d28e",
      "metadata": {
        "id": "855f9f50-ef38-4069-932a-fb49af02d28e"
      },
      "source": [
        "# Query Pipeline for Advanced Text-to-SQL\n",
        "\n",
        "In this guide we show you how to setup a text-to-SQL pipeline over your data with our [query pipeline](https://docs.llamaindex.ai/en/stable/module_guides/querying/pipeline/root.html) syntax.\n",
        "\n",
        "This gives you flexibility to enhance text-to-SQL with additional techniques. We show these in the below sections:\n",
        "1. **Query-Time Table Retrieval**: Dynamically retrieve relevant tables in the text-to-SQL prompt.\n",
        "2. **Query-Time Sample Row retrieval**: Embed/Index each row, and dynamically retrieve example rows for each table in the text-to-SQL prompt.\n",
        "\n",
        "Our out-of-the box pipelines include our `NLSQLTableQueryEngine` and `SQLTableRetrieverQueryEngine`. (if you want to check out our text-to-SQL guide using these modules, take a look [here](https://docs.llamaindex.ai/en/stable/examples/index_structs/struct_indices/SQLIndexDemo.html)). This guide implements an advanced version of those modules, giving you the utmost flexibility to apply this to your own setting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e39cc96c-9fbc-44c3-b57f-017a9aa75473",
      "metadata": {
        "id": "e39cc96c-9fbc-44c3-b57f-017a9aa75473"
      },
      "source": [
        "## Load and Ingest Data\n",
        "\n",
        "\n",
        "### Load Data\n",
        "We use the [WikiTableQuestions dataset](https://ppasupat.github.io/WikiTableQuestions/) (Pasupat and Liang 2015) as our test dataset.\n",
        "\n",
        "We go through all the csv's in one folder, store each in a sqlite database (we will then build an object index over each table schema)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "6bc8cd21",
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "import zipfile\n",
        "import json\n",
        "import json as pyjson\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "# put data into sqlite db\n",
        "from sqlalchemy import (\n",
        "    create_engine,\n",
        "    MetaData,\n",
        "    Table,\n",
        "    Column,\n",
        "    String,\n",
        "    Integer,\n",
        ")\n",
        "\n",
        "# setup Arize Phoenix for logging/observability\n",
        "import phoenix as px\n",
        "from llama_index.core import set_global_handler\n",
        "\n",
        "from llama_index.core.objects import (\n",
        "    SQLTableNodeMapping,\n",
        "    ObjectIndex,\n",
        "    SQLTableSchema,\n",
        ")\n",
        "from llama_index.core import SQLDatabase, VectorStoreIndex\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "from llama_index.core.retrievers import SQLRetriever\n",
        "\n",
        "from llama_index.core.prompts.default_prompts import DEFAULT_TEXT_TO_SQL_PROMPT\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.llms import ChatResponse\n",
        "\n",
        "from llama_index.core.workflow import Workflow, step, StartEvent, StopEvent\n",
        "from llama_index.core.workflow.events import Event\n",
        "\n",
        "# import networkx as nx\n",
        "# from pyvis.network import Network\n",
        "\n",
        "from llama_index.utils.workflow import (\n",
        "    draw_all_possible_flows,\n",
        "    draw_most_recent_execution,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cadfb28c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "Extracting...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "URL = \"https://github.com/ppasupat/WikiTableQuestions/releases/download/v1.0.2/WikiTableQuestions-1.0.2-compact.zip\"\n",
        "\n",
        "OUTPUT_DIR = \"../data\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Downloading...\")\n",
        "response = requests.get(URL)\n",
        "response.raise_for_status()\n",
        "\n",
        "print(\"Extracting...\")\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "    z.extractall(OUTPUT_DIR)\n",
        "\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5a710f7a-74b4-48c3-98d1-a6d409a7af1a",
      "metadata": {
        "id": "5a710f7a-74b4-48c3-98d1-a6d409a7af1a",
        "outputId": "fb840754-8360-459d-fe4b-bbe92b24475e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\0.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\1.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\10.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\11.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\12.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\14.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\15.csv\n",
            "Error parsing ..\\data\\WikiTableQuestions\\csv\\200-csv\\15.csv: Error tokenizing data. C error: Expected 4 fields in line 16, saw 5\n",
            "\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\17.csv\n",
            "Error parsing ..\\data\\WikiTableQuestions\\csv\\200-csv\\17.csv: Error tokenizing data. C error: Expected 6 fields in line 5, saw 7\n",
            "\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\18.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\20.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\22.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\24.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\25.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\26.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\28.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\29.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\3.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\30.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\31.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\32.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\33.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\34.csv\n",
            "Error parsing ..\\data\\WikiTableQuestions\\csv\\200-csv\\34.csv: Error tokenizing data. C error: Expected 4 fields in line 6, saw 13\n",
            "\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\35.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\36.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\37.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\38.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\4.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\41.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\42.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\44.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\45.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\46.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\47.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\48.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\7.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\8.csv\n",
            "processing file: ..\\data\\WikiTableQuestions\\csv\\200-csv\\9.csv\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = Path(\"../data/WikiTableQuestions/csv/200-csv\")\n",
        "CSV_FILES = sorted([f for f in DATA_DIR.glob(\"*.csv\")])\n",
        "dfs = []\n",
        "\n",
        "for csv_file in CSV_FILES:\n",
        "    print(f\"processing file: {csv_file}\")\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        dfs.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {csv_file}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c271b986-9ed6-4a8a-a7c2-1dad7a642c06",
      "metadata": {
        "id": "c271b986-9ed6-4a8a-a7c2-1dad7a642c06"
      },
      "source": [
        "### Extract Table Name and Summary from each Table\n",
        "\n",
        "Here we use gpt-3.5 to extract a table name (with underscores) and summary from each table with our Pydantic program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4cef9585-87f8-4427-aaca-c0038c289e00",
      "metadata": {
        "id": "4cef9585-87f8-4427-aaca-c0038c289e00",
        "outputId": "03b3f4e4-93cf-4125-b745-a5f190208bbf"
      },
      "outputs": [],
      "source": [
        "TABLEINFO_DIR = \"../data/WikiTableQuestions_TableInfo\"\n",
        "os.makedirs(TABLEINFO_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a81afbf-0870-41b1-baea-017026a1b7d6",
      "metadata": {
        "id": "9a81afbf-0870-41b1-baea-017026a1b7d6"
      },
      "outputs": [],
      "source": [
        "class TableInfo(BaseModel):\n",
        "    \"\"\"Information regarding a structured table.\"\"\"\n",
        "\n",
        "    table_name: str = Field(\n",
        "        ..., description=\"table name (must be underscores and NO spaces)\"\n",
        "    )\n",
        "    table_summary: str = Field(\n",
        "        ..., description=\"short, concise summary/caption of the table\"\n",
        "    )\n",
        "\n",
        "PROMPT_STR = \"\"\"\\\n",
        "    Return only a JSON object, with no explanation, no prose, no markdown, and no trailing text.\n",
        "    You are to produce **only** a JSON object matching the following exact schema:\n",
        "\n",
        "    {\n",
        "        \"table_name\": \"<short_name_in_snake_case_without_spaces>\",\n",
        "        \"table_summary\": \"<short concise caption of the table>\"\n",
        "    }\n",
        "\n",
        "    Example:\n",
        "    {\"table_name\": \"movie_info\", \"table_summary\": \"Summary of movie data\"}\n",
        "\n",
        "    Rules:\n",
        "    - The table_name must be unique to the table, describe it clearly, and be in snake_case.\n",
        "    - Do NOT output a generic table name (e.g., \"table\", \"my_table\").\n",
        "    - Do NOT make the table name one of the following: {exclude_table_name_list}.\n",
        "    - Do NOT include any keys other than \"table_name\" and \"table_summary\".\n",
        "    - Do NOT include extra text before/after the JSON.\n",
        "    - Do NOT include any other keys or text before/after the JSON.\n",
        "    - Do NOT wrap in ```json.\n",
        "\n",
        "    Table:\n",
        "    {table_str}\n",
        "\"\"\"\n",
        "\n",
        "Settings.llm = Ollama(\n",
        "    model=\"qwen3:0.6b\", \n",
        "    request_timeout=240,\n",
        "    format=\"json\",\n",
        "    # context_window=1000\n",
        ")\n",
        "\n",
        "program = LLMTextCompletionProgram.from_defaults(\n",
        "    output_cls=TableInfo,\n",
        "    prompt_template_str=PROMPT_STR,\n",
        "    llm=Settings.llm,\n",
        "    # verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "db30f75b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_first_json_block(text: str):\n",
        "    match = re.search(r\"\\{.*\\}\", text, re.S)  # grab first {...} block\n",
        "    if not match:\n",
        "        raise ValueError(\"No JSON object found in output\")\n",
        "    return pyjson.loads(match.group())\n",
        "\n",
        "\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "\n",
        "def _get_tableinfo_with_index(idx: int) -> str:\n",
        "    results_gen = Path(TABLEINFO_DIR).glob(f\"{idx}_*\")\n",
        "    results_list = list(results_gen)\n",
        "    \n",
        "    if len(results_list) == 0:\n",
        "        return None\n",
        "    elif len(results_list) == 1:\n",
        "        path = results_list[0]\n",
        "        json_str = path.read_text(encoding=\"utf-8\")\n",
        "        return TableInfo.model_validate_json(json_str)\n",
        "    else:\n",
        "        raise ValueError(f\"More than one file matching index: {list(results_gen)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f50a3c04-d1fb-4964-8f37-741fb98a5249",
      "metadata": {
        "id": "f50a3c04-d1fb-4964-8f37-741fb98a5249"
      },
      "outputs": [],
      "source": [
        "table_names = set()\n",
        "table_infos = []\n",
        "\n",
        "for idx, df in enumerate(dfs):\n",
        "    table_info = _get_tableinfo_with_index(idx)\n",
        "    if table_info:\n",
        "        table_infos.append(table_info)\n",
        "        continue\n",
        "\n",
        "    df_str = df.head(10).to_csv()\n",
        "\n",
        "    for attempt in range(MAX_RETRIES):\n",
        "        try:\n",
        "            raw_output = program(\n",
        "                table_str=df_str,\n",
        "                exclude_table_name_list=str(list(table_names)),\n",
        "            )\n",
        "\n",
        "            if isinstance(raw_output, TableInfo):\n",
        "                table_info = raw_output\n",
        "            elif isinstance(raw_output, dict):\n",
        "                table_info = TableInfo(**raw_output)\n",
        "            elif isinstance(raw_output, str):\n",
        "                parsed_dict = extract_first_json_block(raw_output)\n",
        "                table_info = TableInfo(**parsed_dict)\n",
        "            else:\n",
        "                raise TypeError(f\"Unexpected return type from program(): {type(raw_output)}\")\n",
        "\n",
        "            table_name = table_info.table_name\n",
        "            print(f\"Processed table: {table_name}\")\n",
        "\n",
        "            if table_name in table_names:\n",
        "                print(f\"Table name '{table_name}' already exists, skipping this table.\")\n",
        "                table_info = None  # don’t append duplicate\n",
        "                break  # skip\n",
        "\n",
        "            # save table info\n",
        "            table_names.add(table_name)\n",
        "            out_file = f\"{TABLEINFO_DIR}/{idx}_{table_name}.json\"\n",
        "            json.dump(table_info.model_dump(), open(out_file, \"w\"))\n",
        "            break  # move to next table\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with attempt {attempt+1}: {e}\")\n",
        "            time.sleep(2)\n",
        "\n",
        "    if table_info:\n",
        "        table_infos.append(table_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e667fde",
      "metadata": {},
      "source": [
        "To retry for a single index (in needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8dd7ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error with attempt 1: 1 validation error for TableInfo\n",
            "  Invalid JSON: trailing characters at line 1 column 97 [type=json_invalid, input_value='{\"table_name\": \"award_in...n the specified table\"}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n",
            "Processed table: award_nominations\n"
          ]
        }
      ],
      "source": [
        "# idx = 20\n",
        "# df = dfs[idx]\n",
        "\n",
        "# table_info = _get_tableinfo_with_index(idx)\n",
        "# if table_info:\n",
        "#     table_infos.append(table_info)\n",
        "# else:\n",
        "#     df_str = df.head(20).to_csv()\n",
        "\n",
        "#     for attempt in range(MAX_RETRIES):\n",
        "#         try:\n",
        "#             raw_output = program(\n",
        "#                 table_str=df_str,\n",
        "#                 exclude_table_name_list=str(list(table_names)),\n",
        "#             )\n",
        "\n",
        "#             if isinstance(raw_output, TableInfo):\n",
        "#                 table_info = raw_output\n",
        "#             elif isinstance(raw_output, dict):\n",
        "#                 table_info = TableInfo(**raw_output)\n",
        "#             elif isinstance(raw_output, str):\n",
        "#                 parsed_dict = extract_first_json_block(raw_output)\n",
        "#                 table_info = TableInfo(**parsed_dict)\n",
        "#             else:\n",
        "#                 raise TypeError(f\"Unexpected return type from program(): {type(raw_output)}\")\n",
        "\n",
        "#             table_name = table_info.table_name\n",
        "#             print(f\"Processed table: {table_name}\")\n",
        "\n",
        "#             if table_name in table_names:\n",
        "#                 print(f\"Table name '{table_name}' already exists, skipping this table.\")\n",
        "#                 table_info = None\n",
        "#                 break\n",
        "\n",
        "#             table_names.add(table_name)\n",
        "#             out_file = f\"{TABLEINFO_DIR}/{idx}_{table_name}.json\"\n",
        "#             json.dump(table_info.model_dump(), open(out_file, \"w\"))\n",
        "#             break\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error with attempt {attempt+1}: {e}\")\n",
        "#             time.sleep(2)\n",
        "\n",
        "#     if table_info:\n",
        "#         table_infos.append(table_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1cc3230-d14c-4491-b79f-45159708badb",
      "metadata": {
        "id": "a1cc3230-d14c-4491-b79f-45159708badb"
      },
      "source": [
        "### Put Data in SQL Database\n",
        "\n",
        "We use `sqlalchemy`, a popular SQL database toolkit, to load all the tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "53544059-de7d-48dd-8e00-89517964852b",
      "metadata": {
        "id": "53544059-de7d-48dd-8e00-89517964852b",
        "outputId": "df224651-1765-4aa7-e841-d58546c20e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating table: movie_chart_positions\n",
            "Creating table: movie_data\n",
            "Creating table: death_accident_statistics\n",
            "Creating table: award_data_1972\n",
            "Creating table: award_data\n",
            "Creating table: people_info\n",
            "Creating table: broadcasting_info\n",
            "Creating table: person_info\n",
            "Creating table: chart_positions\n",
            "Creating table: kodachrome_film_info\n",
            "Creating table: bbc_radio_costs\n",
            "Creating table: airport_locations\n",
            "Creating table: party_voters\n",
            "Creating table: club_performance\n",
            "Creating table: horse_race_data\n",
            "Creating table: grammy_awards\n",
            "Creating table: boxing_matches\n",
            "Creating table: sports_performance_data\n",
            "Creating table: district_info\n",
            "Creating table: party_data\n",
            "Creating table: award_nominations\n",
            "Creating table: government_ministers\n",
            "Creating table: new_municipality_old_municipality_seat\n",
            "Creating table: team_performance\n",
            "Creating table: encoding_info\n",
            "Creating table: temperature_data\n",
            "Creating table: people_terms\n",
            "Creating table: new_mexico_governorships\n",
            "Creating table: weather_statistics\n",
            "Creating table: drop_event_data\n",
            "Creating table: precipitation_data\n",
            "Creating table: afrikaans_language_usage\n",
            "Creating table:  ohio_districts\n",
            "Creating table: gene_functions\n"
          ]
        }
      ],
      "source": [
        "# Function to create a sanitized column name\n",
        "def sanitize_column_name(col_name):\n",
        "    # Remove special characters and replace spaces with underscores\n",
        "    return re.sub(r\"\\W+\", \"_\", col_name)\n",
        "\n",
        "\n",
        "# Function to create a table from a DataFrame using SQLAlchemy\n",
        "def create_table_from_dataframe(\n",
        "    df: pd.DataFrame, table_name: str, engine, metadata_obj\n",
        "):\n",
        "    # Sanitize column names\n",
        "    sanitized_columns = {col: sanitize_column_name(col) for col in df.columns}\n",
        "    df = df.rename(columns=sanitized_columns)\n",
        "\n",
        "    # Dynamically create columns based on DataFrame columns and data types\n",
        "    columns = [\n",
        "        Column(col, String if dtype == \"object\" else Integer)\n",
        "        for col, dtype in zip(df.columns, df.dtypes)\n",
        "    ]\n",
        "\n",
        "    # Create a table with the defined columns\n",
        "    table = Table(table_name, metadata_obj, *columns)\n",
        "\n",
        "    # Create the table in the database\n",
        "    metadata_obj.create_all(engine)\n",
        "\n",
        "    # Insert data from DataFrame into the table\n",
        "    with engine.connect() as conn:\n",
        "        for _, row in df.iterrows():\n",
        "            insert_stmt = table.insert().values(**row.to_dict())\n",
        "            conn.execute(insert_stmt)\n",
        "        conn.commit()\n",
        "\n",
        "\n",
        "engine = create_engine(\"sqlite:///:memory:\")\n",
        "metadata_obj = MetaData()\n",
        "for idx, df in enumerate(dfs):\n",
        "    tableinfo = _get_tableinfo_with_index(idx)\n",
        "    if tableinfo is None:\n",
        "        print(f\"[ERROR] No TableInfo for index {idx}\")\n",
        "        continue  # skip this one or handle it differently\n",
        "    print(f\"Creating table: {tableinfo.table_name}\")\n",
        "    create_table_from_dataframe(df, tableinfo.table_name, engine, metadata_obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f12a34b5-1d91-4e85-a6ce-97adb5ddfa06",
      "metadata": {
        "id": "f12a34b5-1d91-4e85-a6ce-97adb5ddfa06",
        "outputId": "4527a7d1-6b5f-4f89-9a63-e5263f4e4441"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
            "  next(self.gen)\n",
            "C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:144: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
            "  next(self.gen)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
            "📖 For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n"
          ]
        }
      ],
      "source": [
        "px.launch_app()\n",
        "set_global_handler(\"arize_phoenix\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5906e7-4e20-4b0a-bc42-615f6b86beb7",
      "metadata": {
        "id": "1b5906e7-4e20-4b0a-bc42-615f6b86beb7"
      },
      "source": [
        "## Advanced Capability 1: Text-to-SQL with Query-Time Table Retrieval.\n",
        "\n",
        "We now show you how to setup an e2e text-to-SQL with table retrieval.\n",
        "\n",
        "### Define Modules\n",
        "\n",
        "Here we define the core modules.\n",
        "1. Object index + retriever to store table schemas\n",
        "2. SQLDatabase object to connect to the above tables + SQLRetriever.\n",
        "3. Text-to-SQL Prompt\n",
        "4. Response synthesis Prompt\n",
        "5. LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0830ecca-9688-45b7-b011-d6d44d6fc551",
      "metadata": {
        "id": "0830ecca-9688-45b7-b011-d6d44d6fc551"
      },
      "source": [
        "Object index, retriever, SQLDatabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8a89bc36-a5ac-46bf-b9ae-801f34992019",
      "metadata": {
        "id": "8a89bc36-a5ac-46bf-b9ae-801f34992019"
      },
      "outputs": [],
      "source": [
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "sql_database = SQLDatabase(engine)\n",
        "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
        "\n",
        "table_schema_objs = [\n",
        "    SQLTableSchema(table_name=t.table_name, context_str=t.table_summary)\n",
        "    for t in table_infos\n",
        "]  # add a SQLTableSchema for each table\n",
        "\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    table_schema_objs,\n",
        "    table_node_mapping,\n",
        "    VectorStoreIndex,\n",
        "    embed_model=embed_model,\n",
        ")\n",
        "obj_retriever = obj_index.as_retriever(similarity_top_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4620fbe4-eac6-4476-b373-0e48dfbd81e0",
      "metadata": {
        "id": "4620fbe4-eac6-4476-b373-0e48dfbd81e0"
      },
      "source": [
        "SQLRetriever + Table Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3e9d68bb-16a5-409c-a406-1432565dde99",
      "metadata": {
        "id": "3e9d68bb-16a5-409c-a406-1432565dde99"
      },
      "outputs": [],
      "source": [
        "sql_retriever = SQLRetriever(sql_database)\n",
        "\n",
        "\n",
        "def get_table_context_str(table_schema_objs: List[SQLTableSchema]):\n",
        "    \"\"\"Get table context string.\"\"\"\n",
        "    context_strs = []\n",
        "    for table_schema_obj in table_schema_objs:\n",
        "        table_info = sql_database.get_single_table_info(\n",
        "            table_schema_obj.table_name\n",
        "        )\n",
        "        if table_schema_obj.context_str:\n",
        "            table_opt_context = \" The table description is: \"\n",
        "            table_opt_context += table_schema_obj.context_str\n",
        "            table_info += table_opt_context\n",
        "\n",
        "        context_strs.append(table_info)\n",
        "    return \"\\n\\n\".join(context_strs)\n",
        "\n",
        "\n",
        "table_parser_component = get_table_context_str(table_schema_objs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830ff35b-72ba-42bc-ab49-14b2efc93d17",
      "metadata": {
        "id": "830ff35b-72ba-42bc-ab49-14b2efc93d17"
      },
      "source": [
        "Text-to-SQL Prompt + Output Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "246b8a28-a5b8-4103-b731-a6c09f8694ed",
      "metadata": {
        "id": "246b8a28-a5b8-4103-b731-a6c09f8694ed",
        "outputId": "479f47f2-f530-4984-d0fe-ded7a02a306e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return the most interesting examples in the database.\n",
            "\n",
            "Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
            "\n",
            "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Pay attention to which column is in which table. Also, qualify column names with the table name when needed. You are required to use the following format, each taking one line:\n",
            "\n",
            "Question: Question here\n",
            "SQLQuery: SQL Query to run\n",
            "SQLResult: Result of the SQLQuery\n",
            "Answer: Final answer here\n",
            "\n",
            "Only use tables listed below.\n",
            "{schema}\n",
            "\n",
            "Question: {query_str}\n",
            "SQLQuery: \n"
          ]
        }
      ],
      "source": [
        "def parse_response_to_sql(response: ChatResponse) -> str:\n",
        "    \"\"\"Parse response to SQL.\"\"\"\n",
        "    response = response.message.content\n",
        "    sql_query_start = response.find(\"SQLQuery:\")\n",
        "    if sql_query_start != -1:\n",
        "        response = response[sql_query_start:]\n",
        "        \n",
        "        if response.startswith(\"SQLQuery:\"):\n",
        "            response = response[len(\"SQLQuery:\") :]\n",
        "    sql_result_start = response.find(\"SQLResult:\")\n",
        "    if sql_result_start != -1:\n",
        "        response = response[:sql_result_start]\n",
        "    return response.strip().strip(\"```\").strip()\n",
        "\n",
        "\n",
        "sql_parser_tool = FunctionTool.from_defaults(fn=parse_response_to_sql)\n",
        "\n",
        "text2sql_prompt = DEFAULT_TEXT_TO_SQL_PROMPT.partial_format(\n",
        "    dialect=engine.dialect.name\n",
        ")\n",
        "print(text2sql_prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cf6a211-dd6b-4ffc-b781-0b0c38896e25",
      "metadata": {
        "id": "0cf6a211-dd6b-4ffc-b781-0b0c38896e25"
      },
      "source": [
        "Response Synthesis Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a2fe48e8-ffdd-48f8-b59a-d13d973e8a19",
      "metadata": {
        "id": "a2fe48e8-ffdd-48f8-b59a-d13d973e8a19"
      },
      "outputs": [],
      "source": [
        "response_synthesis_prompt_str = (\n",
        "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
        "    \"Query: {query_str}\\n\"\n",
        "    \"SQL: {sql_query}\\n\"\n",
        "    \"SQL Response: {context_str}\\n\"\n",
        "    \"Response: \"\n",
        ")\n",
        "response_synthesis_prompt = PromptTemplate(\n",
        "    response_synthesis_prompt_str,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ad7cc4-763b-4060-8cc3-ac198c6b956c",
      "metadata": {
        "id": "d4ad7cc4-763b-4060-8cc3-ac198c6b956c"
      },
      "source": [
        "### Define Workflow\n",
        "\n",
        "Now that the components are in place, let's define the query pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe05227",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # custom events\n",
        "# class TableRetrievedEvent(Event):\n",
        "#     tables: list\n",
        "#     query_str: str\n",
        "\n",
        "# class SchemaProcessedEvent(Event):\n",
        "#     table_schema: str\n",
        "#     query_str: str\n",
        "\n",
        "# class SQLPromptReadyEvent(Event):\n",
        "#     t2s_prompt: str\n",
        "#     query_str: str\n",
        "#     table_schema: str\n",
        "\n",
        "# class SQLGeneratedEvent(Event):\n",
        "#     sql_query: str\n",
        "#     query_str: str\n",
        "#     table_schema: str\n",
        "\n",
        "# class SQLParsedEvent(Event):\n",
        "#     sql_query: str\n",
        "#     query_str: str\n",
        "#     table_schema: str\n",
        "\n",
        "# class SQLResultsEvent(Event):\n",
        "#     context_str: str\n",
        "#     sql_query: str\n",
        "#     query_str: str\n",
        "\n",
        "# class ResponsePromptReadyEvent(Event):\n",
        "#     rs_prompt: str\n",
        "\n",
        "\n",
        "# def extract_sql_from_response(llm_response: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Extract SQL query from LLM response that might contain reasoning or formatting.\n",
        "#     \"\"\"\n",
        "#     response = llm_response.strip()\n",
        "    \n",
        "#     # First, remove <think> blocks entirely\n",
        "#     response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()\n",
        "    \n",
        "#     # Method 1: Look for SQLQuery: pattern\n",
        "#     sql_query_match = re.search(r'SQLQuery:\\s*([^;]+;?)', response, re.IGNORECASE | re.DOTALL)\n",
        "#     if sql_query_match:\n",
        "#         sql = sql_query_match.group(1).strip()\n",
        "#         return clean_sql_query(sql)\n",
        "    \n",
        "#     # Method 2: Look for SQL in code blocks\n",
        "#     code_block_match = re.search(r'```sql\\s*\\n(.*?)\\n```', response, re.IGNORECASE | re.DOTALL)\n",
        "#     if code_block_match:\n",
        "#         sql = code_block_match.group(1).strip()\n",
        "#         return clean_sql_query(sql)\n",
        "    \n",
        "#     # Method 3: Look for standalone SQL statements (most common case)\n",
        "#     sql_keywords = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'WITH']\n",
        "    \n",
        "#     # Split by lines and look for SQL statements\n",
        "#     lines = response.split('\\n')\n",
        "#     for line in lines:\n",
        "#         line = line.strip()\n",
        "#         if not line:\n",
        "#             continue\n",
        "            \n",
        "#         # Check if line starts with SQL keyword\n",
        "#         if any(line.upper().startswith(keyword.upper()) for keyword in sql_keywords):\n",
        "#             return clean_sql_query(line)\n",
        "    \n",
        "#     # Method 4: Look for multi-line SQL statements\n",
        "#     for keyword in sql_keywords:\n",
        "#         pattern = rf'\\b{keyword}\\b.*?(?=\\n\\s*\\n|\\nSQLResult|\\nAnswer|$)'\n",
        "#         sql_match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
        "#         if sql_match:\n",
        "#             sql = sql_match.group(0).strip()\n",
        "#             return clean_sql_query(sql)\n",
        "    \n",
        "#     # Fallback: if nothing found, return empty string to avoid errors\n",
        "#     print(f\"Warning: Could not extract SQL from response: {response[:100]}...\")\n",
        "#     return \"SELECT 1\"  # Safe fallback query\n",
        "\n",
        "\n",
        "# def clean_sql_query(sql: str) -> str:\n",
        "#     \"\"\"\n",
        "#     Clean and standardize SQL query.\n",
        "#     \"\"\"\n",
        "#     if not sql:\n",
        "#         return \"SELECT 1\"\n",
        "    \n",
        "#     # Remove extra whitespace\n",
        "#     sql = ' '.join(sql.split())\n",
        "    \n",
        "#     # Fix quote issues - convert double quotes to single quotes for string literals\n",
        "#     # This is a simple approach - for more complex cases, you'd need a proper SQL parser\n",
        "#     sql = re.sub(r'\"([^\"]*)\"', r\"'\\1'\", sql)\n",
        "    \n",
        "#     # Remove multiple semicolons\n",
        "#     sql = re.sub(r';+', ';', sql)\n",
        "    \n",
        "#     # Remove trailing semicolon and add it back cleanly\n",
        "#     sql = sql.rstrip(';').strip()\n",
        "    \n",
        "#     # Don't add semicolon for now since it might be causing issues\n",
        "#     return sql\n",
        "\n",
        "\n",
        "# class Text2SQLWorkflow(Workflow):\n",
        "    \n",
        "#     @step\n",
        "#     async def input_step(self, ev: StartEvent) -> TableRetrievedEvent:\n",
        "#         \"\"\"Process the initial query and retrieve relevant tables\"\"\"\n",
        "#         query = ev.query\n",
        "        \n",
        "#         # Retrieve table schemas (you'll need to define obj_retriever)\n",
        "#         table_schema_objs = obj_retriever.retrieve(query)\n",
        "        \n",
        "#         return TableRetrievedEvent(\n",
        "#             tables=table_schema_objs,\n",
        "#             query_str=query\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def table_output_parser_step(self, ev: TableRetrievedEvent) -> SchemaProcessedEvent:\n",
        "#         \"\"\"Parse table schemas into string format\"\"\"\n",
        "#         # You'll need to define get_table_context_str function\n",
        "#         schema_str = get_table_context_str(ev.tables)\n",
        "        \n",
        "#         return SchemaProcessedEvent(\n",
        "#             table_schema=schema_str,\n",
        "#             query_str=ev.query_str\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def text2sql_prompt_step(self, ev: SchemaProcessedEvent) -> SQLPromptReadyEvent:\n",
        "#         \"\"\"Create the text-to-SQL prompt\"\"\"\n",
        "#         # Enhanced prompt to ensure clean SQL output\n",
        "#         ENHANCED_PROMPT = f\"\"\"\n",
        "#             Given the following table schema and user question, generate a SQL query.\n",
        "\n",
        "#             Table Schema:\n",
        "#             {ev.table_schema}\n",
        "\n",
        "#             User Question: {ev.query_str}\n",
        "\n",
        "#             Instructions:\n",
        "#             1. Generate ONLY a valid SQL query\n",
        "#             2. Do not include any explanations, reasoning, or additional text\n",
        "#             3. Do not include SQLQuery:, SQLResult:, or Answer: labels\n",
        "#             4. Do not wrap in code blocks or other formatting\n",
        "#             5. End the query with a semicolon\n",
        "\n",
        "#             SQL Query:\n",
        "#         \"\"\"\n",
        "        \n",
        "#         # If you have a custom text2sql_prompt, use it instead\n",
        "#         # prompt = text2sql_prompt.format(\n",
        "#         #     query_str=ev.query_str,\n",
        "#         #     table_schema=ev.table_schema\n",
        "#         # )\n",
        "        \n",
        "#         return SQLPromptReadyEvent(\n",
        "#             t2s_prompt=ENHANCED_PROMPT,\n",
        "#             query_str=ev.query_str,\n",
        "#             table_schema=ev.table_schema\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def text2sql_llm_step(self, ev: SQLPromptReadyEvent) -> SQLGeneratedEvent:\n",
        "#         \"\"\"Generate SQL query using LLM\"\"\"\n",
        "#         # You'll need to configure Settings.llm\n",
        "#         sql_response = await Settings.llm.acomplete(ev.t2s_prompt)\n",
        "        \n",
        "#         return SQLGeneratedEvent(\n",
        "#             sql_query=str(sql_response).strip(),\n",
        "#             query_str=ev.query_str,\n",
        "#             table_schema=ev.table_schema\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def sql_output_parser_step(self, ev: SQLGeneratedEvent) -> SQLParsedEvent:\n",
        "#         \"\"\"Parse and clean the generated SQL query\"\"\"\n",
        "#         # Extract clean SQL from the LLM response\n",
        "#         clean_sql = extract_sql_from_response(ev.sql_query)\n",
        "        \n",
        "#         print(f\"Original LLM Response: {ev.sql_query}\")\n",
        "#         print(f\"Cleaned SQL Query: {clean_sql}\")\n",
        "        \n",
        "#         # Validate that we have a reasonable SQL query\n",
        "#         if not clean_sql or clean_sql == \"SELECT 1\":\n",
        "#             print(\"Warning: Could not extract valid SQL, using fallback\")\n",
        "        \n",
        "#         return SQLParsedEvent(\n",
        "#             sql_query=clean_sql,\n",
        "#             query_str=ev.query_str,\n",
        "#             table_schema=ev.table_schema\n",
        "#         )\n",
        "    \n",
        "#     @step\n",
        "#     async def sql_retriever_step(self, ev: SQLParsedEvent) -> SQLResultsEvent:\n",
        "#         \"\"\"Execute SQL query and get results\"\"\"\n",
        "#         try:\n",
        "#             # You'll need to define sql_retriever\n",
        "#             results = sql_retriever.retrieve(ev.sql_query)\n",
        "            \n",
        "#             return SQLResultsEvent(\n",
        "#                 context_str=str(results),\n",
        "#                 sql_query=ev.sql_query,\n",
        "#                 query_str=ev.query_str\n",
        "#             )\n",
        "#         except Exception as e:\n",
        "#             print(f\"SQL Execution Error: {e}\")\n",
        "#             print(f\"Failed SQL Query: {ev.sql_query}\")\n",
        "#             # Return error information for debugging\n",
        "#             return SQLResultsEvent(\n",
        "#                 context_str=f\"SQL execution failed: {str(e)}\",\n",
        "#                 sql_query=ev.sql_query,\n",
        "#                 query_str=ev.query_str\n",
        "#             )\n",
        "    \n",
        "#     @step\n",
        "#     async def response_synthesis_prompt_step(self, ev: SQLResultsEvent) -> ResponsePromptReadyEvent:\n",
        "#         \"\"\"Create the response synthesis prompt\"\"\"\n",
        "#         # You'll need to define response_synthesis_prompt template\n",
        "#         prompt = response_synthesis_prompt.format(\n",
        "#             query_str=ev.query_str,\n",
        "#             context_str=ev.context_str,\n",
        "#             sql_query=ev.sql_query\n",
        "#         )\n",
        "        \n",
        "#         return ResponsePromptReadyEvent(rs_prompt=prompt)\n",
        "    \n",
        "#     @step\n",
        "#     async def response_synthesis_llm_step(self, ev: ResponsePromptReadyEvent) -> StopEvent:\n",
        "#         \"\"\"Generate final answer using LLM\"\"\"\n",
        "#         answer = await Settings.llm.acomplete(ev.rs_prompt)\n",
        "        \n",
        "#         return StopEvent(result=str(answer))\n",
        "\n",
        "\n",
        "# async def run_text2sql_workflow(query: str):\n",
        "#     workflow = Text2SQLWorkflow(timeout=120)\n",
        "#     result = await workflow.run(query=query)\n",
        "#     return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e53ace4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# custom events\n",
        "class TableRetrievedEvent(Event):\n",
        "    tables: list\n",
        "    query_str: str\n",
        "\n",
        "class SchemaProcessedEvent(Event):\n",
        "    table_schema: str\n",
        "    query_str: str\n",
        "\n",
        "class SQLPromptReadyEvent(Event):\n",
        "    t2s_prompt: str\n",
        "    query_str: str\n",
        "    table_schema: str\n",
        "    retry_count: int = 0\n",
        "    error_message: str = \"\"\n",
        "\n",
        "class SQLGeneratedEvent(Event):\n",
        "    sql_query: str\n",
        "    query_str: str\n",
        "    table_schema: str\n",
        "    retry_count: int = 0\n",
        "    error_message: str = \"\"\n",
        "\n",
        "class SQLParsedEvent(Event):\n",
        "    sql_query: str\n",
        "    query_str: str\n",
        "    table_schema: str\n",
        "    retry_count: int = 0\n",
        "    error_message: str = \"\"\n",
        "\n",
        "class SQLResultsEvent(Event):\n",
        "    context_str: str\n",
        "    sql_query: str\n",
        "    query_str: str\n",
        "    success: bool = True\n",
        "\n",
        "class ResponsePromptReadyEvent(Event):\n",
        "    rs_prompt: str\n",
        "\n",
        "\n",
        "\n",
        "def extract_sql_from_response(llm_response: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract SQL query from LLM response that might contain reasoning or formatting.\n",
        "    \"\"\"\n",
        "    response = llm_response.strip()\n",
        "    \n",
        "    # First, remove <think> blocks entirely\n",
        "    response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()\n",
        "    \n",
        "    # Method 1: Look for SQLQuery: pattern\n",
        "    sql_query_match = re.search(r'SQLQuery:\\s*([^;]+;?)', response, re.IGNORECASE | re.DOTALL)\n",
        "    if sql_query_match:\n",
        "        sql = sql_query_match.group(1).strip()\n",
        "        return clean_sql_query(sql)\n",
        "    \n",
        "    # Method 2: Look for SQL in code blocks\n",
        "    code_block_match = re.search(r'```sql\\s*\\n(.*?)\\n```', response, re.IGNORECASE | re.DOTALL)\n",
        "    if code_block_match:\n",
        "        sql = code_block_match.group(1).strip()\n",
        "        return clean_sql_query(sql)\n",
        "    \n",
        "    # Method 3: Look for standalone SQL statements (most common case)\n",
        "    sql_keywords = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'WITH']\n",
        "    \n",
        "    # Split by lines and look for SQL statements\n",
        "    lines = response.split('\\n')\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "            \n",
        "        # Check if line starts with SQL keyword\n",
        "        if any(line.upper().startswith(keyword.upper()) for keyword in sql_keywords):\n",
        "            return clean_sql_query(line)\n",
        "    \n",
        "    # Method 4: Look for multi-line SQL statements\n",
        "    for keyword in sql_keywords:\n",
        "        pattern = rf'\\b{keyword}\\b.*?(?=\\n\\s*\\n|\\nSQLResult|\\nAnswer|$)'\n",
        "        sql_match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)\n",
        "        if sql_match:\n",
        "            sql = sql_match.group(0).strip()\n",
        "            return clean_sql_query(sql)\n",
        "    \n",
        "    # Fallback: if nothing found, return empty string to avoid errors\n",
        "    print(f\"Warning: Could not extract SQL from response: {response[:100]}...\")\n",
        "    return \"SELECT 1\"  # Safe fallback query\n",
        "\n",
        "\n",
        "def clean_sql_query(sql: str) -> str:\n",
        "    \"\"\"\n",
        "    Clean and standardize SQL query.\n",
        "    \"\"\"\n",
        "    if not sql:\n",
        "        return \"SELECT 1\"\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    sql = ' '.join(sql.split())\n",
        "    \n",
        "    # Fix quote issues - convert double quotes to single quotes for string literals\n",
        "    # This is a simple approach - for more complex cases, you'd need a proper SQL parser\n",
        "    sql = re.sub(r'\"([^\"]*)\"', r\"'\\1'\", sql)\n",
        "    \n",
        "    # Remove multiple semicolons\n",
        "    sql = re.sub(r';+', ';', sql)\n",
        "    \n",
        "    # Remove trailing semicolon and add it back cleanly\n",
        "    sql = sql.rstrip(';').strip()\n",
        "    \n",
        "    # Don't add semicolon for now since it might be causing issues\n",
        "    return sql\n",
        "\n",
        "\n",
        "def analyze_sql_error(error_message: str, sql_query: str, table_schema: str) -> str:\n",
        "    \"\"\"\n",
        "    Analyze SQL error and provide suggestions for fixing the query.\n",
        "    \"\"\"\n",
        "    error_lower = error_message.lower()\n",
        "    \n",
        "    if \"no such column\" in error_lower:\n",
        "        # Extract the problematic column name\n",
        "        column_match = re.search(r'no such column:\\s*(\\w+)', error_lower)\n",
        "        if column_match:\n",
        "            bad_column = column_match.group(1)\n",
        "            return f\"Column '{bad_column}' does not exist in the table. Please check the table schema and use the correct column name.\"\n",
        "    \n",
        "    elif \"no such table\" in error_lower:\n",
        "        return \"Table does not exist. Please check the table name in the schema.\"\n",
        "    \n",
        "    elif \"syntax error\" in error_lower:\n",
        "        return \"SQL syntax error. Please check for missing quotes, parentheses, or incorrect SQL structure.\"\n",
        "    \n",
        "    elif \"ambiguous column\" in error_lower:\n",
        "        return \"Ambiguous column reference. Please specify table aliases or use fully qualified column names.\"\n",
        "    \n",
        "    return f\"SQL execution error: {error_message}\"\n",
        "\n",
        "\n",
        "class Text2SQLWorkflow(Workflow):\n",
        "    \n",
        "    @step\n",
        "    async def input_step(self, ev: StartEvent) -> TableRetrievedEvent:\n",
        "        \"\"\"Process the initial query and retrieve relevant tables\"\"\"\n",
        "        query = ev.query\n",
        "        \n",
        "        # Retrieve table schemas (you'll need to define obj_retriever)\n",
        "        table_schema_objs = obj_retriever.retrieve(query)\n",
        "        \n",
        "        return TableRetrievedEvent(\n",
        "            tables=table_schema_objs,\n",
        "            query_str=query\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def table_output_parser_step(self, ev: TableRetrievedEvent) -> SchemaProcessedEvent:\n",
        "        \"\"\"Parse table schemas into string format\"\"\"\n",
        "        # You'll need to define get_table_context_str function\n",
        "        schema_str = get_table_context_str(ev.tables)\n",
        "        \n",
        "        return SchemaProcessedEvent(\n",
        "            table_schema=schema_str,\n",
        "            query_str=ev.query_str\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def text2sql_prompt_step(self, ev: SchemaProcessedEvent | SQLResultsEvent) -> SQLPromptReadyEvent:\n",
        "        \"\"\"Create the text-to-SQL prompt with optional error correction\"\"\"\n",
        "        \n",
        "        # Handle both initial attempt and retry attempts\n",
        "        if isinstance(ev, SchemaProcessedEvent):\n",
        "            table_schema = ev.table_schema\n",
        "            query_str = ev.query_str\n",
        "            retry_count = 0\n",
        "            error_message = \"\"\n",
        "        else:  # SQLResultsEvent (retry case)\n",
        "            table_schema = getattr(ev, 'table_schema', '')\n",
        "            query_str = ev.query_str\n",
        "            retry_count = getattr(ev, 'retry_count', 0) + 1\n",
        "            error_message = getattr(ev, 'error_message', '')\n",
        "        \n",
        "        if retry_count == 0:\n",
        "            # Initial attempt\n",
        "            ENHANCED_PROMPT = f\"\"\"Given the table schema and user question below, generate ONLY a valid SQL query.\n",
        "\n",
        "                Table Schema:\n",
        "                {table_schema}\n",
        "\n",
        "                User Question: {query_str}\n",
        "\n",
        "                IMPORTANT RULES:\n",
        "                1. Return ONLY the SQL query, nothing else\n",
        "                2. Use single quotes for string literals, not double quotes\n",
        "                3. Do not include any explanations, reasoning, or additional text\n",
        "                4. Do not include labels like \"SQLQuery:\", \"Answer:\", etc.\n",
        "                5. Do not wrap in code blocks or markdown formatting\n",
        "                6. Do not include semicolons at the end\n",
        "                7. Do not include any <think> tags or reasoning\n",
        "                8. Only use column names that exist in the provided schema\n",
        "\n",
        "                Example format:\n",
        "                SELECT column_name FROM table_name WHERE condition\n",
        "\n",
        "                Your SQL query:\n",
        "            \"\"\"\n",
        "        else:\n",
        "            # Retry attempt with error information\n",
        "            ENHANCED_PROMPT = f\"\"\"The previous SQL query failed with an error. Please generate a corrected SQL query.\n",
        "\n",
        "                Table Schema:\n",
        "                {table_schema}\n",
        "\n",
        "                User Question: {query_str}\n",
        "\n",
        "                Previous Error: {error_message}\n",
        "\n",
        "                IMPORTANT RULES:\n",
        "                1. Return ONLY the corrected SQL query, nothing else\n",
        "                2. Use single quotes for string literals, not double quotes\n",
        "                3. Carefully check that all column names exist in the provided schema\n",
        "                4. Do not include any explanations, reasoning, or additional text\n",
        "                5. Do not include labels like \"SQLQuery:\", \"Answer:\", etc.\n",
        "                6. Do not wrap in code blocks or markdown formatting\n",
        "                7. Do not include semicolons at the end\n",
        "                8. Only use column names that are explicitly listed in the schema above\n",
        "\n",
        "                Your corrected SQL query:\n",
        "            \"\"\"\n",
        "        \n",
        "        return SQLPromptReadyEvent(\n",
        "            t2s_prompt=ENHANCED_PROMPT,\n",
        "            query_str=query_str,\n",
        "            table_schema=table_schema,\n",
        "            retry_count=retry_count,\n",
        "            error_message=error_message\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def text2sql_llm_step(self, ev: SQLPromptReadyEvent) -> SQLGeneratedEvent:\n",
        "        \"\"\"Generate SQL query using LLM\"\"\"\n",
        "        # You'll need to configure Settings.llm\n",
        "        sql_response = await Settings.llm.acomplete(ev.t2s_prompt)\n",
        "        \n",
        "        return SQLGeneratedEvent(\n",
        "            sql_query=str(sql_response).strip(),\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=ev.table_schema,\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=ev.error_message\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def sql_output_parser_step(self, ev: SQLGeneratedEvent) -> SQLParsedEvent:\n",
        "        \"\"\"Parse and clean the generated SQL query\"\"\"\n",
        "        # Extract clean SQL from the LLM response\n",
        "        clean_sql = extract_sql_from_response(ev.sql_query)\n",
        "        \n",
        "        print(f\"Attempt #{ev.retry_count + 1}\")\n",
        "        print(f\"Original LLM Response: {ev.sql_query}\")\n",
        "        print(f\"Cleaned SQL Query: {clean_sql}\")\n",
        "        \n",
        "        # Validate that we have a reasonable SQL query\n",
        "        if not clean_sql or clean_sql == \"SELECT 1\":\n",
        "            print(\"Warning: Could not extract valid SQL, using fallback\")\n",
        "        \n",
        "        return SQLParsedEvent(\n",
        "            sql_query=clean_sql,\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=ev.table_schema,\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=ev.error_message\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def sql_retriever_step(self, ev: SQLParsedEvent) -> SQLResultsEvent:\n",
        "        \"\"\"Execute SQL query and get results with retry logic\"\"\"\n",
        "        max_retries = 3\n",
        "        \n",
        "        try:\n",
        "            # You'll need to define sql_retriever\n",
        "            results = sql_retriever.retrieve(ev.sql_query)\n",
        "            \n",
        "            print(f\"[SUCCESS] SQL executed successfully on attempt #{ev.retry_count + 1}\")\n",
        "            return SQLResultsEvent(\n",
        "                context_str=str(results),\n",
        "                sql_query=ev.sql_query,\n",
        "                query_str=ev.query_str,\n",
        "                success=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            error_msg = str(e)\n",
        "            print(f\"[ERROR] SQL Execution Error (Attempt #{ev.retry_count + 1}): {error_msg}\")\n",
        "            print(f\"Failed SQL Query: {ev.sql_query}\")\n",
        "            \n",
        "            # Check if we should retry\n",
        "            if ev.retry_count < max_retries:\n",
        "                print(f\"[RETRY] Retrying... (Attempt #{ev.retry_count + 2}/{max_retries + 1})\")\n",
        "                \n",
        "                # Create a new event that will trigger a retry\n",
        "                error_analysis = analyze_sql_error(error_msg, ev.sql_query, ev.table_schema)\n",
        "                \n",
        "                # Return an SQLResultsEvent that will trigger a retry\n",
        "                retry_event = SQLResultsEvent(\n",
        "                    context_str=\"\",\n",
        "                    sql_query=ev.sql_query,\n",
        "                    query_str=ev.query_str,\n",
        "                    success=False\n",
        "                )\n",
        "                retry_event.retry_count = ev.retry_count + 1\n",
        "                retry_event.error_message = error_analysis\n",
        "                retry_event.table_schema = ev.table_schema\n",
        "                \n",
        "                return retry_event\n",
        "            else:\n",
        "                print(f\"[ERROR, RETRY FAILED] Max retries ({max_retries}) reached. Giving up.\")\n",
        "                return SQLResultsEvent(\n",
        "                    context_str=f\"Failed to execute SQL after {max_retries + 1} attempts. Final error: {error_msg}\",\n",
        "                    sql_query=ev.sql_query,\n",
        "                    query_str=ev.query_str,\n",
        "                    success=False\n",
        "                )\n",
        "    \n",
        "    @step\n",
        "    async def retry_handler_step(self, ev: SQLResultsEvent) -> SQLPromptReadyEvent:\n",
        "        \"\"\"Handle retry logic - only triggered when SQL execution fails\"\"\"\n",
        "        # This step only processes failed SQL results that need retrying\n",
        "        if ev.success or not hasattr(ev, 'retry_count'):\n",
        "            return None  # Let successful results pass through to response synthesis\n",
        "        \n",
        "        print(f\"[RETRY] Preparing retry #{ev.retry_count + 1}\")\n",
        "        \n",
        "        # Create a new prompt event for retry\n",
        "        return SQLPromptReadyEvent(\n",
        "            t2s_prompt=\"\",  # Will be filled in text2sql_prompt_step\n",
        "            query_str=ev.query_str,\n",
        "            table_schema=getattr(ev, 'table_schema', ''),\n",
        "            retry_count=ev.retry_count,\n",
        "            error_message=getattr(ev, 'error_message', 'Unknown error')\n",
        "        )\n",
        "    \n",
        "    @step\n",
        "    async def response_synthesis_prompt_step(self, ev: SQLResultsEvent) -> ResponsePromptReadyEvent:\n",
        "        \"\"\"Create the response synthesis prompt - only for successful SQL results\"\"\"\n",
        "        # Only process successful SQL results\n",
        "        if not ev.success:\n",
        "            return None\n",
        "            \n",
        "        # You'll need to define response_synthesis_prompt template\n",
        "        prompt = response_synthesis_prompt.format(\n",
        "            query_str=ev.query_str,\n",
        "            context_str=ev.context_str,\n",
        "            sql_query=ev.sql_query\n",
        "        )\n",
        "        \n",
        "        return ResponsePromptReadyEvent(rs_prompt=prompt)\n",
        "    \n",
        "    @step\n",
        "    async def response_synthesis_llm_step(self, ev: ResponsePromptReadyEvent) -> StopEvent:\n",
        "        \"\"\"Generate final answer using LLM\"\"\"\n",
        "        answer = await Settings.llm.acomplete(ev.rs_prompt)\n",
        "        \n",
        "        return StopEvent(result=str(answer))\n",
        "\n",
        "\n",
        "async def run_text2sql_workflow(query: str):\n",
        "    workflow = Text2SQLWorkflow(timeout=240)\n",
        "    result = await workflow.run(query=query)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e250a417-42c3-49c2-a037-a282974d5f9a",
      "metadata": {
        "id": "e250a417-42c3-49c2-a037-a282974d5f9a"
      },
      "source": [
        "### Visualize Workflow\n",
        "\n",
        "A really nice property of the query pipeline syntax is you can easily visualize it in a graph via networkx."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5f419c-c128-4b04-b18f-0f8b671ff3a4",
      "metadata": {
        "id": "8c5f419c-c128-4b04-b18f-0f8b671ff3a4",
        "outputId": "713e82d3-ddae-4a41-bd65-0cfd802eae9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved text2sql_dag.html successfully.\n"
          ]
        }
      ],
      "source": [
        "# # Build a directed graph of steps\n",
        "# G = nx.DiGraph()\n",
        "\n",
        "# # Nodes\n",
        "# steps = [\n",
        "#     \"input\",\n",
        "#     \"table_retriever\",\n",
        "#     \"table_output_parser\",\n",
        "#     \"text2sql_prompt\",\n",
        "#     \"text2sql_llm\",\n",
        "#     \"sql_output_parser\",\n",
        "#     \"sql_retriever\",\n",
        "#     \"response_synthesis_prompt\",\n",
        "#     \"response_synthesis_llm\"\n",
        "# ]\n",
        "# G.add_nodes_from(steps)\n",
        "\n",
        "# # Edges\n",
        "# edges = [\n",
        "#     (\"input\", \"table_retriever\"),\n",
        "#     (\"table_retriever\", \"table_output_parser\"),\n",
        "    \n",
        "#     (\"input\", \"text2sql_prompt\"),\n",
        "#     (\"table_output_parser\", \"text2sql_prompt\"),\n",
        "\n",
        "#     (\"text2sql_prompt\", \"text2sql_llm\"),\n",
        "#     (\"text2sql_llm\", \"sql_output_parser\"),\n",
        "#     (\"sql_output_parser\", \"sql_retriever\"),\n",
        "    \n",
        "#     (\"sql_output_parser\", \"response_synthesis_prompt\"),\n",
        "#     (\"sql_retriever\", \"response_synthesis_prompt\"),\n",
        "#     (\"input\", \"response_synthesis_prompt\"),\n",
        "    \n",
        "#     (\"response_synthesis_prompt\", \"response_synthesis_llm\")\n",
        "# ]\n",
        "# G.add_edges_from(edges)\n",
        "\n",
        "# # Visualize\n",
        "# net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
        "# net.from_nx(G)\n",
        "\n",
        "# html_content = net.generate_html()\n",
        "# with open(\"../outputs/trials_v1/text2sql_dag.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "#     f.write(html_content)\n",
        "\n",
        "# print(\"Saved text2sql_dag.html successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f9eed9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drawing workflow structure...\n",
            "../outputs/trials_v1\\text2sql_workflow_structure.html\n",
            "[SUCCESS] Workflow structure saved to: ../outputs/trials_v1\\text2sql_workflow_structure.html\n"
          ]
        }
      ],
      "source": [
        "async def visualize_text2sql_workflow():\n",
        "    \"\"\"\n",
        "    Function to visualize the Text2SQL workflow both as all possible flows\n",
        "    and a specific execution example\n",
        "    \"\"\"\n",
        "    output_dir = (\"../outputs/trials_v1\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # 1. Draw ALL possible flows through your workflow\n",
        "    print(\"Drawing all possible flows...\")\n",
        "    all_flows_path = os.path.join(output_dir, \"text2sql_workflow_all_flows.html\")\n",
        "    draw_all_possible_flows(\n",
        "        Text2SQLWorkflow, \n",
        "        filename=all_flows_path\n",
        "    )\n",
        "    print(f\"[SUCCESS] All possible flows saved to: {all_flows_path}\")\n",
        "\n",
        "    # 2. Draw a specific execution to see the actual path taken\n",
        "    print(\"Running workflow and drawing execution path...\")\n",
        "    \n",
        "    # Create workflow instance\n",
        "    workflow = Text2SQLWorkflow(timeout=240)\n",
        "    \n",
        "    # Run with a sample query\n",
        "    sample_query = \"What are the top 5 customers by total orders?\"\n",
        "    \n",
        "    try:\n",
        "        # Execute the workflow\n",
        "        result = await workflow.run(query=sample_query)\n",
        "        \n",
        "        # Draw the execution path\n",
        "        execution_path = os.path.join(output_dir, \"text2sql_workflow_recent_execution.html\")\n",
        "        draw_most_recent_execution(\n",
        "            workflow,\n",
        "            filename=execution_path\n",
        "        )\n",
        "        print(f\"[SUCCESS] Recent execution path saved to: {execution_path}\")\n",
        "        print(f\"Workflow result: {result}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Error during workflow execution: {e}\")\n",
        "        print(\"Note: You may need to set up your retriever and LLM settings first\")\n",
        "\n",
        "# Alternative: Just visualize all flows without execution\n",
        "def visualize_workflow_structure_only():\n",
        "    \"\"\"\n",
        "    Just visualize the workflow structure without executing it\n",
        "    \"\"\"\n",
        "    output_dir = \"../outputs/trials_v1\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    structure_path = os.path.join(output_dir, \"text2sql_workflow_structure.html\")\n",
        "    print(\"Drawing workflow structure...\")\n",
        "    draw_all_possible_flows(\n",
        "        Text2SQLWorkflow,\n",
        "        filename=structure_path\n",
        "    )\n",
        "    print(f\"[SUCCESS] Workflow structure saved to: {structure_path}\")\n",
        "\n",
        "\n",
        "# Option 1: Just structure\n",
        "visualize_workflow_structure_only()\n",
        "\n",
        "# Option 2: Full visualization with execution\n",
        "# asyncio.run(visualize_text2sql_workflow())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b525ef9b-cb94-401e-8fd8-47c94eb3eaa5",
      "metadata": {
        "id": "b525ef9b-cb94-401e-8fd8-47c94eb3eaa5"
      },
      "source": [
        "### Run Some Queries!\n",
        "\n",
        "Now we're ready to run some queries across this entire pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "0c0d9411",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user is asking for the year that The Notorious B.I.G was signed to Bad Boy. Hmm, I need to figure out how to connect the tables here.\n",
            "\n",
            "First, the Notorious B.I.G is an artist, so their signing year probably comes from the people_info table. The people_info table has columns Act (VARCHAR) and Year_signed (INTEGER). The question is asking for the Year_signed, so I need to find a row in people_info where the Act is 'The Notorious B.I.G'. Then, check if there's a link between their signing and the album released under Bad Boy. \n",
            "\n",
            "Wait, the table schema mentions people_info has _Albums_released_under_Bad_Boy (VARCHAR). So maybe the people_info table has a column that refers to the album's release year. But the user is asking about the signing year, not the album release. So the question is about the year they signed to Bad Boy's album.\n",
            "\n",
            "So the user wants the Year_signed from the people_info where Act is 'The Notorious B.I.G'. How to get that? Maybe a JOIN between people_info and the table where they are an artist, but the problem is there's no table linking people to other tables except people_info. Wait, the tables are people_info, Grammy Awards, and drop_event_data. The user is asking about the signing of B.I.G, so the people_info table's Act column must be 'The Notorious B.I.G'. Therefore, the SQL query would be SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G'; but the problem says to generate only a valid SQL query. So maybe that's the answer. But the example given in the problem shows SELECT column names. Wait, the example uses SELECT column_name FROM table_name WHERE condition. So perhaps the correct query is that, but the user's question is about the year, so the answer is the same as the example. Therefore, the SQL query would be as simple as selecting Year_signed from people_info where Act is 'The Notorious B.I.G'.\n",
            "</think>\n",
            "\n",
            "SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G';\n",
            "Cleaned SQL Query: SELECT Year_signed FROM people_info WHERE Act = 'The Notorious B.I.G'\n",
            "[SUCCESS] SQL executed successfully on attempt #1\n",
            "<think>\n",
            "Okay, let's see. The user is asking for the year The Notorious B.I.G was signed to Bad Boy. The SQL query selects the Year_signed from the people_info table where the Act is 'The Notorious B.I.G'. The SQL response gives a result of 1993.\n",
            "\n",
            "So, the SQL query's result is a list with one entry, 1993. That means the answer is 1993. I need to make sure there's no other data or context I'm missing. The problem seems straightforward. The SQL is correct, and the result is a single value. Therefore, the answer should be 1993.\n",
            "</think>\n",
            "\n",
            "The Notorious B.I.G was signed to Bad Boy in the year 1993.\n"
          ]
        }
      ],
      "source": [
        "result = await run_text2sql_workflow(\"What was the year that The Notorious B.I.G was signed to Bad Boy?\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "89dfbb01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user wants to know who won the best director in the 1972 academy awards. So first, I need to figure out how to connect the tables to get that information.\n",
            "\n",
            "The tables involved here are award_data_1972, award_nominations, and award_data. The question is about the 1972 awards, so maybe I should look at the year column in those tables. The problem is that the award_data table has the years, but the user is asking specifically for 1972. Also, the question refers to the best director, which is a specific award. \n",
            "\n",
            "Looking at the tables, the award_nominations table might have the year and award details. The result column in award_data_1972 and award_nominations could indicate the result, but how does that relate to the director? Wait, maybe the best director is tied to a specific award. So perhaps in award_nominations, there's a column that corresponds to the best director, or maybe in award_data, there's a category that includes the director. \n",
            "\n",
            "Wait, the user's question is about the best director in 1972. The tables' columns are Award, Category, Nominee, Result, etc. So maybe in award_nominations, there's a nominee field that corresponds to the director. Or in award_data, there's a category like \"Director\" and the year 1972. \n",
            "\n",
            "So the steps would be: check if the award in award_nominations has a year of 1972 and the category as \"Director\". Then select the Nominee from that table. Alternatively, check if the award_data has the year 1972 and the category \"Director\". Then select the Nominee. \n",
            "\n",
            "Wait, but the user is asking for the best director, so maybe the result column in award_nominations or award_data tells us that. Let's think. The result column in award_nominations and award_data could indicate the category. For example, if in award_nominations, the result is \"Best Director\", then the Nominee would be the answer. Similarly, if in award_data, the category is \"Director\" and the year is 1972, then the Nominee would be the answer. \n",
            "\n",
            "So the SQL query would need to check for those conditions. Let's structure it. First, check if there's a nomination in award_nominations where the year is 1972 and the category is \"Director\". Then select the Nominee. Alternatively, check if in award_data, there's a record with year 1972 and category \"Director\". \n",
            "\n",
            "But how to connect these tables? Since the user is asking for the best director, maybe the result column in award_nominations or award_data indicates that. So the SQL query could be: SELECT Nominee FROM award_nominations WHERE Year = 1972 AND Category = 'Director'; or from award_data. \n",
            "\n",
            "Wait, but the problem says to use the provided schema. Let me check the tables again. The award_nominations has columns Year, Award, Film, Result. The award_data has columns Year, Award, Category, Nominated_work, Result. The user's question is about the best director, so maybe the result column in award_nominations or award_data has that information. \n",
            "\n",
            "So the SQL query would be either selecting from award_nominations or award_data. But how to know which one? Maybe the best director is in a specific category. For example, in award_nominations, if the result is \"Best Director\", then the Nominee is the answer. Or in award_data, if the category is \"Director\" and the year is 1972, then the Nominee is the answer. \n",
            "\n",
            "So the SQL query could be: SELECT Nominee FROM award_nominations WHERE Year = 1972 AND Category = 'Director'; or from award_data. But which one is correct? Let's think. The user's question is phrased as \"Who won best director in the 1972 academy awards\". So the answer is the person who won that award. If the result in award_nominations is \"Best Director\", then the Nominee is the answer. Similarly, if in award_data, there's a record with year 1972 and category \"Director\", then the Nominee is the answer. \n",
            "\n",
            "So the SQL query would be selecting the Nominee from either table. But how to know which one? Since the user's question is about the best director, maybe the result in award_nominations or award_data would have that information. \n",
            "\n",
            "Alternatively, maybe the award_data has the year and category, and the Nominee is stored there. So the query would be: SELECT Nominee FROM award_data WHERE Year = 1972 AND Category = 'Director'; \n",
            "\n",
            "But the problem is that the tables are different. For example, award_data has a category, but the user is asking about a specific category. So perhaps the correct approach is to check for the category in award_nominations. \n",
            "\n",
            "Wait, the user's question is about the best director, so the answer is the person who won that award. If in award_nominations, the result is \"Best Director\", then the Nominee is the answer. Similarly, in award_data, if there's a record where the category is \"Director\" and the year is 1972, then the Nominee is the answer. \n",
            "\n",
            "Therefore, the SQL query could be: SELECT Nominee FROM award_nominations WHERE Year = 1972 AND Category = 'Director'; \n",
            "\n",
            "Or from award_data. But how to decide? Since the problem says to use the provided schema, and the tables have columns like Year, Award, Category, etc., perhaps the answer is from award_nominations. \n",
            "\n",
            "Wait, but the user's question is phrased as \"Who won best director in the 1972 academy awards\", which implies that there's a specific award in 1972. So maybe the answer is from award_nominations where the result is \"Best Director\". \n",
            "\n",
            "Alternatively, maybe in award_data, the category is \"Director\", and the year is 1972. \n",
            "\n",
            "But since the user's question is about the best director, which is a specific award, the correct approach is to check for that specific award in the relevant tables. So the SQL query would be selecting the Nominee from the award_nominations or award_data table where the year is 1972 and the category is \"Director\". \n",
            "\n",
            "Therefore, the final SQL query would be: \n",
            "\n",
            "SELECT Nominee FROM award_nominations WHERE Year = 1972 AND Category = 'Director';\n",
            "\n",
            "Or from award_data. But how to know? Since the problem says to use the provided schema, and the tables have those columns, perhaps the answer is from award_nominations. \n",
            "\n",
            "But maybe the answer is from award_data. Let me check. If the award_data has the year and category, and the Nominee is stored there, then yes. So the query would be:\n",
            "\n",
            "SELECT Nominee FROM award_data WHERE Year = 1972 AND Category = 'Director';\n",
            "\n",
            "But the user's question is about the best director, which is a specific award. So the answer depends on which table has that information. \n",
            "\n",
            "Since the user's question is in the context of the tables provided, and given that the tables have the columns, the correct approach is to use the award_nominations table. \n",
            "\n",
            "But I'm not entirely sure. Maybe there's a way to combine the tables. For example, if the result in award_nominations indicates the category, and the year is 1972, then the Nominee is the answer. \n",
            "\n",
            "Alternatively, maybe the answer is in award_data. \n",
            "\n",
            "But the problem says to generate only a valid SQL query. So the user's question is asking for who won best director in 1972, so the answer is the Nominee from the relevant table. \n",
            "\n",
            "So the final answer would be a query that selects the Nominee from the award_nominations or award_data table where Year is 1972 and Category is 'Director'. \n",
            "\n",
            "Therefore, the SQL query is:\n",
            "\n",
            "SELECT Nominee FROM award_nominations WHERE Year = 1972 AND Category = 'Director';\n",
            "\n",
            "Or from award_data. But which one? Since the user's question is about 1972, and the tables have those columns, perhaps the answer is from award_data. \n",
            "\n",
            "Wait, but the award_data has columns like Year, Award, Category, etc. So if in award_data, the Year is 1972 and the Category is 'Director', then the Nominee is the answer. \n",
            "\n",
            "So the query would be:\n",
            "\n",
            "SELECT Nominee FROM award_data WHERE Year = 1972 AND Category = 'Director';\n",
            "\n",
            "Yes, that makes sense. So the answer is this query.\n",
            "</think>\n",
            "\n",
            "SELECT Nominee FROM award_nominations WHERE Year = 1972 AND Category = 'Director';\n",
            "Cleaned SQL Query: SELECT Nominee FROM award_nominations WHERE Year = 1972 AND Category = 'Director'\n",
            "[ERROR] SQL Execution Error (Attempt #1): Statement \"SELECT Nominee FROM award_nominations WHERE Year = 1972 AND Category = 'Director'\" is invalid SQL.\n",
            "Error: no such column: Nominee\n",
            "Failed SQL Query: SELECT Nominee FROM award_nominations WHERE Year = 1972 AND Category = 'Director'\n",
            "[RETRY] Retrying... (Attempt #2/4)\n",
            "[RETRY] Preparing retry #2\n",
            "Warning: Could not extract SQL from response: 您好！您需要我帮助吗？请提供您需要的信息或问题，我会尽力为您提供支持。...\n",
            "Attempt #2\n",
            "Original LLM Response: <think>\n",
            "Okay, the user provided a query in Chinese, but the actual content is empty. I need to ask them to provide the specific information they want to use. Let me check if there's any context or previous messages I missed. Since there's no previous interaction, I should prompt them to give the details they need. I'll make sure to respond politely and ask clearly.\n",
            "</think>\n",
            "\n",
            "您好！您需要我帮助吗？请提供您需要的信息或问题，我会尽力为您提供支持。\n",
            "Cleaned SQL Query: SELECT 1\n",
            "Warning: Could not extract valid SQL, using fallback\n",
            "[SUCCESS] SQL executed successfully on attempt #2\n",
            "Attempt #3\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user is asking for the query that gives the winner of the best director in 1972 academy awards. The previous error was that the column 'nominee' doesn't exist in the table, so I need to check the schema again.\n",
            "\n",
            "First, looking at the tables provided. The 'award_data_1972' has columns: Award, Category, Nominee, Result. The 'award_nominations' has Year, Award, Film, Result. The 'award_data' has Year, Award, Category, Nominated_work, Result. So the correct column for the nominee is 'Nominee' in 'award_data_1972'.\n",
            "\n",
            "The user's question is about the best director in 1972. So I need to find the 'Award' in 'award_data_1972' where the year is 1972, and set the 'Result' to 'best director' and then join or select the relevant fields. But wait, the 'Award' in the 'award_data_1972' table is the same as in the 'award_nominations' table, but the user's question is about the best director, which might be a different award. However, the problem might be that the user is looking for a single record, so perhaps the correct approach is to check if there's a 'Award' in the 'award_data_1972' that matches the best director and the year 1972. But since the error was about the column, maybe the correct query is to select from the correct table where the year is 1972, and the result is 'best director'.\n",
            "\n",
            "So the corrected SQL query would be SELECT * FROM award_data_1972 WHERE Year = 1972 AND Result = 'best director'; but wait, the user's question is about the nominee, not the result. So maybe the correct approach is to join the tables. Let me think again. The 'nominee' column in 'award_data_1972' would correspond to the nominee's name. So the query should select from award_data_1972 where Year is 1972, and the Result is 'best director'. But the previous error was about the column not existing, so maybe the correct query is to use the correct column names as provided. Therefore, the corrected SQL would be SELECT * FROM award_data_1972 WHERE Year = 1972 AND Result = 'best director';\n",
            "</think>\n",
            "\n",
            "SELECT * FROM award_data_1972 WHERE Year = 1972 AND Result = 'best director';\n",
            "Cleaned SQL Query: SELECT * FROM award_data_1972 WHERE Year = 1972 AND Result = 'best director'\n",
            "[ERROR] SQL Execution Error (Attempt #3): Statement \"SELECT * FROM award_data_1972 WHERE Year = 1972 AND Result = 'best director'\" is invalid SQL.\n",
            "Error: no such column: Year\n",
            "Failed SQL Query: SELECT * FROM award_data_1972 WHERE Year = 1972 AND Result = 'best director'\n",
            "[RETRY] Retrying... (Attempt #4/4)\n",
            "[RETRY] Preparing retry #4\n",
            "Attempt #2\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user wants a corrected SQL query for the 1972 Academy Awards Best Director. First, I need to check the provided schema. Wait, the schema is empty? Oh, the user mentioned the table schema, but there's nothing listed. That's a problem. Maybe the original query had a typo, but without the schema details, I can't proceed. Wait, the user's previous error message says the previous SQL query failed. But the schema isn't provided here. How can I fix the query without knowing the actual table structure? Maybe there's a mistake in the initial setup, but without the schema, I can't write the correct query. Hmm, this is confusing. The user might have included some details, but in the current context, there's no table schema. Maybe there's a missing part here. But according to the instructions, I need to generate a corrected SQL query using the provided schema. Since the schema isn't here, perhaps the user expects me to assume some standard table names. Wait, the problem statement says \"Use single quotes for string literals, not double quotes\" and \"Carefully check that all column names exist in the provided schema\". But if the schema is empty, there's no way to check. Maybe there was an error in the initial setup, but without the schema, I can't create the query. This is a contradiction. The user might have provided the schema, but in the current message, it's missing. So perhaps there's a mistake in the message, and the actual schema is present elsewhere. But since I can't access external data, I can't proceed. Wait, maybe the user included the schema in their message, but in the current context, it's not visible. So the answer is that the schema is missing, making it impossible to correct the query. But the user wants a corrected SQL query, so maybe there's an error in the original query, but without the schema, I can't fix it. This is a problem. Maybe I should inform the user that the schema is missing and ask for it. But according to the instructions, I need to return the corrected query. Hmm. Maybe there's a misunderstanding here. Let me re-read the problem statement. The user says, \"The previous SQL query failed with an error. Please generate a corrected SQL query. Table Schema: [...]\". Then the user mentions that the schema is empty. So perhaps the original query had a missing table or column, but without knowing the schema, I can't fix it. Therefore, the answer is that the schema is missing, making it impossible to correct the query. But the user wants the corrected SQL query. So maybe there's an error in the initial setup, but without the schema, I can't proceed. Therefore, the answer is that the schema is missing, and thus no correction can be made. But the user's instruction says to return the corrected query. Maybe there's a typo in the schema, but I can't verify. This is confusing. Perhaps the user intended to provide the schema, but in the current message, it's missing. So I need to state that. But the user's instructions say not to include explanations or labels. So the final answer is that the schema is missing, making it impossible to correct the query.\n",
            "</think>\n",
            "\n",
            "```sql\n",
            "SELECT * FROM [Best Director 1972] WHERE Year = '1972';\n",
            "```\n",
            "Cleaned SQL Query: SELECT * FROM [Best Director 1972] WHERE Year = '1972'\n",
            "[ERROR] SQL Execution Error (Attempt #2): Statement \"SELECT * FROM [Best Director 1972] WHERE Year = '1972'\" is invalid SQL.\n",
            "Error: no such table: Best Director 1972\n",
            "Failed SQL Query: SELECT * FROM [Best Director 1972] WHERE Year = '1972'\n",
            "[RETRY] Retrying... (Attempt #3/4)\n",
            "[RETRY] Preparing retry #3\n"
          ]
        },
        {
          "ename": "WorkflowTimeoutError",
          "evalue": "Operation timed out after 240 seconds",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mWorkflowTimeoutError\u001b[39m                      Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response_1 = \u001b[38;5;28;01mawait\u001b[39;00m run_text2sql_workflow(\u001b[33m\"\u001b[39m\u001b[33mWho won best director in the 1972 academy awards\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(response_1)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 369\u001b[39m, in \u001b[36mrun_text2sql_workflow\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_text2sql_workflow\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    368\u001b[39m     workflow = Text2SQLWorkflow(timeout=\u001b[32m240\u001b[39m)  \u001b[38;5;66;03m# Increased timeout for retries\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m workflow.run(query=query)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Documents\\GitHub\\rag_text-2-sql\\rag\\Lib\\site-packages\\workflows\\workflow.py:486\u001b[39m, in \u001b[36mWorkflow.run.<locals>._run_workflow\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    483\u001b[39m         ctx.write_event_to_stream(StopEvent())\n\u001b[32m    485\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOperation timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._timeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m WorkflowTimeoutError(msg)\n\u001b[32m    488\u001b[39m     result.set_result(ctx._retval)\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[31mWorkflowTimeoutError\u001b[39m: Operation timed out after 240 seconds"
          ]
        }
      ],
      "source": [
        "response_1 = await run_text2sql_workflow(\"Who won best director in the 1972 academy awards\")\n",
        "print(response_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "16c87f2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user is asking for the term of Pasquale Preziosa. I need to figure out which table to use and how to connect it.\n",
            "\n",
            "First, looking at the schema, there's a table called 'government_ministers' with columns like 'Preceded_by_Alfred_Scott', 'Member_of_Parliament_for_Ashton_under_Lyne_1910_1916', and 'Succeeded_by_Albert_Stanley'. But the user's question is about Pasquale Preziosa, which isn't mentioned in the database. So maybe that's not the right table.\n",
            "\n",
            "Then there's a table called 'new_municipality_old_municipality_seat' with columns New_municipality, Old_municipalities, and Seat. But again, Pasquale's name isn't there. Wait, maybe there's another table with people's names. The third table is 'people_terms' which has Name, Term_start, Term_end. Oh! The people_terms table has the name, and perhaps their term starts and ends. But the question is specifically about Pasquale's term. So if I can find a connection between Pasquale's name and the people_terms table, maybe by checking if there's a record where the Name is Pasquale Preziosa. But the problem is, the user hasn't provided any data in the tables, so perhaps I need to assume that Pasquale Preziosa is in the people_terms table and that the term is in Term_start or Term_end. Wait, the user's question is phrased as \"What was the term of Pasquale Preziosa?\" so maybe the answer is looking for the Term_start or Term_end in the people_terms table where the Name is Pasquale Preziosa. But how do I connect the tables?\n",
            "\n",
            "Wait, maybe there's a mistake in the problem setup? Or perhaps the user expects that Pasquale Preziosa is in the people_terms table. But the problem states that the tables are as provided. So perhaps the correct approach is to select from people_terms where Name is 'Pasquale Preziosa' and look for Term_start or Term_end. But since the user hasn't provided any data, maybe there's an error here. Alternatively, maybe there's a different approach. Wait, the rules say to generate only a valid SQL query, so perhaps the answer is to select Term_start or Term_end from people_terms where the Name is Pasquale Preziosa. But how can I know that?\n",
            "\n",
            "Alternatively, maybe the 'government_ministers' table has some information. Let's check. The columns in government_ministers are preceded by Alfred Scott, member for Ashton under Lynne 1910-1916, and succeeded by Albert Stanley. But the user is asking about Pasquale Preziosa, who isn't listed. So that table probably isn't the right one. The new_municipality_old_municipality_seat table has seat names, but that's not relevant. The people_terms table is the only one that could have the term data. Unless there's a mistake in the problem, but the user is asking for the query, so perhaps the correct SQL is to select Term_start or Term_end from people_terms where Name is Pasquale Preziosa. So the answer would be SELECT Term_start, Term_end FROM people_terms WHERE Name = 'Pasquale Preziosa'; but since the user wants only a valid SQL query, and there's no other tables, maybe that's the answer. So the final answer is the SQL query to select Term_start or Term_end from people_terms where Name is Pasquale Preziosa.\n",
            "</think>\n",
            "\n",
            "SELECT Term_start, Term_end FROM people_terms WHERE Name = 'Pasquale Preziosa';\n",
            "Cleaned SQL Query: SELECT Term_start, Term_end FROM people_terms WHERE Name = 'Pasquale Preziosa'\n",
            "[SUCCESS] SQL executed successfully on attempt #1\n",
            "<think>\n",
            "Okay, let's see. The user is asking for the term of Pasquale Preziosa based on the SQL query provided. The SQL response gives a list of terms with the name 'Pasquale Preziosa'. The result is [('25 February 2013', 'Incumbent')]. So, the term is 'Incumbent'.\n",
            "\n",
            "Wait, but how do I present this in a concise way? The user wants the answer from the query results, so I need to state that the term is Incumbent. Make sure to include the date and the role. Also, check if there's any additional information from the SQL response that I missed, but the response seems straightforward. No need to include the score or other metadata. Just the term itself.\n",
            "</think>\n",
            "\n",
            "The term associated with Pasquale Preziosa is **Incumbent**.\n"
          ]
        }
      ],
      "source": [
        "response_2 = await run_text2sql_workflow(\"What was the term of Pasquale Preziosa?\")\n",
        "print(response_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "2e4461a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt #1\n",
            "Original LLM Response: <think>\n",
            "Okay, let's see. The user wants to show total sales by region. The tables involved are chart_positions, district_info, and movie_chart_positions. The question is about regions, so I need to figure out which regions they refer to.\n",
            "\n",
            "First, looking at the tables, chart_positions has columns like Peak_chart_positions_US, Certifications_sales_thresholds_ (INTEGER), and others. The district_info table has Population, Area_Size_km²_, and Density_per_km²_. The movie_chart_positions table has Chart_Positions_UK, Chart_Positions_US, etc. \n",
            "\n",
            "The user's question is about total sales by region. Since the table schema mentions chart_positions with sales thresholds, and another table with sales thresholds (maybe Certifications_sales_thresholds_?), I need to connect these tables. Wait, in the chart_positions table, there's a column called Certifications_sales_thresholds_ which is an INTEGER. Maybe that's the sales threshold for certifications. But how does that tie into regions?\n",
            "\n",
            "Wait, the user wants total sales by region. The problem is that the tables don't directly link to regions unless there's a join. But the user provided tables, so maybe there's a way to combine them. Let me check again.\n",
            "\n",
            "The chart_positions table has Certifications_sales_thresholds_ which might be a sales threshold, but how to get total sales? Maybe the Certifications_sales_thresholds_ is a count or sum of sales. But how to get the regions from that?\n",
            "\n",
            "Alternatively, maybe the table is structured such that each chart position has a region. But the user wants total sales by region. Wait, the table has columns like Peak_chart_positions_US, which could be the number of chart positions. But the user wants total sales, so perhaps the Certifications_sales_thresholds_ is the sales data. But how to get total sales by region?\n",
            "\n",
            "Wait, maybe the sales threshold is per region. For example, Certifications_sales_thresholds_ could be the sales threshold for each region. But how to aggregate by region? Maybe there's a join between chart_positions and the district_info table. For example, if each chart position corresponds to a district, then joining by region, and summing the sales threshold for each district. But the user's question is about total sales by region, so perhaps the total sales per region from the chart_positions table, considering the Certifications_sales_thresholds_.\n",
            "\n",
            "Alternatively, maybe the Certifications_sales_thresholds_ is the total sales, and the regions are the countries. But the problem is that the user's question is about total sales by region, which could be a country, so perhaps the SQL query needs to sum the Certifications_sales_thresholds_ for each region, but how to get the regions from the tables?\n",
            "\n",
            "Wait, maybe the answer is to join the chart_positions and district_info tables on some column, and then sum the Certifications_sales_thresholds_ by region. But the user's question is in the context of the provided tables, so perhaps there's a way. Let me think again.\n",
            "\n",
            "The user's question is to show total sales by region. The table 'chart_positions' has Certifications_sales_thresholds_. Maybe that's the sales threshold, and the regions are the countries. But how to get the regions from the tables. Alternatively, perhaps the total sales is the sum of all Certifications_sales_thresholds_ from the chart_positions table, and regions are the countries. But since the user's tables don't directly specify regions, maybe there's a misunderstanding.\n",
            "\n",
            "Wait, maybe the correct approach is to use the chart_positions table to get the sales data and join it with the district_info table to get the regions. Then sum the sales by region. For example, SELECT SUM(Certifications_sales_thresholds_) FROM chart_positions JOIN district_info ON ... WHERE ... ; but the exact join condition is missing. Since the user's question is about total sales by region, and the tables don't have a region column, perhaps the answer is to sum the Certifications_sales_thresholds_ for each region, but without knowing the regions, maybe there's a mistake here.\n",
            "\n",
            "Alternatively, maybe the sales threshold is per region, so the query is to sum that for each region. But since the user provided tables, and the question is about regions, perhaps the answer is to use the chart_positions table and sum the Certifications_sales_thresholds_ by joining with district_info on Region or something. But the problem is that the user's tables don't specify regions, so maybe there's an error here. Or perhaps the answer is to use the chart_positions table's columns and sum them, but that doesn't make sense.\n",
            "\n",
            "Wait, maybe the user made a typo, and the correct columns are different. Or perhaps the answer is to use the chart_positions table and add all the sales thresholds, but that's not matching the question. Alternatively, the answer is to sum the Certifications_sales_thresholds_ for each country, but how to get the countries from the tables.\n",
            "\n",
            "Alternatively, maybe the user wants to sum all sales from all chart positions, but that doesn't make sense. I'm confused. Let me check the example format. The example given is SELECT column_name FROM table_name WHERE condition. So the user wants to select total sales by region. Since there's no region column, maybe the answer is to sum all Certifications_sales_thresholds_ from chart_positions, but that would be a single value, not per region. Therefore, there's a problem here.\n",
            "\n",
            "Wait, perhaps the user intended to use the movie_chart_positions table, but that's for movies. Alternatively, maybe the answer is to sum all the sales from the chart_positions table. But how to get the regions? Maybe the regions are the countries, so the query is to sum the Certifications_sales_thresholds_ for each country. But how to get the countries? Maybe the chart_positions table has a column that identifies the region, but it's not named here. \n",
            "\n",
            "Alternatively, perhaps the answer is to use the chart_positions table and sum the Certifications_sales_thresholds_ by joining with district_info on some column, but without knowing the columns, I can't proceed. Since the user's tables don't specify regions, maybe there's a mistake in the problem setup. But the user insists on generating a valid SQL query using the given schema. \n",
            "\n",
            "Wait, perhaps the Certifications_sales_thresholds_ is the total sales, and the regions are the countries. But how to get the regions from the tables. Maybe the answer is to use the chart_positions table and sum the sales threshold, but that's a single value. Therefore, perhaps there's a misunderstanding in the problem. But since the user requires a valid SQL query, maybe the intended answer is to sum all the sales thresholds from chart_positions, but that doesn't make sense. \n",
            "\n",
            "Alternatively, maybe the answer is to join the chart_positions and district_info tables on the same column, and then sum the Certifications_sales_thresholds_ by region. But without knowing the join condition, I can't write that. Since the problem is presented as a table, perhaps the correct approach is to assume that the regions are the countries, and the query is to sum the sales thresholds. But that would be a single value. Therefore, perhaps there's a mistake in the problem setup, but since I have to generate a query, maybe I need to proceed.\n",
            "\n",
            "Wait, the user's example uses a column from a table. Maybe the answer is to sum the Certifications_sales_thresholds_ from chart_positions, but that's not per region. Unless the threshold is per region, but how to get that. \n",
            "\n",
            "Alternatively, maybe the answer is to use the movie_chart_positions table and sum the Chart_Positions_UK, Chart_Positions_US, etc. But the user's question is about total sales by region. \n",
            "\n",
            "I think I'm stuck here. Maybe the correct approach is to use the chart_positions table and sum the Certifications_sales_thresholds_ for each region. But how to do that. Since there's no region column, perhaps there's a mistake. But since the user requires a query, maybe the answer is to select SUM(Certifications_sales_thresholds_) from chart_positions, but that's not per region. \n",
            "\n",
            "Wait, perhaps the user wants to show the total sales by country, and the chart_positions table has a column that represents the country. But in the given schema, there's no country column. Therefore, the problem may have errors, but the user expects an answer. \n",
            "\n",
            "Given that, maybe the correct SQL query is to sum the Certifications_sales_thresholds_ from chart_positions, but without specifying regions. But that would be incorrect. Alternatively, perhaps the answer is to join the chart_positions table with district_info on some column, like Region, and then sum the sales. But since there's no Region column, I can't proceed. \n",
            "\n",
            "I think the problem is that there's a mistake in the schema, and the user expects a query that uses the available columns, even if they don't directly relate to regions. However, given the information, I can only provide a query that selects the Certifications_sales_thresholds_ from chart_positions, which would be a single value, not per region. But since the user's example shows selecting a column, perhaps the intended answer is to sum all the sales thresholds. But that's not a valid query for a region-based total. Therefore, I must conclude that there's an error in the problem setup, but the user requires a query, so I'll proceed with the best possible answer based on available information.\n",
            "</think>\n",
            "\n",
            "SELECT SUM(Certifications_sales_thresholds_) FROM chart_positions;\n",
            "Cleaned SQL Query: SELECT SUM(Certifications_sales_thresholds_) FROM chart_positions\n",
            "[SUCCESS] SQL executed successfully on attempt #1\n",
            "<think>\n",
            "Okay, let's see. The user wants to know the total sales by region from the given SQL query. The SQL query is SELECT SUM(Certifications_sales_thresholds_) FROM chart_positions. The response from the SQL is a node with a score, and the result is [(None,)]. \n",
            "\n",
            "Hmm, so the SQL is trying to sum up the Certifications_sales_thresholds_ column from the chart_positions table. But the result is just a list of tuples with None, which might mean that the query didn't return any rows or that there's a problem. The score is missing, but maybe it's indicating that the query didn't find any data.\n",
            "\n",
            "Wait, the user's question is about total sales by region, but the SQL is summing a specific column. Maybe the chart_positions table has data, but when we run the query, it's not showing up. Or perhaps there's a typo or a mistake in the query. The result is [(None,)], which suggests that the query didn't return any sales figures. So the answer would be that there's no data available to calculate the total sales by region based on the current query execution.\n",
            "\n",
            "Alternatively, maybe there's a misunderstanding. If the query is correct, but the data isn't available, the response should clarify that. The user's question is straightforward, so the answer should state that there's no information provided to answer the query, or that the data isn't available. The SQL response is a node indicating the query's result, but without any content, it's just a list of tuples, so the answer is that there's no sales data to show.\n",
            "</think>\n",
            "\n",
            "The SQL query executed successfully but returned an empty result. There is no available data to calculate the total sales by region. The query's result was represented as `[(None,)]`, indicating no sales figures were found in the `chart_positions` table.\n"
          ]
        }
      ],
      "source": [
        "response_3 = await run_text2sql_workflow(\"Show me total sales by region\")\n",
        "print(response_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9acab5f",
      "metadata": {},
      "source": [
        "# FINAL SCORE: 2/4 \n",
        "\n",
        "## Problem: Column names aren't getting specified properly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0fb1122-a15f-4b13-b8e0-6dd23e4fb893",
      "metadata": {
        "id": "a0fb1122-a15f-4b13-b8e0-6dd23e4fb893"
      },
      "source": [
        "## 2. Advanced Capability 2: Text-to-SQL with Query-Time Row Retrieval (along with Table Retrieval)\n",
        "\n",
        "One problem in the previous example is that if the user asks a query that asks for \"The Notorious BIG\" but the artist is stored as \"The Notorious B.I.G\", then the generated SELECT statement will likely not return any matches.\n",
        "\n",
        "We can alleviate this problem by fetching a small number of example rows per table. A naive option would be to just take the first k rows. Instead, we embed, index, and retrieve k relevant rows given the user query to give the text-to-SQL LLM the most contextually relevant information for SQL generation.\n",
        "\n",
        "We now extend our query pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5984f5db-7bfe-41ff-9cfe-2cde0e0a5d94",
      "metadata": {
        "id": "5984f5db-7bfe-41ff-9cfe-2cde0e0a5d94"
      },
      "outputs": [],
      "source": [
        "from llama_index.query_pipeline import QueryPipeline as QP\n",
        "from llama_index.service_context import ServiceContext\n",
        "\n",
        "qp = QP(verbose=True)\n",
        "# NOTE: service context will be deprecated in v0.10 (though will still be backwards compatible)\n",
        "service_context = ServiceContext.from_defaults(callback_manager=qp.callback_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edee5340-b4f9-4594-b62d-376d1ef8cf75",
      "metadata": {
        "id": "edee5340-b4f9-4594-b62d-376d1ef8cf75"
      },
      "source": [
        "### Index Each Table\n",
        "\n",
        "We embed/index the rows of each table, resulting in one index per table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c0fcb2-b079-48f2-8c54-bf5c66940173",
      "metadata": {
        "id": "a5c0fcb2-b079-48f2-8c54-bf5c66940173",
        "outputId": "e8eefac0-5d06-46c5-89af-0de57363db2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indexing rows in table: Academy_Awards_1972\n",
            "Indexing rows in table: Actress_Awards\n",
            "Indexing rows in table: Actress_Awards_Table\n",
            "Indexing rows in table: Actress_Filmography\n",
            "Indexing rows in table: Afrikaans_Language_Translations\n",
            "Indexing rows in table: Airport_Information\n",
            "Indexing rows in table: Average_Temperature_Precipitation\n",
            "Indexing rows in table: Average_Temperature_and_Precipitation\n",
            "Indexing rows in table: BBC_Radio_Costs\n",
            "Indexing rows in table: Bad_Boy_Artists\n",
            "Indexing rows in table: Boxing_Matches\n",
            "Indexing rows in table: Club_Performance_Norway\n",
            "Indexing rows in table: Disappeared_Persons\n",
            "Indexing rows in table: Drop Events\n",
            "Indexing rows in table: European_Football_Standings\n",
            "Indexing rows in table: Football_Team_Records\n",
            "Indexing rows in table: Gortynia_Municipalities\n",
            "Indexing rows in table: Grammy_Awards\n",
            "Indexing rows in table: Italian_Presidents\n",
            "Indexing rows in table: Kentucky_Derby_Winners\n",
            "Indexing rows in table: Kinase_Cancer_Relationships\n",
            "Indexing rows in table: Kodachrome_Film\n",
            "Indexing rows in table: New_Mexico_Officials\n",
            "Indexing rows in table: Number_Encoding_Probability\n",
            "Indexing rows in table: Peak_Chart_Positions\n",
            "Indexing rows in table: Political Positions of Lord Beaverbrook\n",
            "Indexing rows in table: Radio_Stations\n",
            "Indexing rows in table: Renaissance_Discography\n",
            "Indexing rows in table: Schools_in_Ohio\n",
            "Indexing rows in table: Temperature_and_Precipitation\n",
            "Indexing rows in table: Voter_Party_Statistics\n",
            "Indexing rows in table: Voter_Registration_Statistics\n",
            "Indexing rows in table: Yamato_District_Area_Population\n",
            "Indexing rows in table: Yearly_Deaths_and_Accidents\n"
          ]
        }
      ],
      "source": [
        "from llama_index import VectorStoreIndex, load_index_from_storage\n",
        "from sqlalchemy import text\n",
        "from llama_index.schema import TextNode\n",
        "from llama_index.storage import StorageContext\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "def index_all_tables(\n",
        "    sql_database: SQLDatabase, table_index_dir: str = \"table_index_dir\"\n",
        ") -> Dict[str, VectorStoreIndex]:\n",
        "    \"\"\"Index all tables.\"\"\"\n",
        "    if not Path(table_index_dir).exists():\n",
        "        os.makedirs(table_index_dir)\n",
        "\n",
        "    vector_index_dict = {}\n",
        "    engine = sql_database.engine\n",
        "    for table_name in sql_database.get_usable_table_names():\n",
        "        print(f\"Indexing rows in table: {table_name}\")\n",
        "        if not os.path.exists(f\"{table_index_dir}/{table_name}\"):\n",
        "            # get all rows from table\n",
        "            with engine.connect() as conn:\n",
        "                cursor = conn.execute(text(f'SELECT * FROM \"{table_name}\"'))\n",
        "                result = cursor.fetchall()\n",
        "                row_tups = []\n",
        "                for row in result:\n",
        "                    row_tups.append(tuple(row))\n",
        "\n",
        "            # index each row, put into vector store index\n",
        "            nodes = [TextNode(text=str(t)) for t in row_tups]\n",
        "\n",
        "            # put into vector store index (use OpenAIEmbeddings by default)\n",
        "            index = VectorStoreIndex(nodes, service_context=service_context)\n",
        "\n",
        "            # save index\n",
        "            index.set_index_id(\"vector_index\")\n",
        "            index.storage_context.persist(f\"{table_index_dir}/{table_name}\")\n",
        "        else:\n",
        "            # rebuild storage context\n",
        "            storage_context = StorageContext.from_defaults(\n",
        "                persist_dir=f\"{table_index_dir}/{table_name}\"\n",
        "            )\n",
        "            # load index\n",
        "            index = load_index_from_storage(\n",
        "                storage_context, index_id=\"vector_index\", service_context=service_context\n",
        "            )\n",
        "        vector_index_dict[table_name] = index\n",
        "\n",
        "    return vector_index_dict\n",
        "\n",
        "\n",
        "vector_index_dict = index_all_tables(sql_database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f06a001a-7e9b-41e4-94f3-019d3009fe6a",
      "metadata": {
        "id": "f06a001a-7e9b-41e4-94f3-019d3009fe6a",
        "outputId": "579cd0b2-cb2a-4b8d-82c2-b91a425b9069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Diddy', 1993, '6')\n"
          ]
        }
      ],
      "source": [
        "test_retriever = vector_index_dict[\"Bad_Boy_Artists\"].as_retriever(\n",
        "    similarity_top_k=1\n",
        ")\n",
        "nodes = test_retriever.retrieve(\"P. Diddy\")\n",
        "print(nodes[0].get_content())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f598a0a-1a3d-42a7-8640-fc1309d8b387",
      "metadata": {
        "id": "5f598a0a-1a3d-42a7-8640-fc1309d8b387"
      },
      "source": [
        "### Define Expanded Table Parser Component\n",
        "\n",
        "We expand the capability of our `table_parser_component` to not only return the relevant table schemas, but also return relevant rows per table schema.\n",
        "\n",
        "It now takes in both `table_schema_objs` (output of table retriever), but also the original `query_str` which will then be used for vector retrieval of relevant rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22340e9c-382c-4b7d-9266-d53a72af3023",
      "metadata": {
        "id": "22340e9c-382c-4b7d-9266-d53a72af3023"
      },
      "outputs": [],
      "source": [
        "from llama_index.retrievers import SQLRetriever\n",
        "from typing import List\n",
        "from llama_index.query_pipeline import FnComponent\n",
        "\n",
        "sql_retriever = SQLRetriever(sql_database)\n",
        "\n",
        "\n",
        "def get_table_context_and_rows_str(\n",
        "    query_str: str, table_schema_objs: List[SQLTableSchema]\n",
        "):\n",
        "    \"\"\"Get table context string.\"\"\"\n",
        "    context_strs = []\n",
        "    for table_schema_obj in table_schema_objs:\n",
        "        # first append table info + additional context\n",
        "        table_info = sql_database.get_single_table_info(\n",
        "            table_schema_obj.table_name\n",
        "        )\n",
        "        if table_schema_obj.context_str:\n",
        "            table_opt_context = \" The table description is: \"\n",
        "            table_opt_context += table_schema_obj.context_str\n",
        "            table_info += table_opt_context\n",
        "\n",
        "        # also lookup vector index to return relevant table rows\n",
        "        vector_retriever = vector_index_dict[\n",
        "            table_schema_obj.table_name\n",
        "        ].as_retriever(similarity_top_k=2)\n",
        "        relevant_nodes = vector_retriever.retrieve(query_str)\n",
        "        if len(relevant_nodes) > 0:\n",
        "            table_row_context = \"\\nHere are some relevant example rows (values in the same order as columns above)\\n\"\n",
        "            for node in relevant_nodes:\n",
        "                table_row_context += str(node.get_content()) + \"\\n\"\n",
        "            table_info += table_row_context\n",
        "\n",
        "        context_strs.append(table_info)\n",
        "    return \"\\n\\n\".join(context_strs)\n",
        "\n",
        "\n",
        "table_parser_component = FnComponent(fn=get_table_context_and_rows_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff926459-8161-4405-a2e8-3b074e925748",
      "metadata": {
        "id": "ff926459-8161-4405-a2e8-3b074e925748"
      },
      "source": [
        "### Define Expanded Query Pipeline\n",
        "\n",
        "This looks similar to the query pipeline in section 1, but with an upgraded table_parser_component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54d654a0-47bf-47c4-b101-97c55463f5fd",
      "metadata": {
        "id": "54d654a0-47bf-47c4-b101-97c55463f5fd"
      },
      "outputs": [],
      "source": [
        "from llama_index.query_pipeline import (\n",
        "    QueryPipeline as QP,\n",
        "    Link,\n",
        "    InputComponent,\n",
        "    CustomQueryComponent,\n",
        ")\n",
        "\n",
        "qp.add_modules({\n",
        "    \"input\": InputComponent(),\n",
        "    \"table_retriever\": obj_retriever,\n",
        "    \"table_output_parser\": table_parser_component,\n",
        "    \"text2sql_prompt\": text2sql_prompt,\n",
        "    \"text2sql_llm\": llm,\n",
        "    \"sql_output_parser\": sql_parser_component,\n",
        "    \"sql_retriever\": sql_retriever,\n",
        "    \"response_synthesis_prompt\": response_synthesis_prompt,\n",
        "    \"response_synthesis_llm\": llm,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0b921b6-b8da-4901-b1a7-a21df6f1ccb1",
      "metadata": {
        "id": "b0b921b6-b8da-4901-b1a7-a21df6f1ccb1"
      },
      "outputs": [],
      "source": [
        "qp.add_link(\"input\", \"table_retriever\")\n",
        "qp.add_link(\"input\", \"table_output_parser\", dest_key=\"query_str\")\n",
        "qp.add_link(\n",
        "    \"table_retriever\", \"table_output_parser\", dest_key=\"table_schema_objs\"\n",
        ")\n",
        "qp.add_link(\"input\", \"text2sql_prompt\", dest_key=\"query_str\")\n",
        "qp.add_link(\"table_output_parser\", \"text2sql_prompt\", dest_key=\"schema\")\n",
        "qp.add_chain(\n",
        "    [\"text2sql_prompt\", \"text2sql_llm\", \"sql_output_parser\", \"sql_retriever\"]\n",
        ")\n",
        "qp.add_link(\n",
        "    \"sql_output_parser\", \"response_synthesis_prompt\", dest_key=\"sql_query\"\n",
        ")\n",
        "qp.add_link(\n",
        "    \"sql_retriever\", \"response_synthesis_prompt\", dest_key=\"context_str\"\n",
        ")\n",
        "qp.add_link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\")\n",
        "qp.add_link(\"response_synthesis_prompt\", \"response_synthesis_llm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a2f78d4-d2cf-460f-a218-c47b7a98a67e",
      "metadata": {
        "id": "8a2f78d4-d2cf-460f-a218-c47b7a98a67e",
        "outputId": "6759b690-54e5-4b83-eaed-0ae429669c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text2sql_dag.html\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600px\"\n",
              "            src=\"text2sql_dag.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x2c56ff1f0>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyvis.network import Network\n",
        "\n",
        "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
        "net.from_nx(qp.dag)\n",
        "net.show(\"text2sql_dag.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16400cfc-7a21-45fc-932d-b917ab97babe",
      "metadata": {
        "id": "16400cfc-7a21-45fc-932d-b917ab97babe"
      },
      "source": [
        "### Run Some Queries\n",
        "\n",
        "We can now ask about relevant entries even if it doesn't exactly match the entry in the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c54c61a4-87f2-401d-8a3f-955105303883",
      "metadata": {
        "id": "c54c61a4-87f2-401d-8a3f-955105303883",
        "outputId": "8d73da17-42ba-4f53-cc06-89e7118a18e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
            "query: What was the year that The Notorious BIG was signed to Bad Boy?\n",
            "\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module table_retriever with input: \n",
            "input: What was the year that The Notorious BIG was signed to Bad Boy?\n",
            "\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module table_output_parser with input: \n",
            "query_str: What was the year that The Notorious BIG was signed to Bad Boy?\n",
            "table_schema_objs: [SQLTableSchema(table_name='Bad_Boy_Artists', context_str='List of artists signed to Bad Boy Records and their album releases'), SQLTableSchema(table_name='Football_Team_Records', context_str='Summary...\n",
            "\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module text2sql_prompt with input: \n",
            "query_str: What was the year that The Notorious BIG was signed to Bad Boy?\n",
            "schema: Table 'Bad_Boy_Artists' has columns: Act (VARCHAR), Year_signed (INTEGER), _Albums_released_under_Bad_Boy (VARCHAR), and foreign keys: . The table description is: List of artists signed to Bad Boy Rec...\n",
            "\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module text2sql_llm with input: \n",
            "messages: Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer. You can order the results by a relevant column to return...\n",
            "\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_output_parser with input: \n",
            "response: assistant: SELECT Year_signed\n",
            "FROM Bad_Boy_Artists\n",
            "WHERE Act = 'The Notorious B.I.G'\n",
            "SQLResult: 1993\n",
            "Answer: The Notorious BIG was signed to Bad Boy in 1993.\n",
            "\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module sql_retriever with input: \n",
            "input: SELECT Year_signed\n",
            "FROM Bad_Boy_Artists\n",
            "WHERE Act = 'The Notorious B.I.G'\n",
            "\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
            "query_str: What was the year that The Notorious BIG was signed to Bad Boy?\n",
            "sql_query: SELECT Year_signed\n",
            "FROM Bad_Boy_Artists\n",
            "WHERE Act = 'The Notorious B.I.G'\n",
            "context_str: [NodeWithScore(node=TextNode(id_='07dd2198-9ce8-427c-8715-3c5278f6af47', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[(1993,)]'...\n",
            "\n",
            "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_llm with input: \n",
            "messages: Given an input question, synthesize a response from the query results.\n",
            "Query: What was the year that The Notorious BIG was signed to Bad Boy?\n",
            "SQL: SELECT Year_signed\n",
            "FROM Bad_Boy_Artists\n",
            "WHERE Act = '...\n",
            "\n",
            "\u001b[0massistant: The Notorious BIG was signed to Bad Boy in 1993.\n"
          ]
        }
      ],
      "source": [
        "response = qp.run(\n",
        "    query=\"What was the year that The Notorious BIG was signed to Bad Boy?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4821ef4a-aeff-4082-ae2c-accef0068c40",
      "metadata": {
        "id": "4821ef4a-aeff-4082-ae2c-accef0068c40"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
